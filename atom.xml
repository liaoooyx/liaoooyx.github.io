<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>米达的博客</title>
  
  <subtitle>好好学习</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://liaoooyx.com/"/>
  <updated>2020-04-15T17:29:20.358Z</updated>
  <id>https://liaoooyx.com/</id>
  
  <author>
    <name>liaoooyx</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Image Caption Generation 相关问题</title>
    <link href="https://liaoooyx.com/2020/04/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Image-Caption-Generation/"/>
    <id>https://liaoooyx.com/2020/04/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/Image-Caption-Generation/</id>
    <published>2020-04-15T13:25:47.522Z</published>
    <updated>2020-04-15T17:29:20.358Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8" target="_blank" rel="noopener">参考文章</a></p><a id="more"></a><h3 id="Encoder-Decoder模型"><a href="#Encoder-Decoder模型" class="headerlink" title="Encoder-Decoder模型"></a>Encoder-Decoder模型</h3><p>图片字幕生成的细节：</p><ul><li><p>模型使用的词典不在乎单词的顺序问题</p></li><li><p>这是一个监督学习问题</p><ul><li><p>通过输入的Xi，预测输出的Yi</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gdus9eyca0j311q0h8n0h.jpg" alt="截屏2020-04-15 下午2.33.57"></p></li><li><p>也即是给定图片向量，每次预测基于当前的部分字幕，生成下一个单词</p><ul><li>输入：图片向量和当前的部分字幕（以词典中的索引表示）<ul><li>将字幕转化为输入，涉及到词嵌入技术（the word embedding techniques），比如 GLOVE词嵌入模型，将每个单词都匹配为长度200（自定义）的向量</li><li>也可以单纯的只使用词典本身作为向量（在词典中存在为1，不存在为0）</li></ul></li><li>预测输出：下一个单词</li></ul></li></ul></li></ul><hr><h3 id="相关问题"><a href="#相关问题" class="headerlink" title="相关问题"></a>相关问题</h3><h4 id="Q1-What-the-advantages-disadvantages-might-be-of-using-lemmatized-vs-regular-tokens"><a href="#Q1-What-the-advantages-disadvantages-might-be-of-using-lemmatized-vs-regular-tokens" class="headerlink" title="Q1. What the advantages/disadvantages might be of using lemmatized vs regular tokens."></a><strong>Q1. What the advantages/disadvantages might be of using lemmatized vs regular tokens.</strong></h4><p>Tokenization is the process of splitting any string into words. It is an essential approach for data preparation relevant to field of language processing. In this process, there are lots of methods can be applied thus lead to different type of tokens such as lemmatized tokens and regular tokens. Lemmatization usually refers to transforming words from inflected, singular forms etc. to the base form, known as the lemma, which is an actual word in a dictionary. For example, <em>am</em>, <em>is</em>, <em>are</em> will be converted to <em>be</em>, and <em>runs</em>, <em>ran</em>, <em>running</em>, will be of <em>run</em>. During Lemmatization process, the transformation of a specific word relies on the current context, such as identifying whether the word <em>saw</em> is a noun or a verb.</p><p>The regular tokens are generated from simple process such as tokenization, removing punctuation, converting words into lowercase while lemmatized tokens have one more process which is Lemmatization. The mainly different is whether the token word is remaining same or converted to a base form.</p><p>There are many advantages of using lemmatized tokens. One of the most widely known advantages is it can give a better result by removing the inflectional endings only and therefore can properly represents a group of related words with same token. For example, in this Image Caption Generation task, where the data is not big enough, lemmatized tokens can represent the highly discrete words more aggregated. The inflected words with same meaning will be grouped and hence will not affect the weight differently in the network. From another perspective, it is equivalent to increasing the amount of data. As a result, the generated caption might be more accurate. However, it comes with the costs. Lemmatization uses a corpus to transform the words and takes the context of original text into account, which means more computing and storage consumption. On the other words, it will slow down the processing speed and use more memory.</p><p>On the other hand, the advantages and disadvantages of regular tokens are opposite to lemmatized tokens. As its simplicity, it is suitable for the tasks with constraints on time and memory. What’s more, English is not an inflection-rich language (comparing with Spanish and Arabic) thus not that much influence if using regular tokens. But the results may inevitably worse than using lemmatized tokens.</p><p>In conclusion, using lemmatized tokens is usually a better option, but still coms with its drawback. In some circumstances, the regular tokens might be more suitable. As a result, people should depend on the use case to choose a proper approach. </p><h4 id="Q2-Present-the-sample-images-and-generated-caption-for-each-epoch-of-training-for-both-the-RNN-and-LSTM-version-of-the-decoder-including-the-BLEU-scores"><a href="#Q2-Present-the-sample-images-and-generated-caption-for-each-epoch-of-training-for-both-the-RNN-and-LSTM-version-of-the-decoder-including-the-BLEU-scores" class="headerlink" title="Q2. Present the sample images and generated caption for each epoch of training for both the RNN and LSTM version of the decoder, including the BLEU scores."></a><strong>Q2. Present the sample images and generated caption for each epoch of training for both the RNN and LSTM version of the decoder, including the BLEU scores.</strong></h4><p>In this task, the report chooses the same two images for observing the generated caption for RNN and LSTM. Table 1 is listing the parameters which remain the same in the sampling process, including the image, the reference captions used for computing BLEU score, and the weights of BLEU for each gram. Table 2-6 are comparing the generated caption and the corresponding BLEU cumulative score between LSTM and RNN at each epoch. Noticed that the tokens <start> and <end> has been removed from generated caption.</p><p>Table 1: The same parameters when generating caption.</p><div class="table-container"><table><thead><tr><th style="text-align:center">Image Id</th><th>539705321_99406e5820.jpg</th></tr></thead><tbody><tr><td style="text-align:center">Image</td><td><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduyeba6gpj30kj0aggwj.jpg" alt="手机屏幕截图  描述已自动生成"></td></tr><tr><td style="text-align:center">Reference Captions</td><td>a kid in  red falls as he struggles with a kid in white to get to a soccer ball <br />children  chasing the ball in a soccer game<br />little  boys running and chasing a soccer ball<br />the boy  with the red soccer suit is falling down while the boy in the white shirt has  his eyes on the ball <br />two teams  of children one in red and the other in white are playing soccer</td></tr><tr><td style="text-align:center">BLEU Weights</td><td>1-gram: (1, 0, 0, 0)  <br />2-gram: (0.66, 0.33,  0, 0)  <br />3-gram: (0.6, 0.3,  0.1, 0) <br />4-gram: (0.5, 0.25,  0.15, 0.1)</td></tr></tbody></table></div><p>Table 2: BLEU cumulative score for n-gram on LSTM and RNN at 1st epoch.</p><div class="table-container"><table><thead><tr><th style="text-align:center">1st Epoch</th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">LSTM</td><td style="text-align:center">RNN</td></tr><tr><td style="text-align:center">Generated Caption</td><td style="text-align:center">a man in a red shirt and a red shirt and a  woman in a red shirt and a</td><td style="text-align:center">a young girl in a red shirt and a white shirt  and a white shirt and a white shirt</td></tr><tr><td style="text-align:center">BLEU Score</td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye9r4a1j30fc040aan.jpg" alt="手机屏幕截图  描述已自动生成"></td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye7tkewj30fe03wjrz.jpg" alt="手机屏幕截图  描述已自动生成"></td></tr></tbody></table></div><p>Table 3: BLEU cumulative score for n-gram on LSTM and RNN at 2nd epoch.</p><div class="table-container"><table><thead><tr><th style="text-align:center">2nd Epoch</th><th style="text-align:center"></th><th></th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">LSTM</td><td>RNN</td></tr><tr><td style="text-align:center">Generated Caption</td><td style="text-align:center">a group of children playing in a field</td><td>two girls are playing in a field</td></tr><tr><td style="text-align:center">BLEU Score</td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduyec0ufyj30fg03yq3j.jpg" alt="手机屏幕截图  描述已自动生成"></td><td><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye4j63ij30fk03u74w.jpg" alt="手机屏幕截图  描述已自动生成"></td></tr></tbody></table></div><p>Table 4: BLEU cumulative score for n-gram on LSTM and RNN at 3rd epoch.</p><div class="table-container"><table><thead><tr><th style="text-align:center">3rd Epoch</th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">LSTM</td><td style="text-align:center">RNN</td></tr><tr><td style="text-align:center">Generated Caption</td><td style="text-align:center">a group of people are playing soccer on a  field</td><td style="text-align:center">two soccer players are playing soccer</td></tr><tr><td style="text-align:center">BLEU Score</td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduyecm1ecj30bz02y0t7.jpg" alt="手机屏幕截图  描述已自动生成"></td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye1an4bj30fi03yjrz.jpg" alt="手机屏幕截图  描述已自动生成"></td></tr></tbody></table></div><p>Table 5: BLEU cumulative score for n-gram on LSTM and RNN at 4th epoch.</p><div class="table-container"><table><thead><tr><th style="text-align:center">4th Epoch</th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">LSTM</td><td style="text-align:center">RNN</td></tr><tr><td style="text-align:center">Generated Caption</td><td style="text-align:center">a boy in a red shirt and a baseball cap is  running on a grassy field</td><td style="text-align:center">three children play in a field</td></tr><tr><td style="text-align:center">BLEU Score</td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye2alcej30d303aaan.jpg" alt="手机屏幕截图  描述已自动生成"></td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduyeam4bnj30fc03smxr.jpg" alt="手机屏幕截图  描述已自动生成"></td></tr></tbody></table></div><p>Table 6: BLEU cumulative score for n-gram on LSTM and RNN at 5th epoch.</p><div class="table-container"><table><thead><tr><th style="text-align:center">5th Epoch</th><th style="text-align:center"></th><th style="text-align:center"></th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">LSTM</td><td style="text-align:center">RNN</td></tr><tr><td style="text-align:center">Generated Caption</td><td style="text-align:center">a boy in a red shirt is running with a soccer  ball in a field of grass</td><td style="text-align:center">three children are playing soccer on a grassy  field</td></tr><tr><td style="text-align:center">BLEU Score</td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye1p276j30fc03ywf3.jpg" alt="手机屏幕截图  描述已自动生成"></td><td style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye8r05jj30fg03ugm7.jpg" alt="手机屏幕截图  描述已自动生成"></td></tr></tbody></table></div><h4 id="Q3-Compare-training-using-an-RNN-vs-LSTM-for-the-decoder-network"><a href="#Q3-Compare-training-using-an-RNN-vs-LSTM-for-the-decoder-network" class="headerlink" title="Q3. Compare training using an RNN vs LSTM for the decoder network."></a><strong>Q3. Compare training using an RNN vs LSTM for the decoder network.</strong></h4><p>In this coursework, we are the using encoder-decoder model for image caption generation. For both RNN decoder or LSTM decoder, they are all using the same encoder with CNN, which is responsible for extracting and compressing the contents of images into small feature vectors. And the variable that might affect the generated captions is controlled between RNN and LSTM in the decoder. The comparison will start by comparing the structure and then move to the results of the CW code, including the overall loss and BLEU score, the difference for training with long or short captions and quality of generated captions.</p><p>From the structural level, the recurrent neural network (RNN) is a feedforward neural network that has internal memory and is recurrent in nature. The traditional convolutional neural network (CNN) in which the data stream is flowing from layer to layer has no connections between neurons (or nodes) inside the layer, causing current neuron lacks memory for the previous neurons. While RNN, on the contrary, has connections between neurons inside the hidden layers. The inputs of a current neuron include the outputs of the last layer and the previous neuron in the current layer. As a result, RNN is suitable for sequence-related tasks such as speech recognition, natural language processing, etc. </p><p>Long short-term memory network (LSTM) is a variant of RNN, belonging to feedback neural network. It is aiming to deal with the problems of gradient vanish that traditional RNN encountered during training, which means losing information in a long-distance propagation. LSTM has a similar structure as RNN in general but more complex in details. Comparing with RNN, a common LSTM has an additional parameter to keep the memory of previous data over arbitrary time intervals, called cell state, which is the core of LSTM. To regulate the information over the cell, there are three gates named forget gate, input gate and output gate. The forget gate decides which information will be removed from the last cell state. The input gate is deciding what information should be added to the current cell state. Concatenate these two steps with the last cell state, it can update the current cell state. Then, the output gate determines which information will be outputted based on above, and finally get the output. This structure helps LSTM to address the vanishing gradient problem, and accordingly, have better performance than traditional RNN in terms of longer time series tasks</p><p>To evaluate and compare models, the first criteria is observing the loss value on both the straining step and test step. Figure 1 illustrates the trends of loss for LSTM and RNN, including the loss values for every batch and the average loss values at each epoch. But the difference between them is hard to find. From table 7, which is showing the average loss in number, it can still be noticed that the loss of LSTM is slightly bigger than that of RNN at the first epoch and becomes slightly smaller at the final epoch.</p><div class="table-container"><table><thead><tr><th style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye45gbrj30h00cw0tx.jpg" alt="地图的截图  描述已自动生成"></th><th style="text-align:center"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye5z19zj30hb0crmyc.jpg" alt="手机屏幕截图  描述已自动生成"></th></tr></thead><tbody><tr><td style="text-align:center">(1)    LSTM</td><td style="text-align:center">(2)    RNN</td></tr></tbody></table></div><p> Figure 1: Loss per batch and  average loss per epoch during training for LSTM (1)  and RNN (2).  </p><p>Table 7: Average loss for LSTM and RNN on training set at each epoch.</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduylad30jj310y0900ts.jpg" alt="截屏2020-04-15 下午6.20.37"> </p><p>After finish training the model, we can evaluate the model using the test set. Here we compare the loss of model on the test set between LSTM and RNN, as well as the differences of BLEU score. In Table 8, the loss of model with LSTM decoder is also lower than that with RNN decoder. Figure 2 is illustrating the cumulative BLEU scores from 1-gram to 4-gram, which can describe the overall performance of generated captions in the perspective of words. The areas under the line are representing the percentage of captions with different scores, where blue lines stand for LSTM and orange lines stand for RNN. From the distribution of the area under the lines, we might find that the area of RNN is prone to the left than the area of LSTM, indicating a lower score. The vertical dash lines in the figures that point out the average score over the whole test set (figure 2, where the actual values are shown in table 9) prove this again. On the other hand, we have to notice that LSTM are more likely to get scores very close to zero.</p><p>Table 8: Loss for LSTM and RNN on test set</p><div class="table-container"><table><thead><tr><th></th><th>LSTM</th><th>RNN</th></tr></thead><tbody><tr><td>Test set</td><td>2.603</td><td>2.725</td></tr></tbody></table></div><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduye539qzj30z80b341c.jpg" alt="图片包含 游戏机, 设备  描述已自动生成"></p><p>Figure 2: All of Cumulative BLEU scores and the average of scores on test set for LSTM and RNN, score from 0 to 1 separated into 30 bins.</p><p> Table 9: Average cumulative BLEU score for LSTM and RNN on test set.</p><div class="table-container"><table><thead><tr><th></th><th>LSTM</th><th>RNN</th></tr></thead><tbody><tr><td>1-gram</td><td>0.550</td><td>0.494</td></tr><tr><td>2-gram</td><td>0.461</td><td>0.416</td></tr><tr><td>3-gram</td><td>0.452</td><td>0.417</td></tr><tr><td>4-gram</td><td>0.467</td><td>0.442</td></tr></tbody></table></div><p>Table 10 is comparing the results between images with the longest reference captions and shortest captions on average in the test set. For the image with the longest reference captions, although the 1-gram BLEU score for LSTM is slightly lower than that for RNN, the other three type of cumulative BLEU scores, from 2-gram to 4-gram, are all higher. And for the image with the shortest one, all of the BLEU scores when using LSTM to train the decoder are higher than using RNN. However, if we compare the generated captions in a human perspective, it is obvious that all of them are misdescribing the corresponding images at the same point thus do not show much difference for people. </p><p>We compare the loss of LSTM decoder and RNN decoder, during the training epoch on the training set and after finish training on the test set, as well as the cumulative BLEU scores on the generated captions, on average and on both the longest and the shortest reference captions. In conclusion, the difference between Loss and BLEU score in overall may indicate that LSTM may have a better performance than RNN. But with human perception, it is hard to judge which is better. And the LSTM does not show its advantages in dealing with long captions. However, this insight may not obvious and convincing enough in this case as the training set, length of the captions and training epochs seem quite constrained.</p><p>Table 10: Comparing the images with long (left) or short (right) reference captions on average in test set.</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduyncvc1mj30u00vu454.jpg" alt="截屏2020-04-15 下午6.21.38"> </p><h4 id="Q4-Among-the-text-annotations-files-downloaded-with-the-Flickr8k-dataset-are-two-files-we-did-not-use-ExpertAnnotations-txt-and-CrowdFlowerAnnotations-txt-Read-the-readme-txt-to-understand-their-contents-then-consider-and-discuss-how-these-might-be-incorporated-into-evaluating-your-models"><a href="#Q4-Among-the-text-annotations-files-downloaded-with-the-Flickr8k-dataset-are-two-files-we-did-not-use-ExpertAnnotations-txt-and-CrowdFlowerAnnotations-txt-Read-the-readme-txt-to-understand-their-contents-then-consider-and-discuss-how-these-might-be-incorporated-into-evaluating-your-models" class="headerlink" title="Q4. Among the text annotations files downloaded with the Flickr8k dataset are two files we did not use: ExpertAnnotations.txt and CrowdFlowerAnnotations.txt. Read the readme.txt to understand their contents, then consider and discuss how these might be incorporated into evaluating your models."></a><strong>Q4. Among the text annotations files downloaded with the Flickr8k dataset are two files we did not use: ExpertAnnotations.txt and CrowdFlowerAnnotations.txt. Read the readme.txt to understand their contents, then consider and discuss how these might be incorporated into evaluating your models.</strong></h4><p>The file ExpertAnnotations.txt contains a set of image-captions pairs with a score that rated by experts from 1 (the caption does not describe the image at all) to 4 (the caption describes the image correctly). The file CrowdFlowerAnnotations.txt contains a collection of image-captions pairs with the judgement, by asking human whether the caption describes the image or not. Both of them giving additional non-correct captions for images compared with the file Flickr8k.token.txt, while the Crowd Flower Annotations use a binary judgement and the Expert Annotations provides a finer-grained score.</p><p>One of the limitations within the encoder-decoder model is that the only connection between the encoder and decoder is a fixed-length feature vector which represents the images with an uncertain number of objects. The feature vector may not represent all of the information of the input image so that the accuracy of the decoder will hence be affected.</p><p>On the other hand, the domain of image caption generation is related to the supervised learning using an algorithm to find out the optimal solution for generating appropriate caption of a specific image based on a collection of caption-image pairs. It is similar to image classification but far more complex as there are more objects. Hodosh et al. (2013) [1] shows that using multiple captions for an image gives better results than using a single caption. Extending from this, we suppose that if the model has additional data about not only what is correct but also what could be wrong, it might be possible to improve the model and achieve better results.</p><p>For example, when converting the words to the vector at the decoder step, we can introduce finer-grain weights with non-correct caption instead of binary values based on the two additional files. Or use it to improve the performance of the word embedding functions.</p><p>Reference:</p><p>[1] M. Hodosh, P. Young, and J. Hockenmaier. Framing image description as a ranking task: Data, models and evaluation metrics. J. Artif. Int. Res., 47(1):853–899, May 2013.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;https://towardsdatascience.com/image-captioning-with-keras-teaching-computers-to-describe-pictures-c88a46a311b8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考文章&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="人工智能" scheme="https://liaoooyx.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://liaoooyx.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="AI" scheme="https://liaoooyx.com/tags/AI/"/>
    
      <category term="RNN" scheme="https://liaoooyx.com/tags/RNN/"/>
    
      <category term="Image Caption" scheme="https://liaoooyx.com/tags/Image-Caption/"/>
    
      <category term="encoder-decoder" scheme="https://liaoooyx.com/tags/encoder-decoder/"/>
    
  </entry>
  
  <entry>
    <title>LSTM和RNN</title>
    <link href="https://liaoooyx.com/2020/04/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/RNN%E5%92%8CLSTM/"/>
    <id>https://liaoooyx.com/2020/04/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/RNN%E5%92%8CLSTM/</id>
    <published>2020-04-11T23:00:00.000Z</published>
    <updated>2020-04-15T17:30:02.481Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h4 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h4><p><a href="https://www.jianshu.com/p/89f3b045d9cb" target="_blank" rel="noopener">从结构上描述</a></p><p><a href="https://www.jianshu.com/p/7e6e55c48972" target="_blank" rel="noopener">从算法层面描述</a></p><p><a href="https://www.jianshu.com/p/9dc9f41f0b29" target="_blank" rel="noopener">整体描述LSTM</a></p><h4 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h4><p>循环神经网络的主要用途是处理和预测序列数据。</p><p>在全连接神经网络或者卷积神经网络中，都是从输入层到隐藏层再到输出层的，层与层之间都的全连接的，但<strong>每层之间的结点是无连接的</strong>。这就导致当前神经元没有前一个的记忆。而RNN的隐藏层之间的结点是有连接的，RNN的当前节点的输入包含上一层的输出和本层上一个节点的输出。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gdrer62l38j30ys0ae791.jpg" alt="截屏2020-04-12 下午4.37.36" style="zoom:33%;" /></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gdreshd3cuj30wg0d4wit.jpg" alt="截屏2020-04-12 下午4.38.49" style="zoom:33%;" /></p><p>它对短距离依赖很有效，但对长距离依赖的效果则变差</p><h4 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h4><p>LSTM 是一种特殊的RNN。通过精巧的设计（CNN中的深度残差网络也是类似）<strong>解决长序列训练过程中的梯度消失和梯度爆炸问题</strong>，即远距离传递导致的信息丢失问题。</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gdret6tzvnj30vo0ca0yo.jpg" alt="截屏2020-04-12 下午4.39.32" style="zoom:33%;" /></p><h4 id="相关名词"><a href="#相关名词" class="headerlink" title="相关名词"></a>相关名词</h4><blockquote><p>Long-Term Dependencies —— 长距离依赖</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h4 id=&quot;参考文章&quot;&gt;&lt;a href=&quot;#参考文章&quot; class=&quot;headerlink&quot; title=&quot;参考文章&quot;&gt;&lt;/a&gt;参考文章&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;https://www.jianshu.com/p/89f3b045d
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://liaoooyx.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://liaoooyx.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://liaoooyx.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="人工智能" scheme="https://liaoooyx.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="LSTM" scheme="https://liaoooyx.com/tags/LSTM/"/>
    
      <category term="RNN" scheme="https://liaoooyx.com/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>云计算中的安全性</title>
    <link href="https://liaoooyx.com/2020/04/%E4%BA%91%E8%AE%A1%E7%AE%97/16%20%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/"/>
    <id>https://liaoooyx.com/2020/04/%E4%BA%91%E8%AE%A1%E7%AE%97/16%20%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%AD%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7/</id>
    <published>2020-03-31T23:00:00.000Z</published>
    <updated>2020-04-01T21:56:04.824Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a><h4 id="网络安全"><a href="#网络安全" class="headerlink" title="网络安全"></a>网络安全</h4><p>互联网最初的设计并没有太多的考虑安全问题。最初的观点是：“通过互联网联系在一起的相互信任的用户”，而互联网协议的设计者在其中充当佐料的角色。</p><p>网络安全领域包括黑客如何攻击电脑网络，我们如何对这些攻击进行防御，以及如何设计能够免疫攻击的结构。</p><p>在每一层中都应该考虑安全性问题。</p><h4 id="什么是网络安全"><a href="#什么是网络安全" class="headerlink" title="什么是网络安全"></a>什么是网络安全</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h4 id=&quot;网络安全&quot;&gt;&lt;a href=&quot;#网络安全&quot; class=&quot;headerlink&quot; title=&quot;网络安全&quot;&gt;&lt;/a&gt;网络安全&lt;/h4&gt;&lt;p&gt;互联网最初的设计并没有太多的考虑安全问题。最初的观点是：“通过互联网联系在一起的相互信任
      
    
    </summary>
    
    
      <category term="云计算" scheme="https://liaoooyx.com/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="安全性" scheme="https://liaoooyx.com/tags/%E5%AE%89%E5%85%A8%E6%80%A7/"/>
    
  </entry>
  
  <entry>
    <title>软件度量工具的使用和比较：SonarQube、JDEPEND、</title>
    <link href="https://liaoooyx.com/2020/04/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E8%BD%AF%E4%BB%B6%E5%BA%A6%E9%87%8F%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AF%B9%E6%AF%94/"/>
    <id>https://liaoooyx.com/2020/04/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/%E8%BD%AF%E4%BB%B6%E5%BA%A6%E9%87%8F%E5%B7%A5%E5%85%B7%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%AF%B9%E6%AF%94/</id>
    <published>2020-03-31T23:00:00.000Z</published>
    <updated>2020-04-06T15:54:33.260Z</updated>
    
    <content type="html"><![CDATA[<p>软件度量是对程序本身进行数值化表示的一种方法，比如方法复杂度，代码行数，包数目等。目的是帮助开发者和管理者发现软件可能存在的缺陷、技术债务积累、代码气味等问题。</p><p><a href="https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis" target="_blank" rel="noopener">静态代码分析工具列表</a></p><a id="more"></a><h3 id="使用环境"><a href="#使用环境" class="headerlink" title="使用环境"></a>使用环境</h3><p>MacOS Catalina 10.15.4</p><p>Win10（虚拟机）</p><p>IntelliJ IDEA 2019.3</p><h3 id="SonarQube-8-2"><a href="#SonarQube-8-2" class="headerlink" title="SonarQube 8.2"></a>SonarQube 8.2</h3><p>提供多种安装方式，这里安装在本机：</p><p>下载压缩包并解压到对应目录后，使用命令行启动服务器，并访问<a href="http://localhost:9000/" target="_blank" rel="noopener">http://localhost:9000</a>即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">../sonarqube/bin/[OS]/sonar.sh console</span><br></pre></td></tr></table></figure><p>SonarQube提供的度量方法，帮助用户了解自己是否满足代码质量的标准，好的代码质量能够减少许多代码问题和技术债务的积累。确保新写的代码是干净的，从不同的层面进行分析。</p><p>在GUI中，有相关的引导，能够轻易的将SonarQube引入项目中：基本原理是在GUI页面中为项目生成一个特定的Token，在Maven或Gradle项目的配置文件中添加SonarQube插件，最后执行提供的命令即可，命令中包含了之前生成的项目令牌。</p><p>在Measure栏，SonarQube中提供了许多实用的度量方法，包括：</p><ul><li>可靠性：Bugs、分级、补救措施</li><li>安全性：易损性、分级、补救措施</li><li>安全性审查：安全性热点、分级</li><li>可维护性（对会增加更新难度的代码进行标记）：代码气味、债务（时间）、债务比例、分级、达到A级的措施</li><li>覆盖率：覆盖率、需覆盖行、未覆盖行、已覆盖率<ul><li>单元测试数量、错误、故障、跳过、成功、执行时间</li></ul></li><li>重复率：密度、重复行、重复块、重复文件</li><li>大小（数量）：代码行、总行数、声明、函数、类、文件、注释行、注释行占比</li><li>复杂度：循环复杂度（全覆盖测试的最少测试用例）、感知复杂度（理解程序的困难程度）</li><li>问题：开放问题、重开问题、确认问题、False Positive问题，保留问题</li></ul><p>在Issues栏，SonarQube还能分析代码，检测出违反开发规范的代码，并给与提醒</p><p>在Activity栏，可以展示软件度量的变化趋势，主要包括：</p><ul><li>问题：Bugs、代码气味、易损性</li><li>覆盖率：需覆盖行和未覆盖行</li><li>重复率：代码行和重复行</li><li>定制：对任意的软件度量进行组合</li></ul><p>使用该功能，每执行一次命令行则记录一次数据日志</p><p>优点：全面</p><p>缺点：</p><ul><li>无法直接回顾以前的历史记录，需要对源码进行版本控制</li><li>不开源，研究人员/开发者无法使用自己的软件度量标准</li></ul><h3 id="JDepend"><a href="#JDepend" class="headerlink" title="JDepend"></a><a href="https://github.com/clarkware/jdepend" target="_blank" rel="noopener">JDepend</a></h3><p>说明文档在</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$JDEPEND_HOME&#x2F;doc</span><br></pre></td></tr></table></figure><p>缺点：项目太老，需要修改源码重新编译，不支持可视化，没有历史记录，数据没有可视化，难以阅读，对新手来说难以理解</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdh8kjrwnij313t0u0qfg.jpg" alt="截屏2020-04-03 下午9.27.56"></p><h3 id="X-Ray"><a href="#X-Ray" class="headerlink" title="X-Ray"></a><a href="http://xray.inf.usi.ch/xray.php#download" target="_blank" rel="noopener">X-Ray</a></h3><p>2008年的工具</p><p>优点：多种可视化方式</p><p>缺点：只作为<a href="https://marketplace.eclipse.org/content/x-ray-software-visualization" target="_blank" rel="noopener">旧版Eclapse-Ganymede插件</a>使用，部分图片的内容让人感到混乱，扩展性差</p><h3 id="SourceMonitor"><a href="#SourceMonitor" class="headerlink" title="SourceMonitor"></a><a href="http://www.campwoodsw.com/sourcemonitor.html" target="_blank" rel="noopener">SourceMonitor</a></h3><p>优点：支持多语言，图形化设置，通过checkpoint可以保持和查看历史数据</p><p>缺点：只支持Windows，设置不合理，无历史记录，数据没有可视化，难以阅读，排版差</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdha02b0ilj30sg0no763.jpg" alt="截屏2020-04-03 下午10.17.29"></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdha3u8dw5j31f20iwn8m.jpg" alt="截屏2020-04-03 下午10.17.29"></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdha651nybj31f20hojup.jpg" alt="截屏2020-04-03 下午10.17.29"></p><h3 id="CodeCity"><a href="#CodeCity" class="headerlink" title="CodeCity"></a><a href="https://wettel.github.io/codecity.html" target="_blank" rel="noopener">CodeCity</a></h3><p>介绍，<a href="https://www.youtube.com/watch?v=HT3iw5l4l6U" target="_blank" rel="noopener">导入模型</a></p><p>优点：好看，功能多</p><p>缺点：复杂，旧，操作不易</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdhb7tnianj31cv0u0qo0.jpg" alt="截屏2020-04-03 下午10.59.19"></p><h3 id="FindBugs"><a href="#FindBugs" class="headerlink" title="FindBugs"></a><a href="http://findbugs.sourceforge.net/publications.html" target="_blank" rel="noopener">FindBugs</a></h3><h3 id="PMD"><a href="#PMD" class="headerlink" title="PMD"></a><a href="https://pmd.github.io/" target="_blank" rel="noopener">PMD</a></h3><p>PMD is a source code analyzer. It finds common programming flaws like unused variables, empty catch blocks, unnecessary object creation, and so forth. It supports Java, JavaScript, Salesforce.com Apex and Visualforce, PLSQL, Apache Velocity, XML, XSL.</p><p>Additionally it includes CPD, the copy-paste-detector. CPD finds duplicated code in Java, C, C++, C#, Groovy, PHP, Ruby, Fortran, JavaScript, PLSQL, Apache Velocity, Scala, Objective C, Matlab, Python, Go, Swift and Salesforce.com Apex and Visualforce.</p><p>PMD的文档，它会对代码中的如下部分进行检查：<br>　　 未使用的本地变量<br>　　 空的catch块<br>　　 未使用参数<br>　　 空if语句<br>　　 重复的import语句<br>　　 未使用的私有方法<br>　　 可能是Singletons的类<br>　　 短/长变量及方法名字</p><p>PMD提供了一项叫作CPD的很有用的功能，它检查代码的拷贝粘贴部分。我使用PMD找到的最频繁的错误是未使用的import语句，未使用的私有变量以及意外重复拼写。</p><h3 id="CheckStyle"><a href="#CheckStyle" class="headerlink" title="CheckStyle"></a><a href="https://github.com/checkstyle/checkstyle" target="_blank" rel="noopener">CheckStyle</a></h3><p>Checkstyle is a tool for checking Java source code for adherence to a Code Standard or set of validation rules (best practices).</p><p>Checkstyle检查如下部分：<br>　　 Javadoc注释<br>　　 命名约定<br>　　 标题<br>　　 Import语句<br>　　 体积大小<br>　　 空白<br>　　 修饰符<br>　　 块<br>　　 混合检查（包活一些有用的比如非必须的System.out和printstackTrace）</p><p>不像PMD，Checkstyle能够检查Javadoc注释；Checkstyle可以发现更多的错误。包括漏掉的Javadoc注释，超过80个字符的行、不合约定的变量名、用tab来代替空格等等。两个工具都允许创建自定义的规则。</p><h3 id="Jalopy"><a href="#Jalopy" class="headerlink" title="Jalopy"></a><a href="http://jalopy.sourceforge.net/" target="_blank" rel="noopener">Jalopy</a></h3><p>商用版 <a href="https://www.triemax.com/" target="_blank" rel="noopener">TRIEMAX</a></p><p>　　Jalopy是一个易于配置的源代码格式程序，它能检测并修补Java代码中大量的习惯性缺陷。Jalopy更像一个代码整理器而不是检查器。Jalopy的插件现在已经支持大多数IDE，而且多数是无缝集成。我发现Jalopy特别强大，能够干许多很酷的事情。例如，它可以修改代码缩进、对齐括号、使行宽符合某个字符长度、插入相关的Javadoc注释以及对import语句排序。Jalopy最好的地方是超级自定义功能。一个简单的用户界面就可以让你选择Jalopy的所有功能的开关，不需要XML配置文件。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>如果想在你的组织中使用它们中的一个，Checkstyle似乎更好一些：它检查公司编码约定的大多数项目。如果增强代码质量是主要目标，那PMD是一个好的选择。但是如果你想要更多的功能并真正使用工具来修改代码，应该试试Jalopy。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;软件度量是对程序本身进行数值化表示的一种方法，比如方法复杂度，代码行数，包数目等。目的是帮助开发者和管理者发现软件可能存在的缺陷、技术债务积累、代码气味等问题。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_tools_for_static_code_analysis&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;静态代码分析工具列表&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="软件工程" scheme="https://liaoooyx.com/categories/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"/>
    
    
      <category term="软件度量" scheme="https://liaoooyx.com/tags/%E8%BD%AF%E4%BB%B6%E5%BA%A6%E9%87%8F/"/>
    
      <category term="SonarQube" scheme="https://liaoooyx.com/tags/SonarQube/"/>
    
  </entry>
  
  <entry>
    <title>《A Manifesto for Future Generation Cloud Computing&amp;#59 Research Directions for the Next Decade》 —— 读书笔记</title>
    <link href="https://liaoooyx.com/2020/04/%E4%BA%91%E8%AE%A1%E7%AE%97/%E6%96%87%E7%8C%AE%E7%AC%94%E8%AE%B0/%E4%BA%91%E8%AE%A1%E7%AE%97%E7%9A%84%E6%8C%91%E6%88%98%E5%92%8C%E6%9C%AA%E6%9D%A5%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/"/>
    <id>https://liaoooyx.com/2020/04/%E4%BA%91%E8%AE%A1%E7%AE%97/%E6%96%87%E7%8C%AE%E7%AC%94%E8%AE%B0/%E4%BA%91%E8%AE%A1%E7%AE%97%E7%9A%84%E6%8C%91%E6%88%98%E5%92%8C%E6%9C%AA%E6%9D%A5%E7%A0%94%E7%A9%B6%E6%96%B9%E5%90%91/</id>
    <published>2020-03-31T23:00:00.000Z</published>
    <updated>2020-04-16T18:25:47.623Z</updated>
    
    <content type="html"><![CDATA[<p>云计算和按需付费模型的出现，让用户可以随时随地获得基于订阅的服务。这带来的好处包括：更短的启动时间；创建可扩展的全球企业程序；给科学计算和高性能计算带来更好的成本价值关联；以及为无处不在的普适程序带来不同的调用/执行模型。</p><p>另一方面，无服务计算、软件定义网络、物联网、边缘计算等新技术为云计算带来了机遇，但也同时带来了新的挑战，对新方法和研究策略的需求。对于解决可扩展性、灵活性、可靠性、安全性、可持续性等问题的模型，也需要重新进行评估。</p><p>该文献将定义云计算中的主要的开放性挑战，调查最新的解决方案和它们的局限。接着讨论新兴的趋势和影响范围，以及它们如何推动未来云计算的挑战。据此再进一步讨论云计算的未来，并指出下一个十年的研究方向。</p><a id="more"></a><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>云计算模型，提供了对基于订阅的IT资源的按需访问，按需扩展，按使用付费。当前的三种主要服务模型为SaaS、PaaS、IaaS。在软件即服务SaaS中，用户通过互联网访问在数据中心上运行和管理的程序或软件，从而避免如版权、维护IT基础设施等费用；平台即服务PaaS，适合对IT资源需要更多控制的用户，但也同时为用户提供了一些框架来支持云程序的创建和部署；基础设施即服务IaaS，则允许用户访问计算资源，通常是提供虚拟机和存储空间。它不仅是前两者的基础，也是云计算的支柱。</p><p>云计算中旧有的技术同样在不断发展，在虚拟化中，容器技术的出现和广泛使用，甚至导致新的服务模型出现：容器即服务CaaS。</p><p>其中一些特定云服务专注于简化配置，以此满足特定的商业要求，这些旨在帮助企业创造价值的云服务，在种类和数量方面正在快速的增长：比如新兴的、易于使用的、基于云的数据分析服务和无服务结构。</p><p>云计算中的分布式计算是一个更明显的发展趋势，相关概念有雾计算、边缘计算、物联网、将服务分布在地理分布的数据中心等。边缘/雾计算的核心思想是将计算能力移动到更接近数据的地方，比如移动基站、网关、交换机、路由器等，从而降低延迟；</p><blockquote><p>cluster computing —— 网格计算<br>grid computing —— 集群计算</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdfjn0ul31j311n0u04d1.jpg" alt="截屏2020-04-02 上午10.19.45"></p><h3 id="开放性问题"><a href="#开放性问题" class="headerlink" title="开放性问题"></a>开放性问题</h3><h4 id="可扩展性和可伸缩性（弹性）"><a href="#可扩展性和可伸缩性（弹性）" class="headerlink" title="可扩展性和可伸缩性（弹性）"></a>可扩展性和可伸缩性（弹性）</h4><ul><li>通过硬件的异质性来加速计算</li><li>资源虚拟化、性能、隔离、价值模型</li><li>用于可扩展弹性服务的软件</li><li>对性能进行监控和建模的中间件</li><li>适应性的程序编程模型</li></ul><p>网格计算和集群计算是早期的分布式计算模型，云计算与前两者不同，它的优点是可以保证按需提供几乎无限的计算资源。好处之一是<strong>云计算中预料之外的计算资源需求激增不会违反<a href="http://blog.sina.com.cn/s/blog_c3917d180101c8r6.html" target="_blank" rel="noopener">服务级别协议SLAs</a></strong>，因为用户购买的固定计算资源无法给用户提供预期之外的服务质量QoS。但<strong>前提</strong>是云服务提供商提供可扩展的服务，即用户可<strong>以按需增加计算资源</strong>，并且新的计算资源能够直接给当前程序带来性能和服务质量的提升；其二是<strong>客户不需要提前调查、规划、购买硬件设备，而是根据当前需求购买云计算资源，并灵活变动</strong>。</p><p>研究挑战在于可扩展的服务，它包括硬件级、中间件级和应用级。在硬件级中，要求云计算提供商有<strong>并行计算硬件</strong>，如多核、集群、加速器（GPUs），和非传统的架构（神经和量子），以及在<strong>IaaS服务</strong>中为用户提供<strong>异质硬件的抽象</strong>（如VMs、容器），同时提供隔离和性能保证。在<strong>中间件级别</strong>中，需要为用户提供<strong>编程模型和抽象</strong>，从而让使用PaaS服务的开发者可以专注于程序本身的功能（如Map、Reduce函数），而非功能性的问题（如可扩展性、容错）则交给中间件负责。在<strong>应用级</strong>中，需要开发新的算法，克服<strong>顺序确定性算法</strong>固有的可扩展性问题，包括非同步演化算法、近似算法、在线/增量算法（<a href="https://ieeexplore.ieee.org/document/5380857" target="_blank" rel="noopener">文献</a>）等，这些算法可能会通过<strong>牺牲精度或一致性来实现可扩展性和性能</strong>。</p><p>在弹性服务方面的挑战包括：如何<strong>精确预测</strong>计算资源需求和不同资源分配下的程序性能。这些工作负载和性能模型能够帮助中间件中的资源管理器进行决策，也使程序能够扩展和收缩，包括动态创建、迁移、回收虚拟机、容器和其他计算资源等。</p><p>成熟的<strong>虚拟机技术</strong>，使得CPU密集型应用中在虚拟机中的性能已经足以跟本机性能媲美，但依旧出现了<strong>容器技术</strong>，在快速启动的易于使用方面对虚拟机进行了改进。</p><p><strong>编程模型</strong>则使程序能够<strong>动态重新配置</strong>，让中间件在公有云和私有云之间迁移数据和计算，甚至是将计算移动到离数据源更近的地方，如IoT中的传感器网络。</p><p>云的可扩展性最终还是受各个<strong>组件</strong>（如计算、存储、相互联系）的扩展规模的限制。由Moore’s law 和 Dennard scaling可以推断，新的计算单元和用电量都将不再扩展，这直接影响了云的计算性能和成本。在这方面，需要研究CMOS（互补金属氧化物半导体）以外的新技术。类似的还有内存，DRAM（动态随机存取存储器）限制了成本和扩展，新的研究方向是非易失性技术，这些技术将在降低功耗的同时，进一步扩展负载存储操作内存。最后一个研究方向是<strong>光子互联</strong>，让所谓的硅光子通关光子连接传播到芯片中，改进性能、扩大规模、降低能耗。</p><blockquote><p>Service Level Agreement/SLA —— 服务协议级别<br>neuromorphic —— 神经形态<br>sequential deterministic algorithms —— 顺序确定性算法<br>asynchronous evolutionary algorithms ——非同步演化算法<br>approximation algorithms —— 近似算法<br>online/incremental algorithms —— 在线/增量算法<br>Complementary Metal-Oxide-Semiconductor —— CMOS —— 互补金属氧化物半导体<br>Dynamic Random-Access Memory —— DRAM —— 动态随机存取存储器</p></blockquote><h4 id="资源管理和调度"><a href="#资源管理和调度" class="headerlink" title="资源管理和调度"></a>资源管理和调度</h4><ul><li>大规模服务中的自动扩展和资源控制</li><li>多云操作和负载平衡</li><li>专门的多重控制循环设计</li><li>工作负载特征错误的敏感性</li><li>安全和资源管理的相互作用</li></ul><p>云数据中心有多达几十万的计算和存储设备，因此需要高效的资源管理和调度策略。当前的<strong>IaaS</strong>主要依赖两种<strong>虚拟机配置策略</strong>：<strong>静态</strong>和<strong>动态</strong>。静态策略使用<strong>装箱算法</strong>将固定数量的物理资源分配给虚拟机；动态则通过虚拟机<strong>实时迁移</strong>和其他负载平衡技术来处理负载的变化。这些策略可以是<strong>提前预测分配</strong>，也可以是<strong>监测后重新分配</strong>，但不管如何，都需要知道虚拟机资源的需求，可以是用户指定，也可以是通过监控数据进行预测</p><p>对于<strong>PaaS</strong>、<strong>SaaS</strong>供应商来说，资源管理方法可以帮助管理分配给分布式应用、容器、网络服务、微服务的资源的种类和数量。相关的策略有：1<strong>.自动扩展技术</strong>（基于当前和预测的负载动态扩展或收缩）2<strong>.资源节流技术</strong>（处理瞬时自动扩展中的工作负载突发、平滑和变化，和控制可抢占VM的使用）3.<strong>准入控制方法</strong>（处理高峰负载和高价值客户的负载优先级）4.<strong>服务编排和工作流调度</strong>（整理和编排工作负载，可能专门为特定领域设计，如科学领域中对成本和任务需求有限制的工作流，<a href="https://manuscript.elsevier.com/S0167739X15000059/pdf/S0167739X15000059.pdf" target="_blank" rel="noopener">参考文献</a>）5.<strong>多云的负载平衡</strong>（将应用的负载分布到多个云数据中心）。</p><p>其中的一个挑战是，当前的资源管理策略<strong>不适用</strong>于<strong>不精确的资管需求预测</strong>，因此需要新的权衡方法，在工作负载信息不精确的情况下，对策略<strong>最优性</strong>和<strong>稳健性</strong>之间进行权衡。当前的需求估计和工作负载预测方法在未来可能不适用，而机器学习和人工智能能否胜任有待研究。</p><p>另一个常见的问题是，资源管理策略<strong>专注于优化特定的度量指标和资源</strong>，缺少一个能在<strong>相同多重控制循环环境中共存</strong>的系统方法，使用户能公平的访问资源，以及对云堆栈各层在整体上实现最佳化（<a href="https://ieeexplore.ieee.org/abstract/document/6809354" target="_blank" rel="noopener">参考文献</a>）</p><p>当前的研究功能工作还缺少安全和资源管理之间的相互作用的风险问题</p><blockquote><p>provisioning policies —— 配置策略<br>bin-packing algorithms —— 装箱算法<br>resource throttling methods —— 资源节流技术<br>preemptible —— 抢占式的<br>service orchestration —— 服务编排<br>multiple control loops —— 多重控制循环</p></blockquote><h4 id="可靠性"><a href="#可靠性" class="headerlink" title="可靠性"></a>可靠性</h4><ul><li>导致大规模服务中断的故障关联</li><li>缺少整体服务可靠性模型</li><li>缺少自动的可靠性感知的服务管理机制</li><li>缺少故障感知的配置策略</li></ul><p>云数据中心的系统是高度相互关联和相互依赖的。由于云计算系统的规模、复杂性和相互依赖性，它们需要面对可靠性相关挑战，比如硬件故障、资源缺失故障、溢出故障、网络故障、超时故障、和环境改变引发的软件缺陷。有些故障会影响系统操作，连锁故障甚至会应发大规模服务中断。企业组织通常会采用严格的可靠性保证和还原能力。需要新的云服务供应方式，来保障性能和<strong>从能各种故障中恢复的能力</strong>。另一个挑战是云系统的<strong>可靠性</strong>和<strong>能耗</strong>之间的相互影响的研究。</p><p>云计算是<strong>面向服务</strong>的而不是面向资源的，所以分布式计算中保障可靠性的模型（如容错）不适和直接用于云计算系统。</p><p>云计算中相互关联的特征的范围，比如巨大的规模、服务共享模型、广域网络、软/硬件组件异质性，导致难以分析云计算系统的规模和可靠性的<strong>期望值</strong>。</p><p>现有许多研究对故障进行单独分析和解决，但都忽略了<strong>故障之间的相互影响</strong>。现存对的云计算环境中也缺少可靠性模型、自动的可靠性感知的服务管理机制，和故障感知配置策略</p><h4 id="可持续性"><a href="#可持续性" class="headerlink" title="可持续性"></a>可持续性</h4><ul><li>云数据中心的能源需求</li><li>虚拟机整合以最小化服务器的能耗</li><li>服务器之间数据流的最佳调度策略</li><li>基于机器学习的任务分配</li><li>能源与服务质量的权衡</li></ul><p>2017年世界上大约有850万云数据中心，它们每年的耗电量比大多数国家都多（除了美、中、俄、日）。ICT设施的耗电量接近世界总体耗电量的10%。但云和网络也有助于节能，比如智慧城市，或最大程度优化可再生和不可再生能源的混合使用。考<strong>虑能</strong>耗的同时还要考虑<strong>服务质量</strong>，比如在搜救领域就不能降低服务质量来减少能耗。</p><p>当前的主要工作是整合虚拟机（涉及资源管理）以减少能耗。但其他的基础设施，比如制冷系统（接近35%能耗）、网络等也需要适合的调度算法。</p><p>多核结构，新型的基于硬件的休眠启动控件、时钟速度管理技术，让服务器的能耗取决于瞬时工作负载。因此新的基于机器学习的方法能够动态<strong>分配</strong>任务到（云或雾的）多个服务器中，从而最少的违反SLA。整体技术也需要解决网络的服务质量，比如包延迟、远程访问云数据中心的网络能源效率问题。这些技术的目的都是为了提供一个能<strong>在线自动调整</strong>或自治的方法，使云系统的能耗和服务质量作为一个整体得到解决。</p><p>当前的实验研究表明，<strong>深度学习和神经网络</strong>能够按照规定的执行延迟、响应时间、系统吞吐量、和能耗对任务进行分配（<a href="https://spiral.imperial.ac.uk:8443/bitstream/10044/1/59726/2/ServerstateDetection.pdf" target="_blank" rel="noopener">参考文献</a>）。另一种方式涉及<strong>均衡能源供应</strong>，云数据中心可以调节自身能耗并以服务质量作为响应，根据供应的能源动态的修改处理器的可变时钟速率（<a href="https://ieeexplore.ieee.org/document/6903096" target="_blank" rel="noopener">参考文献</a>）。也有人建议使用混合使用可再生和不可再生能源</p><blockquote><p>Information and Communications Technology, ICT —— 信息通信技术<br>sleep-start controls —— 休眠启动控件<br>Holistic techniques —— 整体技术<br>rationing the energy supply —— 均衡能源供应</p></blockquote><h4 id="异质性"><a href="#异质性" class="headerlink" title="异质性"></a>异质性</h4><ul><li>虚拟机级别、供应商级别、硬件结构级别的异质性</li><li>虚拟机放置、供应配置和调度‘</li><li>采用供应商指定语言进行硬件加速</li></ul><p>因为云供应商需要不断更新硬件以满足用户需求，以及提高性能和效率，因此出现了云内在的异质性，反映在三个层面。</p><p><strong>虚拟机</strong>层面，原因是能够以<strong>多种方式和配置方法</strong>对同质的资源进行组织（或者接近同质的，比如相同的处理器族），比如N核的同质硬件处理器可以被组织为有任意核的虚拟机。<strong>供应商</strong>层面，原因是可以从<strong>多个云供应商</strong>中利用资源，不同的云供应商有不同的虚拟机监控程序和软件套件（通常出现在多重云环境中）。<strong>硬件结构</strong>层面，原因是<strong>同时利用</strong>CPUs和硬件加速器（如GPUs、FPGAs）。</p><p>第一重挑战是<strong>异质环境中的资源和工作负载管理</strong>。资源管理专注于以静态和动态的方式对虚拟机进行安置，综合考虑网络参数和能耗的本地调度或全局调度技术。工作负载管理则通过基准技术优化工作负载的安置的调度。基准技术的实践在虚拟机层面已经足够成熟，在供应商层面也正在发展（<a href="https://link.springer.com/article/10.1007/s10922-014-9307-7" target="_blank" rel="noopener">参考文献1</a> &amp; <a href="https://pureadmin.qub.ac.uk/ws/files/74475124/Varghese_IEEETCC.pdf" target="_blank" rel="noopener">参考文献2</a>），但在<strong>硬件结构层面对工作负载的性能预测</strong>还缺少研究。除此之外 ，当前对异质资源的资源管理和工作负载管理的研究也是分别进行的。当前还缺少对3个层面的异质性进行整合和管理的通用云平台。</p><p>第二重挑战关于<strong>应用软件的开发，使之兼容异质资源</strong>。当前大部分的加速器需要不同的编程语言（比如CUDA和OpenCL需要对GPU编程），导致云程序很难采用加速器。在IaaS中，开发者只能直接面对硬件环境进行编程，而SaaS、PaaS中，可以在中间件对硬件进行抽象。但在中间件提供对加速器硬件的抽象，则会减少优化性能的可能性。因此需要对性能和易用性进行权衡。在这方面的开放性挑战是开发与底层硬件无关的软件，并且可以基于可用硬件进行适应（<a href="https://ieeexplore.ieee.org/document/7495121" target="_blank" rel="noopener">参考文献</a>）</p><blockquote><p>homogeneous —— 同质的，同类的<br>heterogeneous —— 异质的<br>vendor —— 供应商<br>Hypervisor —— 虚拟机监控程序<br>Software suits —— 软件套件<br>Field Programmable Gate Arrays (FPGAs) —— 现场可编程门阵列<br>benchmarking techniques —— 基准技术</p></blockquote><h4 id="相互关联的云"><a href="#相互关联的云" class="headerlink" title="相互关联的云"></a>相互关联的云</h4><ul><li>云的相互操作性</li><li>安全性和服务质量的常见规则和标准</li><li>跨站点的虚拟网络</li><li>服务的最小公分母背后的相互操作性</li></ul><p>云供应商都各自把工作局限于自己的服务。云的相互操作性是各种类型的云和系统（如公有云、私有云）彼此相互了解的一种能力，了解的信息包括：系统接口、配置、验证和授权格式、数据格式、程序的初始化和定制化。</p><p>从更宽泛的角度来说，互连云有许多用于方法，用于整合不同的云供应商和数据中心的服务和功能。这些技术取决于互连云的参与者、它的目标、和提供给用户的服务整合的透明度（<a href="Interconnected Cloud Computing Environments: Challenges, Taxonomy, and Survey">参考文献</a>）</p><p>现有的云供应商虽然有专门的互操作机制，但并<strong>没有统一的标准和开源</strong>，因此有很大的局限性。当前的标准化工作有：OGF的OCCI、SNIA的CDMI、DMTF的CIMI和OVF、IEEE的互连云、NIST的联合云。但<strong>现存云服务的接口并没有被标准化，且很多云服务的提供商都使用不同的接口、格式和上下文配置机制</strong>。</p><p>广义上，如果各种云之间的互连是由供应商发起和管理的，这些方式可以被归为联合的云计算。<strong>联合云计算</strong>可以被看做是云计算发展的下一步，也是<strong>整合雾计算和边缘计算</strong>结构的下一步。联合云模型的好处有：资源优化、节约成本、敏捷资源交付、可扩展性、高可用性、商业连续性、地理分布</p><p>共享云之间的资源有2个原因，一是公司企业希望现有的内部基础设施能够<strong>最大程度的被使用</strong>，因此公司的私有云需要与公有云无缝集成；二是公司把的大部分的程序（没有隐私要求的）转移到公有云上，以此将程序的<strong>工作负载转移</strong>到云上，或放宽资源需求的限制。</p><p>最新的项目Aneka开发了中间件和库来整个不同的资源（如VM、数据库等），但也导致非最优的云程序或者只支持特定的服务模型</p><p>互操作性和便携性在不同的组件上有不同的考虑，包括接口规范、可移动的数据格式和应用、国际公认的服务质量和安全标准。如何以高效、透明的方式，通过跨站虚拟网络将本地云和外部供应商资源进行互连，实现云资源的供应、管理和配置，是普及该技术的重要挑战。</p><p>互连云服务的最小公分母是一个限制，如何突破这个限制，从而支持更丰富的云程序是其中的一个挑战。其他挑战还有：如何在多个供应商之间的授权、访问、账单方面进行协调；如何将互连云应用到雾计算等新兴趋势中。</p><blockquote><p>InterCloud —— interconnected Cloud —— 互连云<br>minimum common denominator —— 最小公分母</p><ul><li>Open Grid Forum’s (OGF) Open Cloud Computing Interface (OCCI)</li><li>Storage Networking Industry Association’s (SNIA) Cloud Data Management Interface (CDMI)</li><li>Distributed Management Task Force’s (DMTF) Cloud Infrastructure Man- agement Interface (CIMI)</li><li>DMTF’s Open Virtualization Format (OVF)</li><li>IEEE’s InterCloud</li><li>National Institute of Standards and Technology’s (NIST) Federated Cloud</li></ul></blockquote><h4 id="强化资源受限设备的自主权"><a href="#强化资源受限设备的自主权" class="headerlink" title="强化资源受限设备的自主权"></a>强化资源受限设备的自主权</h4><ul><li>移动云绑定模型——任务委托和代码分流</li><li>移动云的适应性问题</li><li>云中心的物联网</li><li>雾计算</li></ul><p>智能手机等移动设备，它们的电池、CPU、内存、存储等跟台式设备比是受限的，但可以通过外部的云资源减少这些限制。因此出现了移动云的概念。</p><p>在移动云上的主要研究包括<strong>任务委托</strong>和<strong>移动代码负担转移</strong>。任务委托是指，从多个云供应商中移动调用网络服务，因此涉及互操作性问题，解决方案是中间件。代码负担转移，则对应用程序进行配置和分区，并将资源密集型的方法函数转移到云实例的代理上（如Cloudlets/swarmlets）。相关的研究挑战有：如何开发理想的负担转移方式、如何识别资源密集型方法、如何学习合理的决策机制——兼顾设备上下文（如电池级别、网络连通性）和云上下文（如云代理的当前负载）</p><p>物联网演变为工业4.0和互联网4.0+，而云计算能够帮助存储和分布式处理物联网节点的数据。<strong>网络延迟</strong>是以云为中心的物联网模型的挑战之一。除此之外还有<strong>能耗</strong>问题，虽然可以通过可再生能源缓解，但却又引发了<strong>服务质量</strong>问题。</p><p><strong>雾计算</strong>是一个新兴的解决方案，它的优点包括边缘设备的安全、位置识别、敏捷开发、低延迟、成本和性能上的效率，但同时也是关键的挑战。</p><blockquote><p>task delegation —— 任务委托<br>mobile code offloading —— 移动代码负担转移<br>Cloudlet —— 小云<br>swarmlets —— 小集群</p></blockquote><h4 id="安全性和隐私"><a href="#安全性和隐私" class="headerlink" title="安全性和隐私"></a>安全性和隐私</h4><ul><li>基于编码的数据保护</li><li>选择性的信息共享</li><li>细粒度的访问</li><li>查询的机密性和完整性</li><li>基于安全性的云供应商原则</li></ul><p>涉及机密性、完整性、可用性。</p><p>在机密性方面，通常是在储存前在云供应商外部对数据进行编码，但这限制了云供应商的查询评估。解决方案之一是<strong>索引</strong>，使部分查询评估不需要对数据进行解码。索引是保存了部分数据属性的元数据，对索引的定义需要在精确性和隐私性方面取得平衡，<strong>精确的索引能提高查询性能，但会暴露数据信息</strong>。某些编码技术也支持直接对数据进行操作和评估，不需要解码。比如<strong>OPE</strong>和<strong>同态加密</strong>。一些加密的数据库系统支持<strong>对加密数据进行SQL查询</strong>。</p><p>一些基于云的程序（比如健康管理、社交服务等）会从多个数据源获得数据，而一些数据挖掘工具会因此挖掘到比预期更多的隐私数据，如何保护隐私性是一个挑战。对此的研究挑战是如何设计隐私保护的理论模型和实践机制。当前的研究趋势是<strong>采用机器学习分析大数据</strong>，包括威胁分析、攻击智能、病毒传播、数据关联等。</p><p>常用的保护措施是，隐私数据仅对通过加密登录的用户本身开放，但有时候需要选择性的公开一些数据给其他用户，常用的方法是：<strong>选择性加密</strong>和<strong>基于属性加密ABE</strong>。但选择性共享数据还要考虑到第三方合作共享和分布式计算的场景可能出现的问题。</p><p>有时候数据之间的关联比数据本身更加敏感，可以将数据拆分成不同部分并储存在不同的服务器中，但这会导致查询复杂度增加。</p><p>虽然<strong>选择性访问</strong>的问题已经被解决，但却会受到利用访问频率侵犯数据和用户隐私的攻击。解决方案是<strong>私有信息检索RIP技术</strong>，它涉及隐私保护索引技术：比如Oblivious RAM、B-tree结构、二分搜索树（<a href="https://ieeexplore.ieee.org/abstract/document/7830709" target="_blank" rel="noopener">参考文献</a>）。但该领域的实践性解决方案仍然是一个挑战。</p><p>关于完整性的技术有：数字签名、PDP、POR、将探测到的数据未授权修改存储在云供应商外部等。验证授权用户的数据的<strong>完整性</strong>只是其中一个方面。还有，由多用户共享数据的改变和查询引起的问题。相关的方法有确定性方法（使用认证的数据结构）和概率方法（完整性检查插入）（<a href="http://pdfs.semanticscholar.org/8cc0/0323e1907a0cf19561827fe4fa8047334e6f.pdf" target="_blank" rel="noopener">参考文献</a>），都可以代表有希望的方向，但所提供的适用性和完整性保证受到限制。</p><p>关于可用性，是如何让用户能够选择到满足其安全性需求的云供应商（云供应商的行为通常在SLAs中声明）。最近的研究有关于不同云服务特征的可能依赖的探索，但这只是第一步。</p><p>基于硬件的技术也可以保护云中的数据，最著名的是ARM TrustZone和 Intel SGX 技术。简单来说就是创建安全的执行环境。</p><p>高级持久性威胁APTs是一类新的网络攻击，特点是面向目标，高度针对性，组织合理，资金充裕，技术先进，隐秘且持久。目前缺乏足够的防御手段，以及减少损失的措施，如技术驱动或原则驱动的解决方案。</p><blockquote><p>Order Preserving Encryption —— OPE<br>fully (or partial) homomorphic encryption —— 全、半同态加密<br>selective encryption —— 选择性加密<br>attribute-based encryption (ABE) ——基于属性的加密<br>Private Information Retrieval (PIR) —— 私有信息检索<br>privacy-preserving indexing techniques —— 隐私保护索引技术<br>Oblivious RAM<br>Provable Data Possession —— PDP<br>Proof Of Retrievability —— POR<br>Software Guard Extensions —— SGX<br>Advanced Persistent Threats (APTs) —— 高级持久性威胁</p></blockquote><h4 id="云计算的经济"><a href="#云计算的经济" class="headerlink" title="云计算的经济"></a>云计算的经济</h4><ul><li>服务级别协议和策略管理</li><li>将内部的基础设施迁移到公有云供应商</li><li>选择合适的云供应商</li><li>云的许可模型</li></ul><p>近年来，云经济学的研究主题集中在许多关键方面：1.云服务的定价；2.代理机制（搜索符合用户预算的资源）；3.监视以确定是否满足用户要求（涉及SLAs），比如WS-Agreement之类的规范的实现。</p><p>云经济学涉及SLA，而SLA管理又与<u>计算资源、实例和服务</u>的供应和需求有关，在这方面有许多关于<u>基于原则的方法</u>和相关的<u>最优化策略</u>的研究（因为缺少资源适用场景）</p><p>另一个相关的方面是如何迁移公司内部的基础设施和IT部门到云供应商。比如迁移服务需要考虑服务后续如何使用，对业务能力的影响；迁移系统需要考虑是否会影响保留在企业内部的系统功能。其中IT部门应该起到中介者的角色。</p><p>上述背景引起了新技术的出现，比如基于容器的部署（无服务计算），使亚秒级计费成为可能，例如 Google “functions”，AWS Lambda。</p><p>使用许可是另一个问题，包括年度许可和永久许可。独立的软件供应商正在研究更适合云的许可模式，如<u>BYOL</u>，<u>完全按需</u>等。</p><p>选择合适的云供应商是另一个挑战。比较不同的云供应商十分耗时，并且难以比较。有人提出，专门平台对各个云平台进行比较，帮助用户进行选择；还有关于市场模型的研究</p><blockquote><p>BYOL (bring your own license)<br>marketplace models —— 市场模型</p></blockquote><h4 id="应用部署和交付"><a href="#应用部署和交付" class="headerlink" title="应用部署和交付"></a>应用部署和交付</h4><ul><li>资源的可编程性</li><li>持续传递</li><li>敏捷传递带来的技术债务积累</li></ul><p>资源的可编程性，是开发者能够对基础设施和平台进行编程控制，带来的好处比如让程序能够自动扩展，使程序能够在运行时自动修复、优化等。关键的好处是能够加速产品更新的交付。实现的关键是敏捷交付工具和基于模型的编排语言（比如 Terraform，OASIS TOSCA）。这些工具有助于自动化生命周期管理，包括持续交付和持续集成，应用程序和平台配置以及测试。</p><p>平台可编程性，开发云上的程序时，可以帮助减少软件开发的复杂度。比如用户专注于Map、Reduce任务，由中间件负责容错、任务分配的工作。当前正在研究的编程模型，关注如何处理<strong>云平台的异质性</strong>，比如将程序分布于边缘计算中的各个异质节点。当前缺乏交付框架和编程模型，将程序部署在CDC和边缘节点。因而无法在云应用中使用异构硬件，也无法使用互连云操作。</p><p>另一个挑战是应用程序的发展，加速产品更新交付会影响程序的质量。当前缺少云软件工程的研究，将传统开发和敏捷开发的优点结合。比如记录云程序的所有发行版本的性能和可靠性数据，以便更好地指导产品更新，以及自动识别违反设计模式的行为，并在测试新功能期间探索假设场景</p><blockquote><p>CDC —— 云数据中心</p></blockquote><h4 id="数据管理"><a href="#数据管理" class="headerlink" title="数据管理"></a>数据管理</h4><ul><li>服务在管理元数据上的局限性</li><li>数据管理策略和规范</li><li>管理对延迟敏感的数据流</li><li>整合流和批量数据</li></ul><p>大数据平台有多种类型，如用于互联网和企业工作负载，采用批处理+NoSQL，如Apache Hadoop；用于物联网，处理分布式数据流，如Apache Storm。</p><p><u>处理元数据（定位和使用数据）的服务</u>对<u>存储数据的服务</u>的支持不够。数据的隐私问题。广域网的延迟较高，从而影响物联网设备对低延迟处理的需求（出现边缘计算和雾计算）。数据中心里各个虚拟机之间的带宽和网络延迟，也会导致瓶颈和影响延迟敏感的数据流的处理。需要的解决方案包括，<strong>软件定义网络</strong>SDN，和<strong>网络功能虚拟化</strong>NFV。</p><p>还需要对Lambda结构的研究，以便在休息和运行时都能处理数据。Apache Flink和Spark Streaming 提供了一些早期方案。大数据系统对在弹性云上自动扩展和收缩的支持不够。</p><blockquote><p>Software Defined Networking (SDN)<br>Network Functions Virtualization (NFV)</p></blockquote><h4 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h4><ul><li>高能耗和缺少能源的对称性</li><li>缺少对服务质量的保证</li><li>多重租赁和可扩展性问题</li></ul><p>近年关于云网络的研究有：SDN和NFV，用于构建敏捷、灵活的可编程计算机网络，减少运营支出。还有关于扩展限制、平面空间地址、和服务的过度订阅等问题的研究，促进了一些网络结构的产生，比如VL2, PortLand, and BCube。</p><p>关于网络的挑战之一是如何使<strong>能耗与负载成比例</strong>。大多数网络组件，比如交换机、路由器等硬件本身不支持节能的功能，比如没有通信时休眠，低流量时段的链路速率调整等。</p><p>另一个挑战则关于服务质量的保证。因为没有实现<strong>性能隔离</strong>的机制，导致SLAs没有对比如带宽和延迟的保证。当前的研究有通过网络抽象层VDC<strong>对虚拟机带宽的保证</strong>（<a href="https://dl.acm.org/doi/abs/10.1145/1921168.1921188" target="_blank" rel="noopener">参考文献</a>），但没有<strong>对延迟的保证</strong>。</p><p>在<strong>混合云环境中</strong>部署虚拟集群时，虽然可以通过虚拟化技术解决资源的网络连接问题，但云提供商无法像在其自己的数据中心中那样获得对核心Internet设备的特权访问。因此，云提供商在路由和流量工程方面的灵活性在很大程度上受到限制，<strong>网络性能缺少保证</strong>。</p><p>此外，与专用的数据中心网络相比，诸如Internet之类的公用网络的性能更加不可预测和易变，这使得更难以提供有保证的性能要求。传统的WAN方法，例如用于此类网络中流量工程的多协议标签交换MPLS，由于缺乏网络全局视图，因此在带宽使用和处理对延迟敏感的流量方面也效率不高（<a href="https://dl.acm.org/doi/abs/10.1145/2486001.2486012" target="_blank" rel="noopener">参考文献</a>）。 </p><p>由于现代云数据中心的网络规模很大，因此它也同样面临着和互联网相似的问题，比如VLAN的限制，VXLAN在多播种的限制，IPV4的限制等。</p><blockquote><p>Multi-Protocol Label Switching (MPLS) —— 多协议标签转换</p></blockquote><h4 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h4><ul><li>HCI和分布式系统社区的差距</li><li>基础设施和服务的封装</li><li>生产力工具</li></ul><p>可用性是降低组织探索云服务和基础架构成本的关键因素，因为用户可以拥有更好的服务质量并提高生产力，从而减少人工支出。</p><p>云的可用性被NIST的可用性框架中突出为5个方面：能力、个人、可靠、安全、价值（<a href="https://link.springer.com/chapter/10.1007/978-3-319-20376-8_59" target="_blank" rel="noopener">参考文献</a>）。能力，与满足云消费者对云服务功能的期望有关。 个人，是允许用户和组织更改用户界面的外观和风格并自定义服务功能。 可靠，安全和价值，是与使系统在状态条件下安全、受保护地执行其功能，并分别将价值（结果）返回给用户。</p><p>对于可用性，当前的工作主要集中在将复杂的服务封装到API中，以方便用户使用，比如HPC云，研究者一直在创建服务来公开HPC应用程序，以简化其使用。</p><p>另一个方向是DevOps，它的目标是将开发（Dev）和操作（Ops）集成在一起，从而帮助更快地交付软件。在云环境中创建和部署解决方案时，DevOps提高了开发人员和运营商的生产力。 不仅要在云中构建新的解决方案，而且要简化从内部部署环境到多租户弹性云服务的旧软件迁移。</p><blockquote><p>capable, personal, reliable, secure, and valuable<br>High Performance Computing (HPC) —— 高性能计算</p></blockquote><h3 id="新兴的趋势和影响范围"><a href="#新兴的趋势和影响范围" class="headerlink" title="新兴的趋势和影响范围"></a>新兴的趋势和影响范围</h3><h4 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h4><p>Docker的诞生引起了各界对容器技术的关注。</p><p>容器依赖于现代Linux的内核设施，比如 cgroups, LXC (Linux containers) and libcontainer。Docker使用Linux核心的cgroups和命名空间来运行独立的容器。cgroups提供资源的隔离（如CPU、内存、网络、block I/O）。命名空间从程序的角度隔离操作环境（包括进程树、网络、用户ID、挂载文件系统）。libcontainer库作为<u>容器引用实现</u>。并将程序和相关依赖打包到容器镜像中。</p><p>容器技术在行业中的普及，促进了对容器即服务（CaaS）的需求，比如UberCloud。</p><p>容器的两大特点，一是启动速度快，甚至能低于1秒；二是容器对内存的占用量很小，消耗的资源很少。</p><p>容器的缺点是由于共享内核，因此隔离和安全比VM差（这是其中一个研究热点）。解决该问题的可能方案之一是<strong>硬件支持</strong>，比如Intel SGX的受信执行支持；二是使用Unikernel，是一种库操作系统。</p><p>容器技术的挑战是如何最优化容器性能，比如<strong>Slack技术</strong>对存储驱动最佳化，来加速容器启动。还有基于用户服务质量需求的容器集群管理，比如容器集群管理系统，Kubernetes，Mesos 和 Swarm。</p><blockquote><p>mounted file systems —— 挂载文件系统<br>container reference implementation —— 容器引用实现<br>trusted execution support of Intel SGX</p></blockquote><h4 id="雾计算"><a href="#雾计算" class="headerlink" title="雾计算"></a>雾计算</h4><p>雾计算是传统云计算模型的扩展。雾计算包括3个方面，一是使路由节点（如移动基站、网关、路由器等）执行通用目的计算；二是为路由节点添加计算能力，对传输数据进行处理；三是结合前2者。</p><p>好处之一是<strong>减少延迟</strong>，改进流式应用和实时应用的服务质量。二是<strong>无缝支持移动性</strong>，可以启用用户设备和计算服务器之间的无线访问，并可以组织可伸缩的控制系统。这些好处都适用于IoT应用。</p><p>雾计算和边缘计算的不同在于，<strong>边缘计算</strong>将计算能力提供给了IoT设备本身，而<strong>雾计算</strong>的计算节点（Dockers、VMs）则是靠近数据源。<strong>边缘计算需要IoT设备有执行代码和通信的能力，问题在于这样的接口并没有被所有的IoT设备采用</strong>。因此，雾计算似乎是迄今为止唯一可行/通用的解决方案。</p><p>雾计算尽管不能完全作为CDC，但也提供完整的IaaS，PaaS和SaaS资源堆栈。它的主要好处在于能减少延迟，预计每个城市只需要少数几个雾数据中心。从商业角度，还能使用私有云或独立的雾供应商的基础设施作为雾节点。对于<strong>移动边缘计算</strong>，它基于移动蜂窝网络，而不经过传统雾计算的路由节点</p><p>雾计算的优点包括，应用在不同计算层之间的<strong>垂直扩展性</strong>。它允许对<strong>传输数据进行提前处理</strong>，从而只有必要的流量会被发送到云数据中心。<strong>工作负载</strong>也可从云中分解下发到雾节点上，或者从边缘节点向上迁移到雾节点。在雾节点中可以使用更轻量的<strong>容器</strong>代替虚拟机。</p><h4 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h4><h4 id="无服务计算"><a href="#无服务计算" class="headerlink" title="无服务计算"></a>无服务计算</h4><h4 id="软件定义的云计算"><a href="#软件定义的云计算" class="headerlink" title="软件定义的云计算"></a>软件定义的云计算</h4><h4 id="区块链"><a href="#区块链" class="headerlink" title="区块链"></a>区块链</h4><h4 id="机器学习和深度学习"><a href="#机器学习和深度学习" class="headerlink" title="机器学习和深度学习"></a>机器学习和深度学习</h4><h3 id="相关术语"><a href="#相关术语" class="headerlink" title="相关术语"></a>相关术语</h3><p>&gt;</p><blockquote><p>non-volatile technologies —— 非易失性技术<br>Ad-hoc —— 特设的<br>offloading —— 分流<br>proportionality —— 对称性</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;云计算和按需付费模型的出现，让用户可以随时随地获得基于订阅的服务。这带来的好处包括：更短的启动时间；创建可扩展的全球企业程序；给科学计算和高性能计算带来更好的成本价值关联；以及为无处不在的普适程序带来不同的调用/执行模型。&lt;/p&gt;
&lt;p&gt;另一方面，无服务计算、软件定义网络、物联网、边缘计算等新技术为云计算带来了机遇，但也同时带来了新的挑战，对新方法和研究策略的需求。对于解决可扩展性、灵活性、可靠性、安全性、可持续性等问题的模型，也需要重新进行评估。&lt;/p&gt;
&lt;p&gt;该文献将定义云计算中的主要的开放性挑战，调查最新的解决方案和它们的局限。接着讨论新兴的趋势和影响范围，以及它们如何推动未来云计算的挑战。据此再进一步讨论云计算的未来，并指出下一个十年的研究方向。&lt;/p&gt;
    
    </summary>
    
    
      <category term="读书笔记" scheme="https://liaoooyx.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="云计算" scheme="https://liaoooyx.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="云计算" scheme="https://liaoooyx.com/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
  </entry>
  
  <entry>
    <title>云计算大纲</title>
    <link href="https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/00%20%E4%BA%91%E8%AE%A1%E7%AE%97%E5%A4%A7%E7%BA%B2/"/>
    <id>https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/00%20%E4%BA%91%E8%AE%A1%E7%AE%97%E5%A4%A7%E7%BA%B2/</id>
    <published>2020-03-27T00:00:00.000Z</published>
    <updated>2020-03-27T16:34:07.615Z</updated>
    
    <content type="html"><![CDATA[<ol><li>分布式系统模型和支持技术</li><li>云计算–体系结构，服务，模型，用例</li><li>公共云和私有云。 资源管理</li><li>集群和数据中心的虚拟机和虚拟化</li><li>虚拟基础架构管理：OpenNebula和Openstack</li><li>云调度</li><li>容器化和Kubernetes</li><li>云编程和软件环境</li><li>云中间件和配置管理</li><li>大数据。 Mapreduce和Hadoop</li><li>服务水平协议</li><li>云经济</li><li>能源效率</li><li>安全与信任</li><li>无处不在的云和物联网</li><li>云支持：边缘计算，虚拟化/单核，工业4.0，无服务器架构</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;分布式系统模型和支持技术&lt;/li&gt;
&lt;li&gt;云计算–体系结构，服务，模型，用例&lt;/li&gt;
&lt;li&gt;公共云和私有云。 资源管理&lt;/li&gt;
&lt;li&gt;集群和数据中心的虚拟机和虚拟化&lt;/li&gt;
&lt;li&gt;虚拟基础架构管理：OpenNebula和Openstack&lt;/li&gt;
      
    
    </summary>
    
    
      <category term="云计算" scheme="https://liaoooyx.com/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
  </entry>
  
  <entry>
    <title>云计算的新方向1</title>
    <link href="https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/17%20IoT%E7%89%A9%E8%81%94%E7%BD%91/"/>
    <id>https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/17%20IoT%E7%89%A9%E8%81%94%E7%BD%91/</id>
    <published>2020-03-27T00:00:00.000Z</published>
    <updated>2020-04-01T15:50:31.883Z</updated>
    
    <content type="html"><![CDATA[<p>云计算、物联网、社交网络影响着整个服务行业，也因此关系着未来互联网的演变和全球的经济。</p><p>云的生态系统需要普适性、高效性、安全性、用户接受性和值得信赖。</p><p>云是塑造未来互联网的关键：物联网和社交网络正参与着商业、政府、教育、娱乐等的各个方面</p><p><strong>《BIG SWITCH》描述了21世纪初出现的转变：</strong></p><p>更强大的电脑；无限的存储；高带宽的网络和普遍的连接（TB级的网络、宽带无线移动）；行业竞相建立大型数据中心（容量）；虚拟化有助于实现规模经济</p><p><strong>未来的网络开发存在以下技术挑战：</strong></p><p>可编程的网络结构；合并互联网、移动网络、和TV网络；基于TCP/IP的实名数据网络；智能路由和内容分布；加强安全和隐私保护</p><a id="more"></a><h4 id="云在未来互联网和社交网络中的角色"><a href="#云在未来互联网和社交网络中的角色" class="headerlink" title="云在未来互联网和社交网络中的角色"></a>云在未来互联网和社交网络中的角色</h4><p>在未来，云将会是提供网络服务的基础。未来的互联网不仅包含人和机器，还包括任何的对象或物体（物联网）</p><p>物联网的兴起：物理网应用程序必须最大化使用云，以便动态的处理和存储大规模的数据</p><p>云、物联网和社交网络正在重塑人类之间的关系，影响我们的日常生活，并且影响着全球的经济、政治系统</p><h4 id="物联网究竟意味着什么"><a href="#物联网究竟意味着什么" class="headerlink" title="物联网究竟意味着什么"></a>物联网究竟意味着什么</h4><p>Kevin Ashton将“物联网”描述为一个系统，它通过无处不在的传感器将物理世界和互联网联系在一起</p><blockquote><p>无处不在的传感器：手机、汽车、房间、门、床、椅子、建筑等任何物体</p></blockquote><h4 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h4><p>所有的传感器和控制端都在不断产生数据。通常这些数据是有用且私密的。因此需要一个系统来使这些设备相互沟通、管理数据，并加强适当的访问控制</p><p>而所有的通信、管理、访问控制技术，都是应用在大规模的设备网络上，因此必须是<u>可大规模扩展的</u></p><h4 id="开放协议"><a href="#开放协议" class="headerlink" title="开放协议"></a>开放协议</h4><p>当前的互联网和软件的解决方案有：</p><ul><li>接口 API：高度模块化</li><li>云：高度的分布式</li><li>面向服务的体系结构 SOA：高度解耦</li></ul><h4 id="物联网的维度"><a href="#物联网的维度" class="headerlink" title="物联网的维度"></a>物联网的维度</h4><p>任何时间相连：移动时、户内户外、白天晚上</p><p>任何地点相连：移动时、户外、户内（不在电脑上）、电脑上</p><p>任何物体相连：电脑之间、人与人（不使用电脑）、人与物（使用通用设备）、物与物</p><h4 id="无线传感器的角色"><a href="#无线传感器的角色" class="headerlink" title="无线传感器的角色"></a>无线传感器的角色</h4><p>无处不在的计算将促进各种各样的无线应用程序，包括监控宠物和家里的植物、控制程序、追踪书籍和单车等</p><h4 id="物联网的结构"><a href="#物联网的结构" class="headerlink" title="物联网的结构"></a>物联网的结构</h4><p>应用层：商品追踪、环境保护、智能搜索、远程医疗、智能交通、智能家居</p><p>网络层：云计算平台 —— 移动电信网、物联网、信息网</p><p>服务层：射频识别技术（射频标签）、传感器网络（节点）、GPS（公路地图）</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd900m538xj311e0l80x3.jpg" alt="截屏2020-03-27 下午5.27.30" style="zoom:50%;" /></p><h4 id="概念图：基于云的物联网"><a href="#概念图：基于云的物联网" class="headerlink" title="概念图：基于云的物联网"></a>概念图：基于云的物联网</h4><p>无缝连接/无处不在的访问 —— 云计算 —— 基于云的物联网</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd9098ew80j30og0ie0vt.jpg" alt="截屏2020-03-27 下午5.35.49" style="zoom:50%;" /></p><h4 id="本地的分布式云"><a href="#本地的分布式云" class="headerlink" title="本地的分布式云"></a>本地的分布式云</h4><p>公有云：公开资源管理、服务质量管理、服务创新、准入控制</p><p>网络：地点管理、服务呈现、计费、身份管理、服务支持功能</p><p>本地云：本地资源管理、公有云交互</p><p>物体：资源请求、资源呈现</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd90e2iwt8j30kq0j8tds.jpg" alt="截屏2020-03-27 下午5.40.26" style="zoom:50%;" /></p><h4 id="射频识别技术-RFID"><a href="#射频识别技术-RFID" class="headerlink" title="射频识别技术 RFID"></a>射频识别技术 RFID</h4><blockquote><p><a href="https://baike.baidu.com/item/%E5%B0%84%E9%A2%91%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF/9524139" target="_blank" rel="noopener">百度百科</a>：无线射频识别技术通过<a href="https://baike.baidu.com/item/无线电波/942435" target="_blank" rel="noopener">无线电波</a>不接触快速信息交换和存储技术，通过无线通信结合数据访问技术，然后连接数据库系统，加以实现非接触式的双向通信，从而达到了识别的目的，用于数据交换，串联起一个极其复杂的系统。在识别系统中，通过电磁波实现电子标签的读写与通信。根据通信距离，可分为近场和远场，为此读/写设备和电子标签之间的数据交换方式也对应地被分为负载<a href="https://baike.baidu.com/item/调制/4803375" target="_blank" rel="noopener">调制</a>和反向散射调制。</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd90svv6dzj311y0j8dlx.jpg" alt="截屏2020-03-27 下午5.54.38" style="zoom:50%;" /></p><h5 id="应用场景：物流分配中心"><a href="#应用场景：物流分配中心" class="headerlink" title="应用场景：物流分配中心"></a>应用场景：物流分配中心</h5><ol><li>通过RFID指示包裹的输送方向</li><li>通过RFID读取仓库中的库存或在运输中的包裹，同步到系统上，从而与供应链同步</li><li>通过RFID识别集装箱内的包裹，更新库存</li></ol><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd914qqp3tj30zw0k8qp8.jpg" alt="截屏2020-03-27 下午6.06.03" style="zoom:50%;" /></p><h4 id="无线网络——支持普适计算"><a href="#无线网络——支持普适计算" class="headerlink" title="无线网络——支持普适计算"></a>无线网络——支持普适计算</h4><blockquote><p><a href="https://baike.baidu.com/item/%E6%99%AE%E9%80%82%E8%AE%A1%E7%AE%97" target="_blank" rel="noopener">百度百科</a>：<strong>普适计算</strong>（Ubiquitous computing（ubicomp）、pervasive computing），又称<strong>普存计算</strong>、<strong>普及计算</strong>、<strong>遍布式计算</strong>、<strong>泛在计算</strong>，是一个强调和环境融为一体的计算概念，而<a href="https://baike.baidu.com/item/计算机/140338" target="_blank" rel="noopener">计算机</a>本身则从人们的视线里消失。在普适计算的模式下，人们能够在任何时间、任何地点、以任何方式进行信息的获取与处理。</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd91bg1jhpj310y0fw12e.jpg" alt="截屏2020-03-27 下午6.12.32"></p><h4 id="ZigBee-结构"><a href="#ZigBee-结构" class="headerlink" title="ZigBee 结构"></a>ZigBee 结构</h4><p>目的：监控和控制；电池：3个月-3年；网络数量：无限 ；带宽：20-150KB；范围：1-100+米；系统资源：4-32K</p><ul><li>全功能设备 FFD —— <ul><li>协调器 (ZigBee Coordinator, ZC)：<ul><li>一个ZB网络只需要1个协调器，发起网络</li><li>作为 802.15.4 2003 协议的协调器</li><li>当网络成型后，也能作为路由器</li></ul></li><li>路由器 (ZigBee Router, ZR)<ul><li>可选的组件，辅助ZC，对消息进行多跳路由</li></ul></li></ul></li><li>缩减功能设备 RFD<ul><li>终端设备 (ZigBee End Device, ZED)<ul><li>可选的网络组件</li><li>不参与路由</li></ul></li></ul></li></ul><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd91m4qv31j30o60gwwjc.jpg" alt="截屏2020-03-27 下午6.22.47" style="zoom:50%;" /></p><h4 id="物联网中的云和大数据，5C-5ANY"><a href="#物联网中的云和大数据，5C-5ANY" class="headerlink" title="物联网中的云和大数据，5C+5ANY"></a>物联网中的云和大数据，5C+5ANY</h4><p>数据：存储在云中，跟随着用户和用户的设备，可随时随地访问，可被其他人共享</p><p>5C：Convergence、Contents、Computing、Communication、Connectivity</p><p>5Any：Any Time、Any Where、Any Service、Any Network、Any Object</p><h4 id="相关名词"><a href="#相关名词" class="headerlink" title="相关名词"></a>相关名词</h4><blockquote><p>Telecom —— 电信<br>RFID: Radio Frequency Identification Technology —— 射频识别技术<br>Antenna —— 天线</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;云计算、物联网、社交网络影响着整个服务行业，也因此关系着未来互联网的演变和全球的经济。&lt;/p&gt;
&lt;p&gt;云的生态系统需要普适性、高效性、安全性、用户接受性和值得信赖。&lt;/p&gt;
&lt;p&gt;云是塑造未来互联网的关键：物联网和社交网络正参与着商业、政府、教育、娱乐等的各个方面&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;《BIG SWITCH》描述了21世纪初出现的转变：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;更强大的电脑；无限的存储；高带宽的网络和普遍的连接（TB级的网络、宽带无线移动）；行业竞相建立大型数据中心（容量）；虚拟化有助于实现规模经济&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;未来的网络开发存在以下技术挑战：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可编程的网络结构；合并互联网、移动网络、和TV网络；基于TCP/IP的实名数据网络；智能路由和内容分布；加强安全和隐私保护&lt;/p&gt;
    
    </summary>
    
    
      <category term="云计算" scheme="https://liaoooyx.com/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="IoT" scheme="https://liaoooyx.com/tags/IoT/"/>
    
      <category term="物联网" scheme="https://liaoooyx.com/tags/%E7%89%A9%E8%81%94%E7%BD%91/"/>
    
  </entry>
  
  <entry>
    <title>云计算的新方向2</title>
    <link href="https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/18%20%E4%BA%91%E8%AE%A1%E7%AE%97%E7%9A%84%E6%96%B0%E6%96%B9%E5%90%91/"/>
    <id>https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/18%20%E4%BA%91%E8%AE%A1%E7%AE%97%E7%9A%84%E6%96%B0%E6%96%B9%E5%90%91/</id>
    <published>2020-03-27T00:00:00.000Z</published>
    <updated>2020-04-01T18:29:40.713Z</updated>
    
    <content type="html"><![CDATA[<p>概述：</p><ol><li>回顾在物联网环境下，云计算的发展方向</li><li>为了阻止来自物联网的数据泛滥，在远程设备上采用智能本地数据处理成为关键：雾计算、边缘计算</li><li>本地数据处理中的虚拟化问题：以微服务和unikernels为例</li><li>工业4.0和智能工程</li></ol><a id="more"></a><h4 id="物联网家具：设备的发展前景"><a href="#物联网家具：设备的发展前景" class="headerlink" title="物联网家具：设备的发展前景"></a>物联网家具：设备的发展前景</h4><p>灯泡、冰箱、摄像头、手表、音响、显示器、扫地机器人等</p><h4 id="物联与智能产品：飞利浦照明"><a href="#物联与智能产品：飞利浦照明" class="headerlink" title="物联与智能产品：飞利浦照明"></a>物联与智能产品：飞利浦照明</h4><p>用户可以通过手机调节灯泡的亮度，调节开关；通过编程让它们：当发现进入者时闪烁，到晚上时变得昏暗</p><h3 id="雾计算"><a href="#雾计算" class="headerlink" title="雾计算"></a>雾计算</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>物联网应用和设备在持续激增，而旧的数据仓库模型：无法跟上物联网设备创建数据的速度和体积，也无法满足用户对低延迟响应时间的要求。但将数据发送到云上进行分析同样会带来风险：比如数据拥堵，安全问题等。网络数据传输的增长会导致数据拥堵的问题，而新的商业模型要求数据分析的时间少于1分钟（在某些情况下甚至要少与1秒）</p><h4 id="雾计算——思科架构"><a href="#雾计算——思科架构" class="headerlink" title="雾计算——思科架构"></a>雾计算——思科架构</h4><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdeq44w8ybj30tq0ca7cv.jpg" alt="截屏2020-04-01 下午5.18.16" style="zoom:50%;" /></p><p>雾平台：在网络边缘布置的密集型计算结构</p><p>特点：低延迟、位置感知、可通过无线访问使用</p><p>优点：实时分析、优化安全性</p><p>例子：</p><ol><li>智能交通信号灯系统，可基于当前的交通监控状况改变它的信号</li><li>数据可以发送到云端，用于长期分析</li></ol><p>在许多行业中，术语<u>边缘计算</u>和<u>雾计算</u>是可交互使用的，它们都涉及将<u>智能（计算处理数据的能力）</u>下发到离数据源更近的地方（泵、传感器、发动机、继电器），它们的根本区别在于<u>智能</u>到底安置在哪：</p><ul><li>雾：将<u>智能</u>发送到网络结构中的<u>局域网级别</u>，在雾节点或物联网网关中处理数据</li><li>边缘：将<u>智能、处理能力、通信能力</u>发送到边缘网关，或直接应用在设备本身（如可编程的自动化控制器 PACs）</li></ul><h3 id="边缘计算"><a href="#边缘计算" class="headerlink" title="边缘计算"></a>边缘计算</h3><p>在该结构中，数据可被处理，包括监控、分析、去重、缓存。</p><p>在该结构中，还需要考虑4个问题：1. 带宽，2. 网络能源，3.吞吐量，4. 数据存储；其他的开放新问题包括：</p><ol><li>便携性</li><li>能源效率</li><li>硬件结构的异构性</li><li>安全性虚</li><li>虚拟化</li></ol><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdeqp0e6pzj30no0ni7b8.jpg" alt="截屏2020-04-01 下午5.38.22" style="zoom:50%;" /></p><h4 id="1-可移动的边缘计算-Mobile-Edge-Computing-MEC"><a href="#1-可移动的边缘计算-Mobile-Edge-Computing-MEC" class="headerlink" title="1. 可移动的边缘计算 Mobile Edge Computing, MEC"></a>1. 可移动的边缘计算 Mobile Edge Computing, MEC</h4><p>在蜂窝网络或任何网络的边缘，启用云计算能力和通信技术服务环境的，一种网络结构。它的基本思想是与边缘计算和雾计算类似，即在接近蜂窝用户的地方运行程序和处理相关任务，从而缓解网络拥堵，提高性能。云不直接接收用户的数据，而是接收经过MEC节点处理后的少量数据。</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gder2aip6dj30ts0l2dt4.jpg" alt="截屏2020-04-01 下午5.51.06" style="zoom:50%;" /></p><h4 id="2-低能耗计算案例"><a href="#2-低能耗计算案例" class="headerlink" title="2. 低能耗计算案例"></a>2. 低能耗计算案例</h4><p>该技术的关键在于如何使<u>本地处理数据的智能设备</u>使用最少的能源。目前，<u>低功耗和低能耗</u>仍然是物联网连接的智能对象的挑战。</p><p><u>性能</u>的表现由，除了速度之外的，非功能性部分组成，比如：能耗、可靠性、时间需求等</p><p>能源效率应该从三个方面考虑：</p><ol><li>系统级别：比如使用本地计算，而不是将数据传输到外部；通信是能源浪费的主要因素</li><li>设备级别：考虑到设备的异质性，使用在节能的结构</li><li>语言级别：避免数据通信，确保数据的本地性</li></ol><h4 id="3-硬件结构的异质性"><a href="#3-硬件结构的异质性" class="headerlink" title="3. 硬件结构的异质性"></a>3. 硬件结构的异质性</h4><p><u>异质的并行化结构</u>已经收到了相当大的关注，它的好处在于能够高效的运行程序和传递服务，并且在一个系统中组合了不同种类的处理器，从而优化了绝对性能和降低能耗</p><p>于是出现了新的平台，它们将多核CPUs、多核GPUs，和一系列的附加设备合并为一个单独的解决方案。它们的特点是高度的多样化，在混合的环境中操作，以及使用环境十分广泛（从超级计算机到个人智能手机）</p><h4 id="4-安全问题"><a href="#4-安全问题" class="headerlink" title="4.安全问题"></a>4.安全问题</h4><p>将物理网设备中的敏感数据（医疗数据、个人跟踪数据、视频、财务数据等）从数据源（家庭、企业等）中发送出去，可能会导致隐私泄露、声誉受损、数据盗窃等问题。除此之外还需要考虑传输成本，如带宽消耗、处理成本、存储成本。</p><p>解决方案应该专注于保护设备、网络和使用时的安全：物理层的安全性、设备保护、密码保险、泄露预防、基础设备的安全性、数据传输时的安全性、平台安全性</p><h4 id="5-虚拟化：以微服务为例"><a href="#5-虚拟化：以微服务为例" class="headerlink" title="5. 虚拟化：以微服务为例"></a>5. 虚拟化：以微服务为例</h4><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdes9a0hvfj30wq0g8acv.jpg" alt="截屏2020-04-01 下午6.32.26" style="zoom:50%;" /></p><p>微服务是一个结构模型，它以服务为粒度，将其拆分为多个分布的单元（小的服务），多个自治的服务相互合作，各个服务之间相互解耦，并且通过接口和协议（如HTTP）进行访问</p><h5 id="部署选项"><a href="#部署选项" class="headerlink" title="部署选项"></a>部署选项</h5><p>微服务可以是从<u>需要专用硬件</u>到<u>仅仅是软件包</u>。其中部署在容器上（如Docker）是在效率和管理方面都比较理想的选择（包含虚拟机的大部分优点，但比虚拟机的损耗更低）</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdesj02pl5j30eg0m2di1.jpg" alt="截屏2020-04-01 下午6.41.48" style="zoom:33%;" /></p><h5 id="以-Unikernels-独立核心为例"><a href="#以-Unikernels-独立核心为例" class="headerlink" title="以 Unikernels 独立核心为例"></a>以 <a href="http://dockone.io/article/855" target="_blank" rel="noopener">Unikernels</a> 独立核心为例</h5><p>Unikernel简单来说就是<strong>删除应用与硬件中间多余的部分，只保留运行程序所需的最小依赖的库和栈模块的操作系统镜像</strong>。</p><p>由于Unikernel只实现了传统操作系统中的最低限度功能，因此极度轻量，允许在日常硬件上实现高密度部署。Unikernel还可以运行自己的<u>服务</u>，这些服务在需求出现时诞生，并在需求消失后立即消失，其中一些短暂的<u>微服务</u>的寿命可能以秒为单位，甚至是几分之一秒。Unikernel是即时计算服务，仅在有工作要做时存在，因此可以最大限度地利用计算基础架构。</p><p>但是当应用和配置需要更新，我们需要重新编译你的源码来生成新的Unikernel并部署新版本。如果是新的安全升级，也同样需要重新编译和部署。</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gdet1tpmvmj30tu0fggts.jpg" alt="截屏2020-04-01 下午6.59.54" style="zoom:50%;" /></p><h3 id="工业4-0"><a href="#工业4-0" class="headerlink" title="工业4.0"></a>工业4.0</h3><p>在工业4.0中，各个行业中的计算机和自动化将以全新的方式融合在一起，比如机器人远程连接到具备机器学习算法的计算机系统，而机器学习算法只需很少的人工操作即可学习和控制机器人。</p><p>工业4.0引入了<u>智能工厂</u>的概念，其中,<u>网络物理系统</u>监视工厂的物理上处理，并做出非中心化的决策</p><p>物理系统成为物联网，通过无线网络，实时地，在系统间相互通信，并与人类进行协作。</p><h4 id="工业4-0的六大设计原则"><a href="#工业4-0的六大设计原则" class="headerlink" title="工业4.0的六大设计原则"></a>工业4.0的六大设计原则</h4><ul><li><p>互操作性：<u>网络物理系统</u>（即工件载体，装配站和产品）、人类和智能工厂通过物联网相互连接和通信的能力</p></li><li><p>虚拟化：通过将传感器数据（来自监视物理上的处理过程）与虚拟工厂模型和仿真模型进行连接，以此创建的<u>智能工厂的虚拟副本</u></p></li><li><p>去中心化：智能工厂内的<u>网络物理系统</u>有自行决策的能力</p></li><li><p>实时功能：具有收集和分析数据并立即提供见解的能力</p></li><li><p>服务导向：通过<u>Internet of Services</u>提供（网络物理系统、人类和智能工厂的）服务</p></li><li><p>模块化：当对模块的需求发生改变时，智能工厂可以灵活地适应。</p></li></ul><h3 id="相关数据"><a href="#相关数据" class="headerlink" title="相关数据"></a>相关数据</h3><blockquote><p>pump——泵<br>motor——发动机<br>relay——继电器<br>energy efficient——节能<br>data-in-transit——传输中的数据<br>overhead——损耗<br>Cyber-Physical Systems —— 网络物理系统</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;概述：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;回顾在物联网环境下，云计算的发展方向&lt;/li&gt;
&lt;li&gt;为了阻止来自物联网的数据泛滥，在远程设备上采用智能本地数据处理成为关键：雾计算、边缘计算&lt;/li&gt;
&lt;li&gt;本地数据处理中的虚拟化问题：以微服务和unikernels为例&lt;/li&gt;
&lt;li&gt;工业4.0和智能工程&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="云计算" scheme="https://liaoooyx.com/categories/%E4%BA%91%E8%AE%A1%E7%AE%97/"/>
    
    
      <category term="IoT" scheme="https://liaoooyx.com/tags/IoT/"/>
    
      <category term="无处不在的云" scheme="https://liaoooyx.com/tags/%E6%97%A0%E5%A4%84%E4%B8%8D%E5%9C%A8%E7%9A%84%E4%BA%91/"/>
    
      <category term="雾计算" scheme="https://liaoooyx.com/tags/%E9%9B%BE%E8%AE%A1%E7%AE%97/"/>
    
      <category term="MEC" scheme="https://liaoooyx.com/tags/MEC/"/>
    
      <category term="微服务的虚拟化 unikernels" scheme="https://liaoooyx.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E8%99%9A%E6%8B%9F%E5%8C%96-unikernels/"/>
    
      <category term="工业4.0" scheme="https://liaoooyx.com/tags/%E5%B7%A5%E4%B8%9A4-0/"/>
    
  </entry>
  
  <entry>
    <title>图形数据库 Neo4J</title>
    <link href="https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/13%20%E5%9B%BE%E5%BD%A2%E6%95%B0%E6%8D%AE%E5%BA%93-Neo4J/"/>
    <id>https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/13%20%E5%9B%BE%E5%BD%A2%E6%95%B0%E6%8D%AE%E5%BA%93-Neo4J/</id>
    <published>2020-03-20T20:04:14.000Z</published>
    <updated>2020-03-26T03:49:37.319Z</updated>
    
    <content type="html"><![CDATA[<p>NoSQL可以被分成4类：键值对存储（MapReduce）、面向列的数据库（如Google Big Table）、文档数据库（MongoDB）、图形数据库（如Neo4J）</p><p>图形数据库主要用于存储具有更多关联的数据，而传统的RDBMS对大量数据的遍历性能不佳</p><p>图形数据库适合数据元素之间的关系与数据本身同样重要的项目</p><blockquote><p>由Neo4j，Inc.开发的图形数据库管理系统。它的开发人员将Neo4j描述为具有本机图形存储和处理的ACID兼容事务数据库，根据DB-Engines排名，Neo4j是最受欢迎的图形数据库，并且总体上是第22位最受欢迎的数据库。</p></blockquote><a id="more"></a><h4 id="NoSQL的种类"><a href="#NoSQL的种类" class="headerlink" title="NoSQL的种类"></a>NoSQL的种类</h4><p>NoSQL可以被分成4类：键值对存储（MySQL）、面向列的数据库（如Google Big Table）、文档数据库、图形数据库（如Neo4J）</p><h4 id="图-树结构的数据库"><a href="#图-树结构的数据库" class="headerlink" title="图/树结构的数据库"></a>图/树结构的数据库</h4><p>图包括2个元素：</p><ul><li><p>节点node：表示实体</p></li><li><p>关系relationship：表示2个节点之间是如何联系在一起的</p></li></ul><blockquote><p>2019年Twitter的每月活跃用户数量为3.21亿，通过图形数据库关联在一起</p></blockquote><h4 id="图形数据库-VS-传统的关系数据库管理系统RDBMS"><a href="#图形数据库-VS-传统的关系数据库管理系统RDBMS" class="headerlink" title="图形数据库 VS 传统的关系数据库管理系统RDBMS"></a>图形数据库 VS 传统的关系数据库管理系统RDBMS</h4><p>图形数据库主要用于存储更多连接的数据，而传统的RDBMS对大量数据的遍历(traverse)性能不佳</p><p>图形数据库适合：数据元素之间的关系与数据本身同样重要的项目</p><div class="table-container"><table><thead><tr><th>RDBMS</th><th>Graph DataBase</th></tr></thead><tbody><tr><td>表</td><td>图</td></tr><tr><td>行</td><td>节点</td></tr><tr><td>列和数据</td><td>属性和值</td></tr><tr><td>约束</td><td>关系</td></tr><tr><td>Joins</td><td>Traversal 遍历</td></tr></tbody></table></div><p>属性是用来表示数据的键值对</p><h3 id="Neo4J"><a href="#Neo4J" class="headerlink" title="Neo4J"></a>Neo4J</h3><p>是服从ACID的事务性数据库，提供自带的(native)图存储和处理</p><p>由Java编写，其他语言可以通过Cypher Query Language (CQL) 进行访问</p><blockquote><p>Cypher是一种声明性图形查询语言，它允许在属性图形中进行有表现力且有效的数据查询。</p></blockquote><h4 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h4><p>以CQL作为查询语言，类似于SQL的查询语言</p><p>遵循属性图数据模型 Property Graph Data Model</p><p>包含可执行CQL命令的用户接口（Neo4J数据浏览器）</p><p>尽管是NoSQL，但其他大多数图像界面一样，服从ACID</p><p>提供REST和JavaScript接口</p><h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><p>能够简单快速对<u>连接的数据</u>进行表示和获取</p><p>CQL的设计是人类可读的，并且易于学习</p><p>不需要复杂的Joins来获取连接的数据</p><h4 id="属性图数据模型"><a href="#属性图数据模型" class="headerlink" title="属性图数据模型"></a>属性图数据模型</h4><p>Neo4J使用属性图数据模型对数据进行存储和管理，Neo4J使用自带的图处理引擎GPE，对以这个格式存储的数据进行处理。该模型简单，只有少量的基本元素：</p><ul><li>数据由节点、关系和属性表示</li><li>节点和关系都包含属性</li><li>关系连接节点</li><li>属性是键值对</li><li><p>每个关系都包含“起始节点”和“结束节点”</p></li><li><p><strong>标签</strong>：将一系列的节点或关系用一个常用的名字管理起来。一个节点或关系可以有多个标签</p></li></ul><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd12m5xkukj30qw0bk0vr.jpg" alt="截屏2020-03-20下午8.52.53"></p><h4 id="可视化——Neo4J-数据浏览器"><a href="#可视化——Neo4J-数据浏览器" class="headerlink" title="可视化——Neo4J 数据浏览器"></a>可视化——Neo4J 数据浏览器</h4><p>Neo4J 2.0版开始自带。能够快速简单的图形数据库进行可视化和编辑</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd12sg645oj312g0faafz.jpg" alt="截屏2020-03-20下午8.58.59"></p><h4 id="Cypher查询语言"><a href="#Cypher查询语言" class="headerlink" title="Cypher查询语言"></a>Cypher查询语言</h4><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd12xhqnq2j311i0g2djr.jpg" alt="截屏2020-03-20下午9.03.50"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;创建emp节点，标签名为Employee</span><br><span class="line">CREATE (emp:Employee)</span><br><span class="line">&#x2F;&#x2F; 创建包含属性的节点</span><br><span class="line">CREATE (emp:Employee &#123;employeeNumber:10, name&#x3D;“Paul”, location&#x3D;“Leeds”&#125; ) ;</span><br><span class="line">&#x2F;&#x2F; 获取数据</span><br><span class="line">MATCH (myresults: Employee)</span><br><span class="line">RETURN myresults.name, myresults.location</span><br></pre></td></tr></table></figure><h4 id="与Java整合"><a href="#与Java整合" class="headerlink" title="与Java整合"></a>与Java整合</h4><p>Neo4J有自带接口和Cypher接口与Java整合，Cypher接口能让用户通过Java接口直接执行CQL命令</p><h3 id="Neo4J-VS-MySQL"><a href="#Neo4J-VS-MySQL" class="headerlink" title="Neo4J VS MySQL"></a>Neo4J VS MySQL</h3><p>对于MySQL来说，表中的每个元素都有一组提前定义好的属性（列）</p><p>在Neo4J中，每个节点node等价于MySQL中的一行记录</p><ul><li>Label能将相似的数据归为同一组，比如用户组。相当于MySQL中的表，但同一组数据并不会真正的存储在一起，只是语义上的划分</li></ul><h4 id="图形数据库-VS-传统的RDBMS——以用户-餐厅为例"><a href="#图形数据库-VS-传统的RDBMS——以用户-餐厅为例" class="headerlink" title="图形数据库 VS 传统的RDBMS——以用户/餐厅为例"></a>图形数据库 VS 传统的RDBMS——以用户/餐厅为例</h4><p>传统数据库需要3张表分别表示用户、餐厅和关系：</p><ul><li><p>存储：<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd167p6tmfj30em086q6v.jpg" alt="截屏2020-03-20下午10.57.26" style="zoom: 33%;" /></p></li><li><p>查询：</p></li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user.*, restaurant.* </span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">user</span>, restaurant, joinTable </span><br><span class="line"><span class="keyword">WHERE</span> user.firstName = ‘Paul’ <span class="keyword">AND</span> user.id = joinTable.userId <span class="keyword">AND</span> restaurant.id = joinTable.restaurantId <span class="keyword">AND</span> joinTable.rating = ‘LOVED’</span><br></pre></td></tr></table></figure><p>图形数据库通过<u>节点</u>表示用户和餐厅，<u>关系</u>表示节点之间的关联信息，比如当用户写的评论可以直接储存在<u>关系</u>中</p><ul><li><p>存储：<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd16bcna2jj30gu0cgwf3.jpg" alt="截屏2020-03-20下午11.00.43" style="zoom:33%;" /></p></li><li><p>查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Neo4J会忽略不匹配该模式的所有值</span><br><span class="line">&#x2F;&#x2F; 通过提供的变量名，可以使用name.property与所有匹配的节点或关系进行交互</span><br><span class="line">MATCH (u:User &#123;firstName:‘Paul&#39;&#125;)-[rel:LOVED]-&gt;(res:Restaurant) RETURN res</span><br><span class="line">MATCH (u:User)-[rel]-&gt;(res:Restaurant &#123;name:&#39;French Laundry&#39;&#125;) RETURN u</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;NoSQL可以被分成4类：键值对存储（MapReduce）、面向列的数据库（如Google Big Table）、文档数据库（MongoDB）、图形数据库（如Neo4J）&lt;/p&gt;
&lt;p&gt;图形数据库主要用于存储具有更多关联的数据，而传统的RDBMS对大量数据的遍历性能不佳&lt;/p&gt;
&lt;p&gt;图形数据库适合数据元素之间的关系与数据本身同样重要的项目&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;由Neo4j，Inc.开发的图形数据库管理系统。它的开发人员将Neo4j描述为具有本机图形存储和处理的ACID兼容事务数据库，根据DB-Engines排名，Neo4j是最受欢迎的图形数据库，并且总体上是第22位最受欢迎的数据库。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="https://liaoooyx.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="NoSQL" scheme="https://liaoooyx.com/tags/NoSQL/"/>
    
      <category term="Neo4J" scheme="https://liaoooyx.com/tags/Neo4J/"/>
    
  </entry>
  
  <entry>
    <title>云编程的现状</title>
    <link href="https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/11%20Cloud%20Programming%20Landscape%20%E4%BA%91%E7%BC%96%E7%A8%8B/"/>
    <id>https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/11%20Cloud%20Programming%20Landscape%20%E4%BA%91%E7%BC%96%E7%A8%8B/</id>
    <published>2020-03-20T00:00:00.000Z</published>
    <updated>2020-03-20T15:23:56.802Z</updated>
    
    <content type="html"><![CDATA[<h2 id="11-Cloud-Programming-Landscape-云编程"><a href="#11-Cloud-Programming-Landscape-云编程" class="headerlink" title="11 Cloud Programming Landscape 云编程"></a>11 Cloud Programming Landscape 云编程</h2><p>主要内容：</p><p>云编程的前景</p><p>在云中的执行应用程序和服务的框架</p><p>云服务生命周期</p><p>常用的编程框架和模型：MPI、MapReduce / Hadoop 、亚马逊、微软 Azure</p><a id="more"></a><h4 id="云产品的现状"><a href="#云产品的现状" class="headerlink" title="云产品的现状"></a>云产品的现状</h4><p>云产品可应用于以下领域：科学/技术（无人驾驶汽车）、商务（电商、消费者关系管理CRM、会计、企业资源规划ERP）、消费者/社交（FB、Gmail、Twitter）</p><h3 id="产品和服务的编程"><a href="#产品和服务的编程" class="headerlink" title="产品和服务的编程"></a>产品和服务的编程</h3><p>现有的框架支持对应用程序和服务进行编程，并在云中执行：</p><ol><li>新的接口用以开发程序：比如Azure、Google App Engine</li><li>基于服务的工作流程的图形（Web服务业务流程执行语言）</li><li>高性能计算：MPI，OpenMP</li><li>非通用编程模型：MapReduce，Aneka（用于在云上开发分布式应用的平台和框架）</li></ol><h3 id="云服务的生命周期"><a href="#云服务的生命周期" class="headerlink" title="云服务的生命周期"></a>云服务的生命周期</h3><p>编程模型/构造服务：</p><ul><li>编程模型——用于开发产品</li><li>应用包装器——用于创建服务清单</li><li>虚拟机镜像构造器——用于产生镜像</li></ul><p>部署服务</p><ul><li>产品管理器——经服务部署到云基础设施上</li><li>虚拟机上下文工具contextualiser——将服务的软件依赖嵌入到虚拟机镜像中，并支持运行时配置</li><li>产品监控器——在操作是监控服务</li></ul><p>操作服务：</p><ul><li>虚拟机管理器——将虚拟机部署到物理节点</li><li>虚拟机基础设施管理器——管理虚拟机</li><li>基础设施监控器——监控云资源 </li></ul><h3 id="构造云服务"><a href="#构造云服务" class="headerlink" title="构造云服务"></a>构造云服务</h3><p>云服务是专门为了在云基础设施上部署而开发、策划和配置的</p><p>需执行的活动有：</p><ol><li>服务开发：开发应用程序，为用户提供功能服务<ul><li>使用编程模型简化服务开发：MapReduce、MPI、COMP Superscalar</li></ul></li><li>准备好虚拟机，等服务开发完成后，将服务部署在虚拟机上</li><li><p>指定和配置服务需求，描述参数（功能性和非功能性）</p><ul><li>容量需求、位置限制、能源效率限制</li></ul><p>针对云量身定制的编程语言：GO——针对云项目Docker的编程语言，提供并发操作</p></li></ol><h4 id="例1：消息传递接口MPI"><a href="#例1：消息传递接口MPI" class="headerlink" title="例1：消息传递接口MPI"></a>例1：消息传递接口MPI</h4><p>高性能多重计算机的出现；需要面向消息的<u>原语Primitives</u>以轻松编写高效的应用程序</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd04xhtyu7j30ys0i8tbv.jpg" alt="截屏2020-03-20上午1.27.08" style="zoom: 33%;" /></p><p>问题：大多数内部交互网络和高性能多重计算机都自带专有的通信库——需要硬件独立的通信库</p><p>解决方案：MPI</p><ul><li>为并行产品设计</li><li>使用底层网络</li><li>假设通信发生在已知的进程组</li></ul><h5 id="消息传递模型"><a href="#消息传递模型" class="headerlink" title="消息传递模型"></a>消息传递模型</h5><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd04om93dyj30ou0lw418.jpg" alt="截屏2020-03-20上午1.18.52" style="zoom:33%;" /></p><p>消息同步传输：</p><ul><li><p>需要发送者与接受者配合，但“配合”并不总是反映在代码上。</p></li><li><p>比较一对一通信和集体通信</p></li></ul><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd04u6rjjuj30yg0aodgp.jpg" alt="截屏2020-03-20上午1.24.17"></p><h5 id="进程执行：裸机与虚拟环境的对比"><a href="#进程执行：裸机与虚拟环境的对比" class="headerlink" title="进程执行：裸机与虚拟环境的对比"></a>进程执行：裸机与虚拟环境的对比</h5><p>对消息传递的方式对进程来说没有区别，区别在于进程是位于裸机中还是虚拟机中</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd0503wa9hj30xu0nen3p.jpg" alt="截屏2020-03-20上午1.29.58" style="zoom:33%;" /></p><h4 id="例2：MapReduce——在大型集群上的可扩展数据处理"><a href="#例2：MapReduce——在大型集群上的可扩展数据处理" class="headerlink" title="例2：MapReduce——在大型集群上的可扩展数据处理"></a>例2：MapReduce——在大型集群上的可扩展数据处理</h4><ul><li>用于快速处理大规模数据集的编程模型</li><li>适用于网络规模的搜索和云计算产品</li><li>用户编写的<ul><li>map函数用于生成中间操作的键值对</li><li>reduce函数将键值对按键合并</li></ul></li></ul><h4 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h4><p>由雅虎开发的软件平台，让用户编写和运行基于大规模分布式数据的产品</p><p>特点：</p><ul><li>可扩展：可以轻松的在网络空间上扩展，存储和处理PB级的数据</li><li>经济的：开源框架，能够最小化过量的任务滋生和大规模数据通信</li><li>高效的：通过大量的简单节点，进行高度并行的数据处理</li><li>可靠的：自动维护多个数据备份，当发送故障时能够重新部署计算任务</li></ul><h3 id="部署云服务"><a href="#部署云服务" class="headerlink" title="部署云服务"></a>部署云服务</h3><p>成果：服务能够在云基础设施资源上运行</p><p>执行的活动有：</p><ul><li>选择最合适的基础设施来部署服务</li><li>当服务被部署后，确保服务按照其约束进行<ul><li>约束指的是在性能、成本、能耗等方面达成一致</li></ul></li><li>上下文（配置）信息的传递，当服务被部署后，上下文信息用于初始化服务</li></ul><h3 id="操作云服务"><a href="#操作云服务" class="headerlink" title="操作云服务"></a>操作云服务</h3><p>服务运行在云基础设之上</p><p>执行的活动有：</p><ul><li>满足服务需求的管理操作（比如服务质量）</li><li>资源分配机制（包括数据放置）</li><li>（被虚拟机、容器使用的）基础设施用量的监控机制</li><li>根据基础设备用量、历史模式、预测未来用量的变化的报告机制</li></ul><h3 id="在AWS上的并行编程"><a href="#在AWS上的并行编程" class="headerlink" title="在AWS上的并行编程"></a>在AWS上的并行编程</h3><p>部分亚马逊平台上提供的服务</p><ul><li><p>EC2 亚马逊弹性云服务：提供可重新调整计算能力的Web服务，为开发者设计，简化网络规模的云计算</p></li><li><p>S3 简单存储服务：为用户提供安全、可容忍、可高度扩展的对象存储，通过简单的网络服务接口，从网络的任何地方，对任何数量的数据进行存储和获取</p></li><li><p>EBS 弹性块存储：基于EC2实例，支持<u>块级别</u>存储大小的持久化</p></li><li><p>SimpleDB：高度可用和灵活的非关系数据存储，减少开发者对数据库管理的工作。开发者只要通过网络服务请求对数据进行查询和存储，SimpleDB负责其余的工作</p></li></ul><h4 id="EC2——AMI-亚马逊虚拟机镜像"><a href="#EC2——AMI-亚马逊虚拟机镜像" class="headerlink" title="EC2——AMI 亚马逊虚拟机镜像"></a>EC2——AMI 亚马逊虚拟机镜像</h4><p>AMI是虚拟机实例的模板，AMI是预装了软件Linux系统，部署在EC2上。</p><p>AMI的类型包括私有（个人创建和使用），公开（由用户创建，并在AWS社区发布，任何人都能使用），付费（由个人创建，其他用户可以付费使用）</p><h4 id="S3"><a href="#S3" class="headerlink" title="S3"></a>S3</h4><p>特点：</p><ul><li><p>基于对象的存储服务，对象是最基础的数据单元，每个对象的大小为1Byte-5GB</p><ul><li>使用Bucket来存储对象，用Key来获取数据对象</li><li>对象包括：键、值、元数据、访问控制</li></ul></li><li><p>通过地理分散实现冗余，99.99%的可用性目标，共有或私有，每个对象都有专门的URL，支持比特流BitTorrent</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;11-Cloud-Programming-Landscape-云编程&quot;&gt;&lt;a href=&quot;#11-Cloud-Programming-Landscape-云编程&quot; class=&quot;headerlink&quot; title=&quot;11 Cloud Programming Landscape 云编程&quot;&gt;&lt;/a&gt;11 Cloud Programming Landscape 云编程&lt;/h2&gt;&lt;p&gt;主要内容：&lt;/p&gt;
&lt;p&gt;云编程的前景&lt;/p&gt;
&lt;p&gt;在云中的执行应用程序和服务的框架&lt;/p&gt;
&lt;p&gt;云服务生命周期&lt;/p&gt;
&lt;p&gt;常用的编程框架和模型：MPI、MapReduce / Hadoop 、亚马逊、微软 Azure&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Apache Spark</title>
    <link href="https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/16%20APACHE%20SPARK/"/>
    <id>https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/16%20APACHE%20SPARK/</id>
    <published>2020-03-16T00:00:00.000Z</published>
    <updated>2020-03-26T03:51:15.241Z</updated>
    
    <content type="html"><![CDATA[<p><strong>MapReduce的限制</strong></p><ol><li>MapReduce编程对许多人来说都是有难度的</li><li>性能通常会遇到瓶颈（因为批处理不适合所需的用例）</li></ol><p>这导致MapReduce不适用于大型应用程序。因此出现了多种专业系统的发展。</p><p> 因此Spark面世——将所有的专业系统整合到一起</p><a id="more"></a><h2 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h2><p>是一个通用目的数据处理引擎，为不同的需求设计，</p><ul><li>更快的批处理</li><li>应用需要交互式查询处理</li><li>处理流数据</li><li>系统需要迭代算法</li></ul><p>特征：</p><ul><li>是in-memory的计算引擎（充分利用内存）</li><li>用磁盘时比Hadoop快10倍，用内存时比Hadoop快100倍</li></ul><h4 id="Spark-结构"><a href="#Spark-结构" class="headerlink" title="Spark 结构"></a>Spark 结构</h4><p>Spark不提供任何类似HDFS的存储或者资源管理能力，它是一个以几乎实时的方式，处理大量数据的，统一的框架</p><p>三个主要的分层：</p><ol><li>生态层：基于核心层执行操作的库<ul><li>Spark SQL， Spark Streaming， BlinkDB， Spark ML， GraphX， Tachyon</li></ul></li><li>核心层：框架的通用层，它定义了所有的基础功能，其他功能和扩展都是基于这一层创建的<ul><li>Spark Core，Spark DataFrame API</li></ul></li><li>资源管理层：Spark以独立模式（单节点群集设置）管理自己的资源。 但是对于分布式集群模式，它可以与YARN之类的资源管理模块集成在一起。<ul><li>Standalone，YARN，Mesos</li></ul></li></ol><p>结构：</p><ul><li>Spark应用程序在集群上作为独立的进程集运行，由SparkContext对象（也称为驱动程序）协调。<ul><li>每个应用程序都有其自己的执行程序进程，这些进程在整个应用程序期间保持不变，并在多个线程中运行任务。</li><li>这具有将应用程序彼此<strong>隔离</strong>的好处——每个驱动程序调度自己的任务，并且来自不同应用程序的任务在不同的JVM中运行。</li><li>但是，这也意味着，如果不将数据写入外部存储系统，则无法在不同的Spark应用程序（SparkContext实例）之间共享数据。</li></ul></li><li>SparkContext负责将应用程序代码（JAR或Python文件）和任务发送给执行程序。</li><li>每个驱动程序都有一个Web UI，通常在端口4040上，该Web UI显示有关正在运行的任务，执行程序和存储使用情况的信息。</li></ul><h4 id="语言支持"><a href="#语言支持" class="headerlink" title="语言支持"></a>语言支持</h4><p>提供了Java、Scala、Python的high-level APIs</p><p>提供了优化引擎支持：产生执行图，结构化数据处理的高级工具</p><h3 id="Spark-Core"><a href="#Spark-Core" class="headerlink" title="Spark Core"></a>Spark Core</h3><p>处理：</p><ul><li>内存管理和容错</li><li><p>对集群上的任务jobs进行调度，分配，监控</p></li><li><p>与存储系统进行交互</p></li></ul><p>它也实现了弹性分布式数据库（RDDs）的关键概念。</p><ul><li>RDD是对象的不可变容错分布式集合，可以并行操作。</li><li>RDD可以包含任何类型的对象，并且可以通过加载外部数据集或从驱动程序分配集合来创建</li><li>RDD是分布在整个集群中的数据集的表示。</li></ul><h4 id="弹性分布式数据库-RESILIENT-DISTRIBUTED-DATABASES（RDDs）"><a href="#弹性分布式数据库-RESILIENT-DISTRIBUTED-DATABASES（RDDs）" class="headerlink" title="弹性分布式数据库 RESILIENT DISTRIBUTED DATABASES（RDDs）"></a>弹性分布式数据库 RESILIENT DISTRIBUTED DATABASES（RDDs）</h4><ul><li>RDDs可以被存储在内存或磁盘中，主要的性能来自于将数据存在内存中<ul><li>诸如MapReduce之类的当前框架提供了许多用于<u>访问集群的计算资源的接口</u>，但是缺乏<u>利用分布式内存的接口。</u></li></ul></li><li>Spark的优势：<ul><li>数据重用在许多迭代ML算法中很常见，例如K-means聚类。另一个示例是当用户对同一数据子集运行多个临时查询时。</li></ul></li><li>在Hadoop（和其他框架）中，在不同作业之间<u>重用数据的唯一方法</u>是将其写入外部存储系统（例如HDFS）。使用内存中的RDD，可以更快地处理数据。可以存储在分布式内存中的数据大小仅受群集大小限制。</li></ul><h4 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h4><ul><li>Transformations 转换：在RDD上执行并产生包含结果的新RDD的操作（例如，映射，过滤器，联接，联合等）</li><li>Actions 行动：在RDD上运行计算后返回值的操作（例如reduce，count，first等）。</li></ul><p>Spark上的转换操作是lazy的，并不会立即执行。只有当行动被调用时，转换才会执行。执行的结果将返回给驱动程序。该设计能提高Spark的运行效率</p><h4 id="Lazy-（Transformations）评估"><a href="#Lazy-（Transformations）评估" class="headerlink" title="Lazy （Transformations）评估"></a>Lazy （Transformations）评估</h4><p>转换是对数据的操纵。 它们从一个RDD转换到下一个。</p><p>比如：一个Action查询数据集中有多少数据，Spark在收到查询后，才会进行Transformations，再将结果返回给Action</p><h4 id="RDD用例"><a href="#RDD用例" class="headerlink" title="RDD用例"></a>RDD用例</h4><p>假设我们必须在大量的Web服务器访问日志中查找错误代码。</p><p>我们可以使用MapReduce，Storm或我们喜欢的任何框架来读取文件集，查找特定的错误代码，并将带有该代码的所有行放入存储设备（例如HDFS）</p><p>然后，当我们分析这些结果数据时，我们可能希望将错误与其他用户活动进行交叉引用cross-reference。 这将要求我们再次获取文件，处理并提供结果等。</p><p>对于传统方式需要重复对磁盘进行查询，而RDD是将数据存储在内存中，并提供了重新查询所用子集的功能。 </p><p>内存中数据存储非常适合许多迭代和交互式算法</p><h4 id="RDD容错"><a href="#RDD容错" class="headerlink" title="RDD容错"></a>RDD容错</h4><p>设计RDD的主要挑战是定义一个可提供有效容错能力的编程接口。</p><ul><li>故障是系统中的缺陷defect。</li><li>错误error是系统边界内观察到的行为与系统的指定行为之间的<strong>差异</strong></li><li>故障failure是系统当时<u>显示的行为</u>与<u>规范相反</u>的<strong>实例</strong></li></ul><p>现有解决方案提供基于<strong>细粒度更新</strong>的容错接口。</p><ul><li><p>使用这样的系统，获得容错的唯一方法，是<u>跨计算机复制数据</u>或<u>跨计算机记录更新</u>。</p></li><li><p>这些方法是数据密集型的——<strong>高带宽</strong>用于在群集网络上移动数据。</p></li></ul><p>RDD提供了基于粗粒度转换的接口（例如，映射，过滤器，联接）。 这些转换将相同的操作应用于许多数据项。</p><ul><li><p>这允许通过记录用于构建数据库的转换而不是实际数据本身来有效地应用容错。</p></li><li><p>如果RDD的分区丢失，则RDD具有有关如何从其他RDDS派生出来的足够信息，以便仅重新计算该分区。</p></li></ul><h4 id="RDD的限制"><a href="#RDD的限制" class="headerlink" title="RDD的限制"></a>RDD的限制</h4><p>不适合非迭代应用程序，因为Spark的主要性能提升是内存数据的迭代。</p><p>RDD也不太适合对共享状态进行异步细粒度更新的应用程序，例如Web应用程序的存储系统或增量Web爬虫。批量转换对于小的更新是浪费的。</p><h4 id="传统的流处理管道"><a href="#传统的流处理管道" class="headerlink" title="传统的流处理管道"></a>传统的流处理管道</h4><ol><li>从数据源接收流数据</li><li>在集群上并行处理流数据</li><li>将数据输出到下游的系统</li></ol><p>大多数传统的流处理器使用连续操作器（continuous operator）模型进行数据处理</p><ul><li>一组工作节点，每个工作节点运行一个或多个连续操作器</li><li>每个连续的操作器一次处理流数据一个记录，然后将记录转发给管道中的其他操作器。</li><li>有源操作器用于从采集系统接收数据，而下沉操作器则输出到下游系统。</li></ul><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcwbap19kxj30o80e4wii.jpg" alt="截屏2020-03-16下午6.05.24"></p><p>比如Apache Storm；这是一个非常优雅的解决方案，但是随着系统变得越来越大以及大数据分析的复杂性增加，使用此模型面临着越来越多的挑战。</p><h4 id="传统流数据处理系统的问题"><a href="#传统流数据处理系统的问题" class="headerlink" title="传统流数据处理系统的问题"></a>传统流数据处理系统的问题</h4><p><strong>故障和任务被卡主（straggling）：</strong></p><ul><li><p>随着规模扩大，集群节点故障或者无法预测的变慢（比如stragglers，掉队者）的可能性会增加</p></li><li><p>系统需要能自动从故障和卡住的任务（stragglers）中恢复，以实时提供结果</p></li><li>将<u>连续操作器</u>静态分配给工作节点，会使传统系统很难从故障和卡住的任务（stragglers）中快速恢复。</li></ul><p><strong>负载平衡：</strong></p><ul><li>Workers之间的处理负载分配不均，会导致连续操作器系统出现瓶颈。</li><li>这在大型集群和动态变化的工作负载中更可能发生。</li><li>系统需要能够根据工作负载动态调整资源分配。</li></ul><p><strong>流、批处理、交互式工作负载的统一：</strong></p><ul><li>在许多使用案例中，以交互方式查询流数据或将其与静态数据集（例如，预先计算的模型）结合起来很有吸引力。</li><li>在连续的操作器系统中，这很难做到，因为它们并非旨在动态地为临时查询引入新的运算器</li><li>这需要一个可以结合批处理，流式处理和交互式查询的引擎。</li></ul><p><strong>高级分析：</strong></p><ul><li><p>复杂的工作负载需要连续的学习和更新数据模型，甚至是用sql查询最新的流数据视图</p></li><li><p>使这些分析任务具有通用抽象（API），能让开发人员的工作更加轻松</p></li></ul><h4 id="离散流-Discretized-Streams-——-解决方案"><a href="#离散流-Discretized-Streams-——-解决方案" class="headerlink" title="离散流 Discretized Streams —— 解决方案"></a>离散流 Discretized Streams —— 解决方案</h4><p>为了解决这些问题，Spark Streaming组件使用称为离散化流的新架构，该架构直接利用了Spark引擎的库和容错能力。</p><ul><li>Spark Streaming接收器不会一次读取单个数据记录，而是将数据流离散化为亚秒级的微小批量（RDDs）。（即接收者并行接受数据并将其缓冲在Spark worker节点的内存中）。然后，Spark引擎运行简短的任务（数十毫秒）以处理批处理并将结果输出到其他系统。</li></ul><p>与连续操作器模型不同，Spark任务根据数据的位置和可用资源动态分配给工作人员。这是为了实现更好的负载平衡和更快的故障恢复。</p><ul><li>每个数据的batches都是一个RDD。这允许使用任何Spark代码或库来处理流数据。</li></ul><h4 id="DSP好处：动态负载平衡"><a href="#DSP好处：动态负载平衡" class="headerlink" title="DSP好处：动态负载平衡"></a>DSP好处：动态负载平衡</h4><p>将数据划分为多个微批，可以将计算能力以细粒度的方式分配给资源。</p><p>以字数统计为例：分区不均衡的流会导致某个节点过载，达到瓶颈；而将数据离散Discretized 后，可以根据节点的负载对任务进行分配和调度。</p><h4 id="DSP好处：从故障和卡住的任务中快速恢复"><a href="#DSP好处：从故障和卡住的任务中快速恢复" class="headerlink" title="DSP好处：从故障和卡住的任务中快速恢复"></a>DSP好处：从故障和卡住的任务中快速恢复</h4><p>传统流：</p><ul><li>万一发生节点故障，传统系统必须在另一个节点上重新启动发生故障的连续运算器，并重播数据流的某些部分以重新计算丢失的信息。（请注意，在重播后新节点赶上之前，管道无法继续进行。）</li></ul><p>Spark流（离散流）</p><ul><li><p>可以在集群中的所有其他节点上并行重新启动失败的任务，从而将所有重新计算均匀地分布在多个节点上，从而从故障中恢复。</p><p><u>计算已经离散化为可以在任何地方运行而不会影响正确性的任务。</u></p></li></ul><h4 id="DSP好处：流、批处理、交互的统一"><a href="#DSP好处：流、批处理、交互的统一" class="headerlink" title="DSP好处：流、批处理、交互的统一"></a>DSP好处：流、批处理、交互的统一</h4><p>Spark Streaming中的关键编程接口是DStream或分布式流。 每一批流数据都由RDD表示，因此DStream只是一系列RDD。</p><p>因此，我们可以使用任何Spark函数处理DStream。例如，我们可以将DStream与预先计算的静态数据集（已加载到另一个RDD中）结合在一起</p><p>数据批存储在workers的内存中，因此可以按需交互查询。<br>批处理，流和交互式工作负载的这种统一在Spark中非常简单，但是在没有<u>工作负载的通用接口</u>的系统中很难实现</p><h4 id="DSP好处：高级分析"><a href="#DSP好处：高级分析" class="headerlink" title="DSP好处：高级分析"></a>DSP好处：高级分析</h4><p>DStreams生成的RDD可以转换为DataFrames并使用SQL查询</p><p>例如，使用Spark的JDBC驱动程序，可以公开流的状态，并支持SQL语句进行查询。</p><p>然后，通过JDBC服务器，就能够以交互方式（比如SQL命令、GUI）查询持续更新的表。</p><h4 id="Spark流：性能"><a href="#Spark流：性能" class="headerlink" title="Spark流：性能"></a>Spark流：性能</h4><p>实际上，Spark Streaming具有批处理数据和利用Spark引擎的能力，可以使吞吐量与其他流系统相当或更高。</p><ul><li>Spark Streaming可以实现低至几百毫秒的延迟。</li></ul><p>开发人员有时会问微批处理是否会固有地增加过多的延迟。</p><ul><li>实际上，批处理延迟仅是端到端管道延迟的一小部分。</li></ul><ul><li>例如，许多应用程序在滑动窗口上计算结果，甚至在COS中，该窗口也仅定期更新（例如，每2秒滑动20秒的窗口）。</li></ul><ul><li>许多管道等待很短的时间来处理延迟或乱序的数据。</li></ul><ul><li>最后，任何自动触发算法都倾向于等待一段时间才能触发。</li></ul><p>同样，DStreams带来的吞吐量提高通常意味着您需要更少的计算机来处理相同的工作负载。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;MapReduce的限制&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MapReduce编程对许多人来说都是有难度的&lt;/li&gt;
&lt;li&gt;性能通常会遇到瓶颈（因为批处理不适合所需的用例）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这导致MapReduce不适用于大型应用程序。因此出现了多种专业系统的发展。&lt;/p&gt;
&lt;p&gt; 因此Spark面世——将所有的专业系统整合到一起&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="https://liaoooyx.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Spark" scheme="https://liaoooyx.com/tags/Spark/"/>
    
      <category term="RDD" scheme="https://liaoooyx.com/tags/RDD/"/>
    
  </entry>
  
  <entry>
    <title>云计算/10 云中间件，配置管理，PaaS</title>
    <link href="https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/10%20%E4%BA%91%E4%B8%AD%E9%97%B4%E4%BB%B6%EF%BC%8C%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86%EF%BC%8CPaaS/"/>
    <id>https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/10%20%E4%BA%91%E4%B8%AD%E9%97%B4%E4%BB%B6%EF%BC%8C%E9%85%8D%E7%BD%AE%E7%AE%A1%E7%90%86%EF%BC%8CPaaS/</id>
    <published>2020-03-12T18:19:46.893Z</published>
    <updated>2020-03-20T00:39:38.810Z</updated>
    
    <content type="html"><![CDATA[<h2 id="10-云中间件，配置管理，PaaS"><a href="#10-云中间件，配置管理，PaaS" class="headerlink" title="10 云中间件，配置管理，PaaS"></a>10 云中间件，配置管理，PaaS</h2><h4 id="云计算的好处"><a href="#云计算的好处" class="headerlink" title="云计算的好处"></a>云计算的好处</h4><ul><li>弹性资源：自治的资源按需供应（通过实用的模型）</li><li><p>多重租赁：多个用户并发使用相同资源</p></li><li><p>工作负载整合：将利用不足的资源释放，把工作负载低的虚拟机整合到同一个物理机器上。</p></li></ul><h4 id="中间件"><a href="#中间件" class="headerlink" title="中间件"></a>中间件</h4><p>位于网络中分布式计算系统每一侧的操作系统和应用程序之间的软件层：</p><ul><li>连接不同的软件组件</li><li>是在系统和分布式软件之间的软件层</li><li><p>隐藏了分布式系统的复杂性和多样性 heterogeneity</p></li><li><p>连接了低层次的OS通信（系统级别的通信实现）和编程语言抽象（通信的接口）的间隔</p></li><li><p>为分布式应用提供了常用的编程接口和基础设施</p></li><li>促进资源服务的使用</li><li>将应用与基础设施连接</li></ul><h4 id="Platform-as-a-Service-PaaS"><a href="#Platform-as-a-Service-PaaS" class="headerlink" title="Platform as a Service (PaaS)"></a>Platform as a Service (PaaS)</h4><p>定义：“向消费者提供的功能是将使用提供商提供的编程语言，库，服务和工具创建的，由消费者创建或获取的应用程序部署到云基础架构上。 使用者不管理或控制包括网络，服务器，操作系统或存储在内的底层云基础架构，但可以控制已部署的应用程序以及应用程序托管环境的配置设置。</p><p>简单的定义：在基本虚拟资源（即虚拟机，块存储）管理之外提供的任何服务。</p><p>是什么：是一种云中间件；提供<u>软件解决方案堆栈</u>即服务；可以聚合其他PaaS和IaaS供应商服务；通常由工具和/或库(APIs)组成</p><p>用处：通过抽象简化应用开发；通过简化管理促进应用部署</p><h4 id="PaaS例子"><a href="#PaaS例子" class="headerlink" title="PaaS例子"></a>PaaS例子</h4><ul><li>• Google App Engine</li><li>• Amazon Web Services<ul><li>– Amazon RDS (Relational Database Service) </li><li>– Amazon Elastic Transcoder</li></ul></li><li>• Hadoop Project<ul><li>– MapReduce</li><li>– Hbase: Bigtable-like capabilities on top of Hadoop and HDFS</li></ul></li></ul><h4 id="云服务的生命周期"><a href="#云服务的生命周期" class="headerlink" title="云服务的生命周期"></a>云服务的生命周期</h4><ol><li>construction：开发、组合、配置</li><li>deployment：选择供应商、部署、上下文化</li><li>operation：调度、优化、执行、重新上下文化</li></ol><h4 id="配置管理-Configuration-Management-CM"><a href="#配置管理-Configuration-Management-CM" class="headerlink" title="配置管理 Configuration Management (CM)"></a>配置管理 Configuration Management (CM)</h4><p>用于：在构造阶段后（但不是在部署和操作阶段），在大规模机器上（10k）配置应用和中间件</p><p>例子：puppet、chef</p><h4 id="Puppet"><a href="#Puppet" class="headerlink" title="Puppet"></a>Puppet</h4><p>提供基于图像的和模型驱动的方式；通过人类可读的DSL（Domain Specific Language）实现；资源是存储在“清单”中的配置单位；可以将资源编译到定义依赖项的目录中（作为有向非循环图）；目录已应用于系统以对其进行配置；在许多计时器步骤中，配置更改是不确定的（最终应用）</p><h4 id="Chef"><a href="#Chef" class="headerlink" title="Chef"></a>Chef</h4><p>是Puppet的一个受欢迎的分支；</p><p>主要区别：天生就是确定性的 Deterministic</p><p>强调启动一个新的服务（适合虚拟机和云）</p><p>按顺序应用配置，且用户可知</p><p>使用烹饪的类比：<br>•创建配方（安装步骤或脚本的预算）<br>•使用刀（用于管理的命令行工具）<br>•存储在服务器内的食谱中</p><h4 id="Chef的结构"><a href="#Chef的结构" class="headerlink" title="Chef的结构"></a>Chef的结构</h4><p>Client-Server架构</p><p>服务器推送配置变更</p><p>客户端在机器上实施配置变更</p><h4 id="配置管理在Cloud上的问题"><a href="#配置管理在Cloud上的问题" class="headerlink" title="配置管理在Cloud上的问题"></a>配置管理在Cloud上的问题</h4><ol><li>云环境天生就是动态的：CM工具并不是用于处理有弹性的资源集合（AWS Elastic Beanstalk 是Chef的云生命周期可感知版）；因为云的生命周期，导致云应用和普通应用不一样（Useful in Construction，What about: Deployment, Operation?）</li><li>遗留软件如何迁移到云：如何使遗留软件和他们的中间件适应云的动态特征（如何将云的dynamic nature提取走）</li><li>如何构建可内部交互的云应用</li></ol><h4 id="Contextualization-上下文化"><a href="#Contextualization-上下文化" class="headerlink" title="Contextualization 上下文化"></a>Contextualization 上下文化</h4><p>定义：上下文是在部署到特定环境期间自主配置应用程序的各个组件并支持软件堆栈的过程。</p><p>通过在整个生命周期内通过PaaS组件配置SaaS和PaaS，启用弹性云软件堆栈。<br>通过通用配置机制支持旧式中间件<br>通过recontextualization 实现IaaS提供程序的互操作性</p><p>上下文化机制的两个阶段：</p><ul><li>Deployment：从环境中（在PaaS层）采集动态生成的配置数据</li><li>Operation：由VM boot触发，使用上述数据的软件配置</li></ul><p>被OpenNebula和OpenStack采用，用于使软件使用Iaas供应商的环境，例如：</p><ul><li>配置基础网络（静态和动态）</li><li>配置虚拟机秘钥识别（SSH VPN）</li><li>连接基于网络的存储</li></ul><h4 id="Operation阶段的上下文化"><a href="#Operation阶段的上下文化" class="headerlink" title="Operation阶段的上下文化"></a>Operation阶段的上下文化</h4><ul><li>配置数据是如何传递到虚拟机的（见图）</li><li>在boot阶段安装ISO光盘镜像（ISO CD image）：上下文数据通过网络脚本传递到虚拟机内部的脚本上，由脚本创建软件专门的配置文件和域数据</li><li>配置文件和数据用于设置云环境中，软件依赖和中间件服务的上下文，</li></ul><h4 id="Recontextualization-重新上下文化"><a href="#Recontextualization-重新上下文化" class="headerlink" title="Recontextualization 重新上下文化"></a>Recontextualization 重新上下文化</h4><p>在Operation阶段（runtime）改变配置数据</p><blockquote><p>The recontextualizer is responsible for triggering the creation and association of new infrastructure class context data when applicable domains are migrated to the infrastructure.</p></blockquote><p>触发：虚拟机实时迁移Live Migration，比如本地环境变量更改，但无需重启reboot，因此需要触发机制，而不是有规律的执行</p><p>在重新上下文化的过程中，虚拟机将会持续运行，自动的，且更改对应用是透明的</p><h4 id="Contextualizer-结构"><a href="#Contextualizer-结构" class="headerlink" title="Contextualizer 结构"></a>Contextualizer 结构</h4><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcsnmpoczxj31c00g2dlv.jpg" alt="截屏2020-03-13下午2.09.51"></p><blockquote><p>Figure 3 also includes the order in which components are called. From the figure it can be seen that the Contextualizer component is invoked by the VM Manger during application deployment (step 1) to create ISO images (steps 2, 3), create VM images (steps 4, 5) and/or manip- ulate VM images (steps 6, 7). After images have been created and/or manipulated, they are stored in a local data repository (step 8) for deployment by the VM Manager. During operation, if an event from the underlying hypervisor indicates that a VM has been stopped, started or migrated (step 9), alterations to the existing ISO images are made (steps 10, 11) and reinserted into the VM’s virtual device (step 12).</p></blockquote><p>从图中可以看出，在应用程序部署期间，VM管理器调用了Contextuizer组件（步骤1）以创建ISO映像（步骤2、3），创建VM映像（步骤4、5）和/或操作 -确定VM映像（步骤6、7）。 创建和/或操作映像后，它们将存储在本地数据存储库中（步骤8），以供VM Manager进行部署。 在操作过程中，如果来自底层管理程序的事件指示VM已停止，启动或迁移（步骤9），则对现有ISO映像进行更改（步骤10、11），然后将其重新插入VM的虚拟设备中（ 第12步）。</p><h4 id="Recontextualization-例子"><a href="#Recontextualization-例子" class="headerlink" title="Recontextualization 例子"></a>Recontextualization 例子</h4><p>由于先前的设置，分布式文件系统的操作性能可能会在实时迁移后降低</p><p>客户端数据与远程服务节点交互，而不是附近的节点</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;10-云中间件，配置管理，PaaS&quot;&gt;&lt;a href=&quot;#10-云中间件，配置管理，PaaS&quot; class=&quot;headerlink&quot; title=&quot;10 云中间件，配置管理，PaaS&quot;&gt;&lt;/a&gt;10 云中间件，配置管理，PaaS&lt;/h2&gt;&lt;h4 id=&quot;云计算的好
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>云计算/19 Serverless Architectures</title>
    <link href="https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/19%20Serverless%20Architectures/"/>
    <id>https://liaoooyx.com/2020/03/%E4%BA%91%E8%AE%A1%E7%AE%97/19%20Serverless%20Architectures/</id>
    <published>2020-03-12T13:36:24.441Z</published>
    <updated>2020-03-12T14:29:36.723Z</updated>
    
    <content type="html"><![CDATA[<h2 id="19-Serverless-Architectures"><a href="#19-Serverless-Architectures" class="headerlink" title="19 Serverless Architectures"></a>19 Serverless Architectures</h2><h4 id="无服务计算"><a href="#无服务计算" class="headerlink" title="无服务计算"></a>无服务计算</h4><p>开发者不需要配置或者管理服务器或容器，如AWS Lambda，只需要将业务代码上传至平台即可。</p><p>在无服务计算的模型中，服务器的存在对开发者是隐藏的。</p><ul><li>无服务结构和功能即服务 Function-as-a-Service(FaaS) 平台的优点：简单、快速、灵活</li><li><strong>无服务</strong>指的是软件结构，<strong>功能即服务</strong>是其中的关键的机制，通过这种机制，开发者在该软件结构中实现业务逻辑</li></ul><h4 id="IaaS-PaaS-SaaS-FaaS的区别"><a href="#IaaS-PaaS-SaaS-FaaS的区别" class="headerlink" title="IaaS, PaaS, SaaS, FaaS的区别"></a>IaaS, PaaS, SaaS, FaaS的区别</h4><h4 id="无服务计算执行模型"><a href="#无服务计算执行模型" class="headerlink" title="无服务计算执行模型"></a>无服务计算执行模型</h4><p>如果该功能不存在与现有的服务器中，则平台从数据库中读取功能，并部署到服务器上，再返回功能的执行结果给用户</p><h4 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h4><p>无需管理服务器，可连续扩展，动态分配资源，避免资源过度分配（管理资源分配，平衡资源分配），按使用付费</p><p>从生产角度From a productivity standpoint，可以不考虑代码存储和执行环境管理的细节</p><p>基于execution metrics，无服务计算十分划算priced，so there is a financial advantage as well.</p><h4 id="无服务功能-Serverless-Functions"><a href="#无服务功能-Serverless-Functions" class="headerlink" title="无服务功能 Serverless Functions"></a>无服务功能 Serverless Functions</h4><p>从 monoliths 到 microservices 到 functions</p><p><strong>微服务</strong>的特点：Smaller-grained services 粒度小的服务，专属、具体的功能</p><p><strong>微服务</strong>的结构：事件处理器 Event handler，无服务后端，数据处理</p><p><strong>无服务功能</strong>的特点：FaaS的指导原则，开发者无需关注被抽象化的服务器，按照功能的使用服务而不是服务器实例的大小，提供的服务是事件驱动的且能够立即扩展</p><h4 id="透明的应用部署"><a href="#透明的应用部署" class="headerlink" title="透明的应用部署"></a>透明的应用部署</h4><p>PaaS：用于基于用户需求和约束的服务发现</p><p><strong>无服务结构</strong>和<strong>微服务</strong>可以掩盖“运行过程中软件和数据的灵活组合/拆分和可交互性”</p><p><strong>容器</strong>或<strong>技术</strong>用于桥接云和边缘计算之间的间隔：Unikernels 提供解决“软件定义的基础架构”的基础功能</p><h4 id="无服务计算——其他好处"><a href="#无服务计算——其他好处" class="headerlink" title="无服务计算——其他好处"></a>无服务计算——其他好处</h4><p>简化部署和打包，消除系统管理的要求</p><p>敏捷开发，使开发者集中于代码，并快速发布deliver</p><p>扩展的成本更低：扩展（用户访问量）不需要开发者通过代码实现，管理者也不用更新服务器或添加新的服务器</p><p>更小的开发成本和经营成本 operational costs</p><p>更快发布软件 software release，减少到市场的时间 Decreased time to market</p><h4 id="无服务架构的解决方案和结构细节"><a href="#无服务架构的解决方案和结构细节" class="headerlink" title="无服务架构的解决方案和结构细节"></a>无服务架构的解决方案和结构细节</h4><ul><li>Amazon Lambda</li><li>Apache Openwhisk</li><li>IBM Openwhisk</li><li>Google cloud functions</li><li>Microsoft Azure functions Other: Iron.io, Fission</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;19-Serverless-Architectures&quot;&gt;&lt;a href=&quot;#19-Serverless-Architectures&quot; class=&quot;headerlink&quot; title=&quot;19 Serverless Architectures&quot;&gt;&lt;/a&gt;19 Se
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>面向列的数据库</title>
    <link href="https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/12%20NOSQL-%E8%B0%B7%E6%AD%8CBigTable/"/>
    <id>https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/12%20NOSQL-%E8%B0%B7%E6%AD%8CBigTable/</id>
    <published>2020-03-11T00:00:00.000Z</published>
    <updated>2020-03-26T03:52:07.681Z</updated>
    
    <content type="html"><![CDATA[<p>大数据系统的规模对数据库空间的要求有很大挑战</p><p>传统的关系数据库管理系统（Relational Database Management System：<em>RDBMS</em>）无法扩展为适应真正的massive级别数据：ACID原则不适合大规模的数据，CAP定理中描述的问题</p><a id="more"></a><h4 id="CAP定理："><a href="#CAP定理：" class="headerlink" title="CAP定理："></a>CAP定理：</h4><ul><li>一致性：所有客户都能看到最新的数据，不管执行过什么操作（比如更新或删除）</li><li>可用性：即使某些节点发送错误，系统也需要继续客户的操作</li><li>分区容错：即使网络或消息发送错误，系统也需要继续执行可续操作（比如一个节点向另一个节点发送的消息，允许发送错误并被丢弃）</li></ul><h4 id="ACID-和-BASE"><a href="#ACID-和-BASE" class="headerlink" title="ACID 和 BASE"></a>ACID 和 BASE</h4><p>ACID：</p><ul><li>Atomic 原子性：事务的所有操作都成功，不然就回滚</li><li>Consistent 一致性：事务不能使数据库的最终状态出现不一致</li><li>Isolated 隔离性：事务使独立的，不能影响其他事务</li><li>Durable 容忍性：即使服务器重新启动等，已完成的事务也会保留。</li></ul><p>BASE</p><ul><li><strong>B</strong>asic <strong>A</strong>vailability 基础可用性：系统在CAP定理方面，保证系统的可用性</li><li><strong>S</strong>oft-state 软状态：系统的状态会随时间改变，即使没有输入（因为要确保最终一致性）</li><li><strong>E</strong>ventual consistency 最终一致性：只要数据库最终变得一致，在每个事务之后就不需要一致性。</li></ul><h4 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h4><p>可以被分成4类：Key-value stores、Column-oriented databases、Document databases、Graph databases</p><h3 id="Google-BigTable-HBASE"><a href="#Google-BigTable-HBASE" class="headerlink" title="Google BigTable (HBASE)"></a>Google BigTable (HBASE)</h3><p>BigTable是第一个（也是影响力最大的）面向列的NoSQL数据库之一。于2006年发布。它旨在可靠地扩展到数千台计算机上的PB级数据。</p><p>在60多种Google产品中使用，包括Google Earth，Google Analytics（分析）和Youtube。</p><p>BigTable具有极大的影响力，它催生了一个非常受欢迎的开源克隆：HBase。</p><p>设计为与MapReduce BigTable兼容并互补，可为MapReduce提供基于键的快速查找</p><h4 id="关键特征"><a href="#关键特征" class="headerlink" title="关键特征"></a>关键特征</h4><ul><li>BigTable是一个简单的概念 —- 映射两个任意字符串值（行键和列键）以及时间戳，并将其放入关联的任意字节数组中：（行：字符串，列：字符串，时间：int64）-&gt;字符串</li><li>在NoSQL分类中，BigTable是面向列的数据库。<br>它是高度分布式的，没有可用的连接，并且假定“一次写入多次读取”。</li><li>数据模型是“稀疏，分布式，持久的多维排序图”<br>a sparse, distributed, persistent multi-dimensional sorted map”</li><li>实际上，这意味着您可以通过提供行ID，列名和时间戳来访问BigTable中的任何单元（用于版本控制–您保留同一单元的过去版本）。<br>提供这些参数，BigTable会很快将结果返回给您。</li></ul><h4 id="Tablets"><a href="#Tablets" class="headerlink" title="Tablets"></a>Tablets</h4><ul><li>单元的每个新版本都会增加时间戳。 这允许您设置策略，例如“仅保留最新的n个版本”或“仅保留自时间t开始存储的版本”。</li><li>数据按行排序，以行的Key按字典顺序排序，并且表的行范围是动态分区的。 每行范围称为一个Tablets。</li><li>Tablets是分配和负载平衡的单位——如果发生不平衡，则Tablets可以在服务器之间移动。<br>Tablets的大小大约在200MB</li></ul><p>例如 ：如果关键范围是{January，February，March}，并且从March开始有很多数据进入，则它将拆分为多个Tablets，并在服务器之间移动以平衡系统。</p><p>因此，少量row范围的读取是高效的，并且通常仅需要与少量机器通信。</p><h4 id="Tablet-管理"><a href="#Tablet-管理" class="headerlink" title="Tablet 管理"></a>Tablet 管理</h4><p>BigTable使用3层模型对tablet进行管理</p><ol><li>第一层包含存储在Chubby（用于访问控制的分布式锁定服务）中的文件，该文件包含根Tablet的位置。</li><li>根tablet包含系统中所有tablets的位置。 它经过特殊处理，并且与其他tablet不同，它永远不会被分割——确保层次结构永远不会超过3个级别。</li><li>根tablet中的每一行都在内存中使用大约1k的数据。 假设每块tablet有128MB的限制，则3级层次结构可以处理$2^{34}$（〜170亿）个tablets。</li></ol><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd5s2zivqsj30o60b2whu.jpg" alt="截屏2020-03-24下午10.36.12" style="zoom:50%;" /></p><h4 id="总体结构"><a href="#总体结构" class="headerlink" title="总体结构"></a>总体结构</h4><p>Head node：分配tablets到tablet服务器上</p><p>Tablet server：管理对tablets的读写操作；客户端直接与tablet服务器通信；tablet服务器将太大的tablets拆分</p><p>SSTable：Sorted String Tables 包含真实数据</p><h4 id="读写组织"><a href="#读写组织" class="headerlink" title="读写组织"></a>读写组织</h4><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcvbq1kcy8j30sg0e8dhf.jpg" alt="截屏2020-03-15下午9.34.38"></p><p>内存中有一个表（memTable）用于存储发生的一系列的更新</p><p>一个写操作会将记录添加到memTable中，并且同时会写入日志（为了容错）</p><p>通过读取SSTable文件以及通过动态应用memTable的更新来提供读操作。 换句话说：“这里是价值所在，以及需要应用到该价值以获得真正价值的更新流”</p><h4 id="次要压缩-Minor-Compactions"><a href="#次要压缩-Minor-Compactions" class="headerlink" title="次要压缩 Minor Compactions"></a>次要压缩 Minor Compactions</h4><p>随着写操作执行，memTable的大小也会增大。当memTable的大小达到阈值，该memTable会被冻结，并创建一个新的memTable。被冻结的memTable被转化为SSTable并被写成文件。</p><p> 这部分操作被认为次要压缩，该压缩的两个目标：</p><ol><li>减少tablet服务器的内存使用量</li><li>减少数据恢复时，必须从提交日志中读取的数据量。</li></ol><p>发生压缩时，传入的读/写操作可以继续。</p><h4 id="主要压缩-Major-Compactions"><a href="#主要压缩-Major-Compactions" class="headerlink" title="主要压缩 Major Compactions"></a>主要压缩 Major Compactions</h4><p>每个次要压缩都会产生一个新的SSTable，如果该操作不断进行，读操作需要从大量的SSTables中合并更新。</p><p>为了防止这种情况，我们会在后台定期执行合并压缩。这样的压缩读取了几个SSTables和memTable的内容，并写出了一个新的SSTable。 完成后，可以丢弃之前的SSTables和memTable。</p><p><strong>将所有SSTables重写为一个SSTable的合并压缩称为主要压缩</strong>。 请记住，单个SSTable本身可能会拆分为多个文件。</p><h4 id="关键特征-1"><a href="#关键特征-1" class="headerlink" title="关键特征"></a>关键特征</h4><p>调整压缩格式</p><ul><li><p>客户端可以控制是否压缩地区组的SSTable，以及如果压缩，则使用哪种压缩格式。</p><p>用户指定的压缩格式将应用于每个SSTable块（大小可通过特定于位置组的调整参数来控制）。</p><p>分别压缩每个块时，会损失一些空间，但是我们的好处是，可以读取SSTable的一小部分而无需解压缩整个文件。</p></li></ul><p>布隆过滤器</p><ul><li><p>读取操作必须从组成tablet状态的所有SSTable中读取。 如果这些SSTable不在内存中，我们可能最终会进行许多磁盘访问。</p><p>BigTable可以使用Bloom Filters减少此类访问的次数。 布隆过滤器允许我们询问SSTable是否可能包含指定行/列/对的任何数据。</p><p>对于某些应用程序，将少量tablet服务器内存分配给<u>布隆过滤器</u>，能够大大减少读取操作所需的磁盘搜索次数。</p></li></ul><p>使SSTables不可变</p><ul><li><p>使用BigTable改善性能的另一种方法是使SSTables不可变。</p><p>这意味着SSTables不会直接写入，因为唯一可写入的数据结构是memTable，这使得并发控制相对简单。</p><p>结果，由于具有不可变性，仅在发生重大压缩时才创建SSTables。</p></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大数据系统的规模对数据库空间的要求有很大挑战&lt;/p&gt;
&lt;p&gt;传统的关系数据库管理系统（Relational Database Management System：&lt;em&gt;RDBMS&lt;/em&gt;）无法扩展为适应真正的massive级别数据：ACID原则不适合大规模的数据，CAP定理中描述的问题&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="https://liaoooyx.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Google BigTable" scheme="https://liaoooyx.com/tags/Google-BigTable/"/>
    
      <category term="HBase" scheme="https://liaoooyx.com/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>异构硬件</title>
    <link href="https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/12%20%E5%BC%82%E6%9E%84%E7%A1%AC%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    <id>https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/12%20%E5%BC%82%E6%9E%84%E7%A1%AC%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</id>
    <published>2020-03-11T00:00:00.000Z</published>
    <updated>2020-03-26T03:42:24.341Z</updated>
    
    <content type="html"><![CDATA[<p>Cyber-Physical Systems (CPS)，the Internet of Things (IoT)， and the Smart Anything Everywhere Initiative</p><p>从长远来看，随着大规模采用，物联网转型影响预计将显着增加：千万级数量的物品互联，非常大的经济价值</p><p>关键驱动因素：物联网收集的数据，复杂的应用程序开发平台，应用于事物的分析以及<strong>异构硬件体系结构 heterogeneous hardware architectures</strong>，能够促进新业务模型</p><a id="more"></a><h4 id="云计算-大数据"><a href="#云计算-大数据" class="headerlink" title="云计算+大数据"></a>云计算+大数据</h4><p>实时流、实时处理</p><p>数据可视化</p><p>实时结构化数据库、交互式分析、批量处理</p><p>结构化和非结构化数据</p><p>云基础设施</p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>Cyber-Physical Systems (CPS)，the Internet of Things (IoT)， and the Smart Anything Everywhere Initiative</p><p>从长远来看，随着大规模采用，物联网转型影响预计将显着增加：千万级数量的物品互联，非常大的经济价值</p><p>关键驱动因素：物联网收集的数据，复杂的应用程序开发平台，应用于事物的分析以及<strong>异构硬件体系结构 heterogeneous hardware architectures</strong>，能够促进新业务模型</p><h3 id="异构硬件体系结构-Heterogeneous-hardware-architectures"><a href="#异构硬件体系结构-Heterogeneous-hardware-architectures" class="headerlink" title="异构硬件体系结构 Heterogeneous hardware architectures"></a>异构硬件体系结构 Heterogeneous hardware architectures</h3><p>是运行产品和提供服务的一种高效方法；将不同的处理器类型组合到一个系统中，以此提高绝对性能，最小化能耗和成本。</p><p>引入新的平台：合并多核CPUs，多核GPUs，和许多附加设备作为一个单独解决方案。出现在从超级计算机到个人智能手机的各种环境中.</p><p>因为产品的种类不断增长，因此需要设计<strong>更灵活的软件抽象software abstractions</strong>，以及改进系统结构，以探索异构平台的好处</p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>数据巨大且复杂，传统处理方法效率不足：</p><ul><li>Too large to fit reasonably in fast RAM 数据太大无法合理的放入fast RAM中</li><li>Random access intensive, making prefetching and caching ineffective 随机访问密集，使预取和缓存无效</li></ul><p>数据经常被存在多机集群中的二号存储节点中</p><ul><li>存储系统和网络性能成为 first-order concerns</li></ul><h4 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h4><p>大数据系统带来新的需求：新的编程模型和工具</p><p>大数据系统需要实现：高性能和高效率</p><h4 id="关于异质性方面"><a href="#关于异质性方面" class="headerlink" title="关于异质性方面"></a>关于异质性方面</h4><p>异质性是并行结构中最深奥和最有挑战的特征</p><p>宏观方面：分布式计算机（云）的网络，由不同的节点结构（单核，多核）组成，通过可能的异质网络进行内部交互；即网络的异质性和，网络上的机器的异质性</p><p>微观方面：底层的内存结构（main、cache、disk storage、tertiary storage）和不同的accelerator结构（固定的、可编程的，比如GPUs；可配置的：FPGAs）</p><h3 id="电脑结构"><a href="#电脑结构" class="headerlink" title="电脑结构"></a>电脑结构</h3><p>需要进行分类：根据目的进行分类</p><h4 id="通用处理器-General-Purpose-Processors（GPP）"><a href="#通用处理器-General-Purpose-Processors（GPP）" class="headerlink" title="通用处理器 General Purpose Processors（GPP）"></a>通用处理器 <strong>General Purpose Processors</strong>（GPP）</h4><ul><li>通用微处理器（通用电脑）：比如PCs，workstations，Laptops，notepads，用于执行多种应用和任务</li><li>微控制器：嵌入式系统<ul><li>专门为嵌入式系统中指定任务而设计</li><li>有面向控制的外围设备</li><li>具有片上CPU，固定数量的RAM，ROM，I / O端口</li><li>低成本、低能耗、低性能、比微处理器更小</li><li>适合对成本、空间、能耗要求严格的应用</li></ul></li></ul><h4 id="应用专用处理器"><a href="#应用专用处理器" class="headerlink" title="应用专用处理器"></a>应用专用处理器</h4><p>通用处理器对不同的软件都能表现出较好的性能，但专用处理器在特定任务上的表现更好</p><p>应用专用处理器出现的目的：更高的性能，更低的消耗，更低的成本</p><p>比如：TVs、mobile phone（不是智能手机）、GPSs</p><p>被分为：</p><ol><li>Digital Signal Processor (DSPs) 数字信号处理器</li><li>Application Specific Instruction Set Processors (ASIPs) 应用专用命令集处理器</li><li>Application Specific Integrated Circuit (ASICs) 应用专用集成电路<ul><li>指定市场、更少编程、难以构建</li></ul></li></ol><h4 id="Accelerators-Coprocessors-加速器-协处理器"><a href="#Accelerators-Coprocessors-加速器-协处理器" class="headerlink" title="Accelerators - Coprocessors 加速器-协处理器"></a><strong>Accelerators - Coprocessors</strong> 加速器-协处理器</h4><p>加速器-协处理器对某些功能的处理性能比CPU更高效more efficiently ：更快、更低能耗，但更难编程，比如：</p><ol><li>Graphics Processing Unit (GPU)<ul><li>Single Instruction Multiple Thread (SIMT) model 单指令多线程模型 – CUDA code</li><li>高效：数据并行应用；吞吐量密集型应用——算法需要处理大量数据元素</li></ul></li><li>FPGA (Field Programmable Gate Array) 现场可编程门阵列<ul><li>是逻辑门阵列，可以进行硬件编程以完成用户指定的任务</li><li>软件的一部分可以直接由硬件实现</li><li>比软件更有效率，但比ASIC更贵</li></ul></li></ol><h4 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h4><p>Intel CPU -&gt; DSP -&gt; MultiCore -&gt; ManyCore -&gt; GPU -&gt; FPGA -&gt; ASIC</p><p>灵活性、可编程、 ——&gt; 性能、特定领域、能源使用率高 power efficiency</p><h4 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h4><p>Host memory 主存：CPU的内存</p><p>Device memory 显存：GPU的内存</p><p><strong>处理流程：</strong></p><ol><li>从CPU中将输入数据拷贝到GPU中</li><li>加载GPU程序并执行，将数据缓存到芯片chip上提高性能</li><li>将执行结果从GPU内存中拷贝回CPU内存</li></ol><h4 id="GPU——数据处理"><a href="#GPU——数据处理" class="headerlink" title="GPU——数据处理"></a>GPU——数据处理</h4><p>擅长处理并行 data-parallel processing</p><ul><li>在多个数据元素上并行执行相同的计算——低控制流开销和高SP浮点运算强度 high SP floating point arithmetic intensity</li><li>每个内存访问有许多计算</li></ul><p>高浮点运算强度和许多数据元素意味着可以通过计算而不是大数据缓存来隐藏内存访问延迟</p><ul><li>需要避免带宽饱和</li></ul><h4 id="FPGA-现场可编程门阵列"><a href="#FPGA-现场可编程门阵列" class="headerlink" title="FPGA 现场可编程门阵列"></a>FPGA 现场可编程门阵列</h4><p>可配置逻辑块，内部通信网络，I/O信号</p><h4 id="FPGA——数据处理"><a href="#FPGA——数据处理" class="headerlink" title="FPGA——数据处理"></a>FPGA——数据处理</h4><ul><li>用于数据采集和原始数据预处理以进行事件过滤</li><li>需要掌握基于FPGA的硬件描述语言（HDL）的编程模型。<ul><li>– VHDL和Verilog是设计FPGA系统的传统方法</li><li>–描述执行计算的基础设计的基础硬件</li><li>–这与诸如C和C ++的编程语言形成对比，后者描述了在固定不变体系结构上执行的指令</li><li>–这使得FPGA既可以在其上实现的方面极为灵活，又在不充分了解其编程模型的情况下也很难设计。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Cyber-Physical Systems (CPS)，the Internet of Things (IoT)， and the Smart Anything Everywhere Initiative&lt;/p&gt;
&lt;p&gt;从长远来看，随着大规模采用，物联网转型影响预计将显着增加：千万级数量的物品互联，非常大的经济价值&lt;/p&gt;
&lt;p&gt;关键驱动因素：物联网收集的数据，复杂的应用程序开发平台，应用于事物的分析以及&lt;strong&gt;异构硬件体系结构 heterogeneous hardware architectures&lt;/strong&gt;，能够促进新业务模型&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="https://liaoooyx.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="异构硬件" scheme="https://liaoooyx.com/tags/%E5%BC%82%E6%9E%84%E7%A1%AC%E4%BB%B6/"/>
    
      <category term="GPU" scheme="https://liaoooyx.com/tags/GPU/"/>
    
      <category term="FPGA" scheme="https://liaoooyx.com/tags/FPGA/"/>
    
  </entry>
  
  <entry>
    <title>数据仓库、数据去重</title>
    <link href="https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/13%20%E5%8E%BB%E9%87%8D%E5%92%8C%E4%BB%93%E5%BA%93/"/>
    <id>https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/13%20%E5%8E%BB%E9%87%8D%E5%92%8C%E4%BB%93%E5%BA%93/</id>
    <published>2020-03-11T00:00:00.000Z</published>
    <updated>2020-03-26T03:50:45.572Z</updated>
    
    <content type="html"><![CDATA[<p>数据去重是一个逐渐流行起来的方法</p><p>重复数据删除有许多用途，但其主要用途是减少系统所需存储空间的潜力。</p><p>去重可以是文件file级别，块block级别，字节byte级别</p><a id="more"></a><h4 id="数据仓库-data-warehouse"><a href="#数据仓库-data-warehouse" class="headerlink" title="数据仓库 data warehouse"></a>数据仓库 data warehouse</h4><p>假设一个大公司：有许多数据库database、许多站点sites，和不同的schemas。</p><p>求是：•支持决策<br>•在全公司范围内查看高质量信息的集成视图（来自不同的数据库）<br>•分离运营系统和信息系统</p><p>运营系统和信息系统的比较</p><div class="table-container"><table><thead><tr><th>特征</th><th>运营系统</th><th>信息系统</th></tr></thead><tbody><tr><td>主要目的</td><td>在当前基础上用于商业运营</td><td>帮助制定决策</td></tr><tr><td>数据类型</td><td>当前商业运营状况的展示</td><td>历史数据和预测数据</td></tr><tr><td>主要用户</td><td>柜员、销售、管理员</td><td>管理者、商业分析师、客户</td></tr><tr><td>使用范围</td><td>狭窄的、有计划的和简单的<u>更新和查找</u></td><td>宽泛的、复杂的<u>查询和分析</u></td></tr><tr><td>设计目标</td><td>性能：吞吐量、可用性</td><td>灵活访问和使用</td></tr><tr><td>大小</td><td>对一个和少数几个表的大量更新和查询</td><td>周期性的批量更新，对大量或所有行的查询</td></tr></tbody></table></div><p>数据仓库包括：元数据，原始数据-&gt;轻度总结数据-&gt;高度总结数据，数据库管理系统；其他还有：负载管理、查询管理、数据仓库管理</p><p>数据仓库的使用者：联机分析处理OLIP工具，报告、查询、应用开发、EIS工具，数据挖掘工具，和终端用户end-user访问工具</p><p>数据仓库的来源：<strong>运营数据源Operational data source</strong>，运营数据库Operational data store</p><h4 id="数据仓库的定义"><a href="#数据仓库的定义" class="headerlink" title="数据仓库的定义"></a>数据仓库的定义</h4><p>“数据仓库是面向主题的，集成的，随时间变化且非易失性的数据收集，以支持管理层的决策过程。”</p><p><strong>Subject-oriented</strong>：</p><ul><li>面向重要的主题，而不是交易transactions：比如销售、市场、金融、分销distribution；</li><li>简洁的视图，仅提供有用的数据以供决策</li></ul><p><strong>Integrated</strong>：</p><ul><li><p>来自于多个数据源的数据遵循一致的命名习惯Consistent naming conventions、格式、编码结构</p></li><li><p>对缺失数据，噪声数据，不一致数据进行清洗cleaning和预处理pre-processing</p></li></ul><p><strong>Time-varinat</strong>：</p><ul><li>只读，周期性刷新</li><li>提供历史historical值和可能的预测projected值</li></ul><p><strong>Non-volatile</strong>：</p><ul><li>在物理上分别存储</li><li>非在线更新</li><li>从不移除数据，因此没有并发问题</li></ul><h4 id="运营数据-Operational-data"><a href="#运营数据-Operational-data" class="headerlink" title="运营数据 Operational data"></a>运营数据 Operational data</h4><ul><li>transient 短暂的（not historical）</li><li>not normalised非标准化的（指的是数据库的范式）（可能为了性能而去规范化）</li><li>约束在一定范围内（非全面的 not comprehensive）</li><li>有时候质量不佳（出现不一致和错误）</li></ul><p><strong>经过提取/转换/加载 E(xtract)T(ransform)L(oad)后：</strong></p><ul><li>详细的Detailed（但还没被总结summarized）</li><li>历史的（周期性的periodic）</li><li>标准化（第三范式3rd  normal form或更高）</li><li>全面的：以公司为角度</li><li>时效的：数据足够支持目前的决策制定</li><li>质量受控的：数据精确且准确</li></ul><h4 id="删除重复数据-Data-Deduplication"><a href="#删除重复数据-Data-Deduplication" class="headerlink" title="删除重复数据 Data Deduplication"></a>删除重复数据 Data Deduplication</h4><p>数据去重是一个逐渐流行起来的方法</p><p>重复数据删除有许多用途，但其主要用途是减少系统所需存储空间的潜力。</p><p>去重可以是文件file级别，块block级别，字节byte级别</p><h4 id="文件级别去重"><a href="#文件级别去重" class="headerlink" title="文件级别去重"></a>文件级别去重</h4><p>对单文件去重，常被认为“单实例存储”，它的主要思想就是：不管有多少文件实例被使用，只保留一个文件备份</p><p>该技术被用于Amazon S3，并报告出能够减少存储和带宽的成本为1/10</p><h4 id="块级别去重"><a href="#块级别去重" class="headerlink" title="块级别去重"></a>块级别去重</h4><p>将文件拆分成块blocks（或chunks）：核心思想是，经过两个文件不同，但他们可能包括相同的元素（比如两个不同的ppt可能包含同一张图片）</p><h4 id="字节级别去重"><a href="#字节级别去重" class="headerlink" title="字节级别去重"></a>字节级别去重</h4><p>在许多方面，字节级去重是块级去重的一种特殊情况。它比较数据流中的每个单独字节，而不是块。</p><p>字节级别去重是通常是“内容感知”的——比如，卖方对数据流的组成有一定的了解，因此知道要处理的数据流的特定部分。</p><p>该方法通常是“后处理”的，即先存储所有的流，再进行处理</p><h4 id="去重处理"><a href="#去重处理" class="headerlink" title="去重处理"></a>去重处理</h4><p>我们需要一种方法来检查数据是否已经被存储在我们的系统中：对文件、块、字节进行哈希计算，然后在我们的去重数据库DDB中查询该哈希值。如果该值存在，则该数据存在，如果值不存在，则存储该数据和对应的哈希值。</p><h4 id="Source-based-和-Target-based"><a href="#Source-based-和-Target-based" class="headerlink" title="Source-based 和 Target-based"></a>Source-based 和 Target-based</h4><p><strong>Source-based</strong>：</p><ul><li>之间在文件系统（或靠近数据的地方）中进行去重</li><li>对用户和应用透明</li><li>可以由文件系统本身或主机的操作系统执行</li><li>通常一个文件系统会扫描新文件并和现存的文件比较哈希值</li><li>通常需要中心化的管理（文件系统和备份服务器要在一起）</li><li>需要更多的用户资源，而不是带宽</li></ul><p>Target-based</p><ul><li>发生在备份服务器（第二/归档archive数据库）</li><li>重复数据从创建数据的位置删除</li><li>不损耗数据源的资源</li><li>不需要中心化的管理</li><li>需要更多的带宽</li></ul><h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><h4 id="去重的权衡"><a href="#去重的权衡" class="headerlink" title="去重的权衡"></a>去重的权衡</h4><p><strong>Granularity 粒度</strong>：影响存储的效率和性能（存储空间和处理效率的权衡）</p><p>将文件拆分得越小（比如chunck-block-byte），就能找到更多的重复数据，但同样的，去重的处理速度也就越慢</p><p>另一个考虑是是容错：只留一个去重数据的副本copy是否足够</p><p>多个副本的优缺点？容错；数据分散靠近用户的cluster中，有利于提高响应时间；占用存储空间，增加成本</p><h4 id="相关术语"><a href="#相关术语" class="headerlink" title="相关术语"></a>相关术语</h4><blockquote><p>Operational System —— 运营系统<br>ad hoc —— 常用来形容一些特殊的、不能用于其它方面的，为一个特定的问题、任务而专门设定的解决方案<br>throughput —— 吞吐量</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据去重是一个逐渐流行起来的方法&lt;/p&gt;
&lt;p&gt;重复数据删除有许多用途，但其主要用途是减少系统所需存储空间的潜力。&lt;/p&gt;
&lt;p&gt;去重可以是文件file级别，块block级别，字节byte级别&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="https://liaoooyx.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据去重" scheme="https://liaoooyx.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%8E%BB%E9%87%8D/"/>
    
      <category term="数据仓库" scheme="https://liaoooyx.com/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>CAP定理</title>
    <link href="https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/12_%20CAP%E5%AE%9A%E7%90%86/"/>
    <id>https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/12_%20CAP%E5%AE%9A%E7%90%86/</id>
    <published>2020-03-11T00:00:00.000Z</published>
    <updated>2020-03-26T03:54:12.555Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在<a href="https://zh.wikipedia.org/wiki/理论计算机科学" target="_blank" rel="noopener">理论计算机科学</a>中，<strong>CAP定理</strong>（CAP theorem），又被称作<strong>布鲁尔定理</strong>（Brewer’s theorem），它指出对于一个<a href="https://zh.wikipedia.org/wiki/分布式计算" target="_blank" rel="noopener">分布式计算系统</a>来说，不可能同时满足以下三点：<a href="https: //zh.wikipedia.org/wiki/CAP定理#cite_note-Lynch-1">[1]</a><a href="https://zh.wikipedia.org/wiki/CAP定理#cite_note-2" target="_blank" rel="noopener">[2]</a></p><ul><li>一致性（<strong>C</strong>onsistency） （等同于所有节点访问同一份最新的数据副本）</li><li><a href="https://zh.wikipedia.org/wiki/可用性" target="_blank" rel="noopener">可用性</a>（<strong>A</strong>vailability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）</li><li><a href="https://zh.wikipedia.org/w/index.php?title=网络分区&amp;action=edit&amp;redlink=1" target="_blank" rel="noopener">分区容错性</a>（<strong>P</strong>artition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择<a href="https: //zh.wikipedia.org/wiki/CAP定理#cite_note-3">[3]</a>。）</li></ul><p>根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项<a href="https://zh.wikipedia.org/wiki/CAP定理#cite_note-4" target="_blank" rel="noopener">[4]</a>。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。</p></blockquote><a id="more"></a><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>客户端将值写入任何服务器并获得响应后，它期望从其读取的任何服务器取回该值（或更新鲜的值）</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcv3kjxahwj319q0lygnv.jpg" alt="截屏2020-03-15下午4.52.25"></p><p>为了保证该特性，客户端在向其中一个服务器写入后，该服务器需要与其他服务器同步，在同步完成后，才会通知客户端已成功写入。</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcv3kxx6tij318w0lqwh7.jpg" alt="截屏2020-03-15下午4.52.58"></p><h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><blockquote><p>系统中非故障节点收到的每个请求都必须导致响应</p><p>every request received by a non-failing node in the system must result in a response</p></blockquote><p>在可用的系统中，如果我们的客户端向服务器发送请求并且服务器没有崩溃，则服务器最终必须响应客户端。不允许服务器忽略客户端的请求。</p><h3 id="分区容错"><a href="#分区容错" class="headerlink" title="分区容错"></a>分区容错</h3><blockquote><p>网络将被允许任意丢失从一个节点发送到另一节点的许多消息</p><p>the network will be allowed to lose arbitrarily many messages sent from one node to another</p></blockquote><p>即一个节点向另外一个节点发送的消息丢失是可接受的，下图展示当所有消息都丢失的情况：</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcv3sa21zej30yo08k752.jpg" alt="截屏2020-03-15下午4.59.59"></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;在&lt;a href=&quot;https://zh.wikipedia.org/wiki/理论计算机科学&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;理论计算机科学&lt;/a&gt;中，&lt;strong&gt;CAP定理&lt;/strong&gt;（CAP theorem），又被称作&lt;strong&gt;布鲁尔定理&lt;/strong&gt;（Brewer’s theorem），它指出对于一个&lt;a href=&quot;https://zh.wikipedia.org/wiki/分布式计算&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;分布式计算系统&lt;/a&gt;来说，不可能同时满足以下三点：&lt;a href=&quot;https: //zh.wikipedia.org/wiki/CAP定理#cite_note-Lynch-1&quot;&gt;[1]&lt;/a&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/CAP定理#cite_note-2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[2]&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一致性（&lt;strong&gt;C&lt;/strong&gt;onsistency） （等同于所有节点访问同一份最新的数据副本）&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/可用性&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;可用性&lt;/a&gt;（&lt;strong&gt;A&lt;/strong&gt;vailability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://zh.wikipedia.org/w/index.php?title=网络分区&amp;amp;action=edit&amp;amp;redlink=1&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;分区容错性&lt;/a&gt;（&lt;strong&gt;P&lt;/strong&gt;artition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择&lt;a href=&quot;https: //zh.wikipedia.org/wiki/CAP定理#cite_note-3&quot;&gt;[3]&lt;/a&gt;。）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项&lt;a href=&quot;https://zh.wikipedia.org/wiki/CAP定理#cite_note-4&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[4]&lt;/a&gt;。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="https://liaoooyx.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="CAP定理" scheme="https://liaoooyx.com/tags/CAP%E5%AE%9A%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop和MapReduce的发展</title>
    <link href="https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/11%20Hadoop%E5%92%8CMapReduce%E7%9A%84%E5%8F%91%E5%B1%95/"/>
    <id>https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/11%20Hadoop%E5%92%8CMapReduce%E7%9A%84%E5%8F%91%E5%B1%95/</id>
    <published>2020-03-04T00:00:00.000Z</published>
    <updated>2020-03-26T03:41:00.840Z</updated>
    
    <content type="html"><![CDATA[<p>Hadoop 1 的局限、Hadoop 2：HDFS Federation、YARN</p><a id="more"></a><h3 id="Hadoop-1"><a href="#Hadoop-1" class="headerlink" title="Hadoop 1"></a>Hadoop 1</h3><h4 id="Hadoop1中的MapReduce"><a href="#Hadoop1中的MapReduce" class="headerlink" title="Hadoop1中的MapReduce"></a>Hadoop1中的MapReduce</h4><ol><li>客户端提交MapReduce任务到<u>工作追踪器 Job Tracker</u>上</li><li>工作追踪器询问<u>主节点 NameNode</u>：哪些<u>数据节点 Data Node</u>有文件块</li><li>工作追踪器然后将<u>任务追踪器 Task Tracker</u>和<u>执行Map计算的Java代码</u>提供给那些节点。计算任务将在拥有本地数据的节点执行</li><li>任务追踪器将启动Map任务，并监控进程。它将返回心跳和任务状态给工作追踪器</li><li>每一个Map任务完成后，该节点将临时存储结果（中间数据），当所有Map任务都完成后，数据将通过网络发送给执行Reduce任务的节点</li></ol><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd17f7ua3oj30kq0gkdje.jpg" alt="截屏2020-03-20下午11.39.15" style="zoom:50%;" /></p><h4 id="Hadoop-1-的局限"><a href="#Hadoop-1-的局限" class="headerlink" title="Hadoop 1 的局限"></a>Hadoop 1 的局限</h4><p>集群资源管理和MapReduce是紧密耦合的</p><ul><li>Hadoop 1中的工作追踪器只在一个机器上运行<ol><li>可扩展性有限，但实际中可能需要许多数据节点</li><li>可用性只存在于单点，如果工作追踪器发生故障，那么所有工作 Jobs 都要重启</li></ol></li></ul><blockquote><p>雅虎估计该设计的上限是5000个节点和40000个并发任务</p></blockquote><p>在资源使用上同样存在问题</p><ul><li>Hadoop 1对map和reduce的插槽(slots)数量是提前定义好的，因此可能出现map插槽满了而reduce插槽还是空的情况（反之亦然）</li><li>文件的数量也十分有限。主节点在内存中持有元数据，因此每个集群通常限制为5千万-1亿个文件</li></ul><p>在Hadoop1上运行非MapReduce应用也存在限制</p><ul><li>MapReduce工作基于<u>批处理驱动的分析</u>，但是，人们通常希望在Hadoop集群中运行其他计算范例</li><li>为什么要运行非MapReduce应用？<ul><li>实时分析存在困难。 MapReduce是批处理驱动的； 当需要实时结果时，Apache Storm之类的引擎可以更好地工作。</li><li>消息传递方法在MapReduce中是不可能的（没有相互依赖性）。</li></ul></li></ul><p><strong>这些问题都在Hadoop2中得到解决</strong></p><h4 id="长尾现象"><a href="#长尾现象" class="headerlink" title="长尾现象"></a>长尾现象</h4><p>谷歌与2013年将其识别为长尾现象：<u>个别拖后腿的任务task stragglers</u>大大减慢了应用程序的完成速度（执行阈值比作业平均值高50％），由操作系统抖动 OS jitter，数据偏斜 data skew,，守护进程，能源等引起</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd18i1hjspj311y0e677y.jpg" alt="截屏2020-03-21上午12.16.14"></p><h3 id="Hadoop-2"><a href="#Hadoop-2" class="headerlink" title="Hadoop 2"></a>Hadoop 2</h3><p>Hadoop 2从受限的<u>面向批处理的模型</u>转变为更具交互性和专用性的处理模型</p><p>主要变化有：HDFS联盟，YARN，高度可用的NameNode，容器的概念</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd18nu9h66j30tg0cctcc.jpg" alt="截屏2020-03-21上午12.22.08"></p><h4 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h4><p>容器是一个抽象概念，但本质上是一种资源分配。</p><p>容器授予应用程序使用特定主机上特定数量资源（cpu，内存，磁盘）的权限。</p><p>容器类似于虚拟机，但是在现有操作系统之上运行，而不是在<u>虚拟机管理程序Hypervisor</u>上运行。换句话说，容器能在应用级别对用户进行隔离（虚拟机是操作系统级别的隔离）。容器之间是相互独立的，但公用操作系统、bins和库</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd18ujrh6zj30lu0ditbg.jpg" alt="截屏2020-03-21上午12.28.35" style="zoom:50%;" /></p><h4 id="高可用性主节点"><a href="#高可用性主节点" class="headerlink" title="高可用性主节点"></a>高可用性主节点</h4><p>解决Hadoop1中主节点的单点问题：它提供在同一群集中运行两个冗余NameNode的选项，可以主动或被动配置，使备用节点<u>热待命 hot standby</u></p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd1955bwhfj30uq08owgr.jpg" alt="截屏2020-03-21上午12.38.46"></p><h4 id="HDFS水平可扩展性"><a href="#HDFS水平可扩展性" class="headerlink" title="HDFS水平可扩展性"></a>HDFS水平可扩展性</h4><p>由上图可以看出，即使通过备份让主节点获得高可用性，但2个单独的主节点并不能提供水平可扩展性</p><ul><li>垂直可扩展性：更多的RAM，更高效的内存使用，将部分命名空间放到内存中，主类归档（tar/zip）</li><li>水平可扩展性的好处：规模、隔离性、稳定性、可用性、灵活性、实现其他主节点或非HDFS 命名空间</li></ul><h4 id="解决方案：HDFS-Federation"><a href="#解决方案：HDFS-Federation" class="headerlink" title="解决方案：HDFS Federation"></a>解决方案：HDFS Federation</h4><p>解决方式是联合多个独立的主节点</p><ul><li>联合的主节点是独立的，不需要协调。</li><li>数据节点被所有主节点共用，作为块的存储。</li><li>每个数据节点向群集中的所有主节点注册。</li><li>DataNode发送心跳给所有主节点，并接受块报告和处理命令。</li></ul><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd19lu5mjej30jk0bstbq.jpg" alt="截屏2020-03-21上午12.54.48" style="zoom:50%;" /></p><p>主要概念：</p><ul><li><u>块池 Block Pool</u>是一个<u>命名空间 namespace</u>中的一系列块</li><li><p>数据节点存储集群中的所有块</p></li><li><p>块池是独立管理的。因此每个命名空间都可以生成块ID，而不需要与其他命名空间进行达成一致</p></li><li>一个主节点故障不会影响数据节点对其他主节点的服务</li><li>一个命名空间和它对应的块池统称为<u>命名空间卷 Namespace Volumes</u>，如果一个命名空间被删除，它对于的块池也会被删除</li></ul><h4 id="HDFS-Federation的好处"><a href="#HDFS-Federation的好处" class="headerlink" title="HDFS Federation的好处"></a>HDFS Federation的好处</h4><p>命名空间的可扩展性：HDFS群集存储（数据节点）可以水平扩展，但命名空间不能。 当使用大量文件部署时，可通过向群集添加更多主节点的而达成水平扩展的目的</p><p>性能：文件系统操作吞吐量不再局限于单个主节点的</p><p>隔离：单个主节点的在多用户环境中不提供隔离。 现在，我们可以将不同类别的应用程序放入不同的主节点中（例如，实验性应用程序减慢主节点的运行速度不会影响其余集群）</p><h4 id="Yet-Another-Resource-Negotiation-YARN"><a href="#Yet-Another-Resource-Negotiation-YARN" class="headerlink" title="Yet Another Resource Negotiation (YARN)"></a>Yet Another Resource Negotiation (YARN)</h4><p>YARN的基础思想是：将Hadoop资源管理和工作调度拆分为不同的进程（后台进程）</p><p>不同种类的应用程序都能被提交给YARN（比如MapReduce，Giraph等），应用程序可以是单个作业，也可以是作业的<u>有向无环图Directed Acyclic Graph（DAG）</u>。</p><p>这样可以并行运行更多作业，并且可扩展性得到显着提高</p><ul><li><u>资源管理器ResourceManager</u>代替<u>工作追踪器JobTracker</u>，负责在所有应用程序之间仲裁资源的使用权限。<ul><li>持续追踪：维护在集群上运行的所有程序，以及所有在线的节点管理器的可用资源</li><li>分配资源：决定下一个使用集群资源的程序（即下个一程序应该分配到哪个数据节点上）</li><li>监控<u>程序主节点</u></li></ul></li><li><p><u>节点管理器NodeManager</u>是一个基于机器的框架，负责管理容器、监视资源使用情况并向资源管理器报告。 集群中的每台计算机都是一个节点管理器和一个数据节点。 </p><ul><li>以容器的形式提供计算资源</li><li>管理容器内运行的进程</li><li>负责监视资源（容器）。 它没有固定数量的Map和Reduce插槽，但是可以动态创建和管理<u>资源容器</u>。 它就像Hadoop 1中JobTracker的通用版本。</li></ul></li><li><p><u>ApplicationMaster的任务是与资源管理器协商资源，并与各个节点管理器一起执行和监视任务。</p><ul><li>协调执行程序的内所有任务</li><li>请求合适的资源容器来执行任务</li></ul></li></ul><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd1cz80dvaj30zk0hq118.jpg" alt="截屏2020-03-21上午2.51.28"></p><blockquote><p>ApplicationMaster负责单个应用程序的执行。它从资源调度程序（资源管理器）中请求容器，并在获得的容器上执行特定的程序（例如，Java类的主程序）。 Application Master知道程序逻辑，因此每个框架都需要自己编写ApplicationMaster。 MapReduce框架提供了自己的应用ApplicationMaster。</p><p>应用程序管理器ApplicationManager负责维护已提交的应用程序列表。在客户端提交应用程序后，应用程序管理器首先验证是否满足其ApplicationMaster的资源需求。如果有足够的资源，则将程序转发给调度器，否则将拒绝。还要确保没有其他具有相同应用程序ID的应用程序提交。</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd5f0alzhqj30ni0b2dgh.jpg" alt="image"></p><h4 id="提交应用到YARN中"><a href="#提交应用到YARN中" class="headerlink" title="提交应用到YARN中"></a>提交应用到YARN中</h4><ol><li>客户端将需要执行的程序发送给<u>资源管理器ResourceManager</u>（如MapReduce）</li><li>资源管理器，在容器内启动一个<u>程序管理器ApplicationMaster</u>，并将要执行的程序发送过去</li><li><u>程序管理器</u>与<u>资源管理器</u>协商资源。<ul><li>它负责应用程序的整个生命周期。</li><li>资源请求只是请求分配多个容器，表示为magabytes和CPU份额（当前）。</li></ul></li><li>然后，<u>ApplicationMaster</u>与<u>节点管理器</u>联系，以在容器中启动任务<ul><li>它监视这些任务的进度，重启失败的任务，推测性地运行速度较慢的任务，并计算应用程序计数器的总值。</li><li>它的整个生命周期用于与容器协商，来启动完成程序所需的所有任务</li></ul></li><li><u>资源管理器</u>不会监视程序中的任务——但它会检查<u>ApplicationMaster</u>的运行状况<ul><li>如果<u>ApplicationMaster</u>失败，则<u>资源管理器</u>可以在新容器中重新启动它。</li><li><u>资源管理器</u>负责<u>ApplicationMaster</u>，而<u>ApplicationMaster</u>负责<u>任务</u></li></ul></li></ol><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd5fujv1klj317o0r6arg.jpg" alt="截屏2020-03-24下午3.31.42" style="zoom:50%;" /></p><h4 id="YARN可以运行任何分布式程序"><a href="#YARN可以运行任何分布式程序" class="headerlink" title="YARN可以运行任何分布式程序"></a>YARN可以运行任何分布式程序</h4><p>ResourceManager，NodeManager和Container不关心它们要运行的任务或应用程序的类型。只要实现了适当的ApplicationMaster，任何应用程序都可以运行。</p><p>好处：</p><ul><li>更高的集群利用率（一个框架不使用的资源可以被另一个框架使用）</li><li>更低的运营成本（仅需要管理和调整一种类型的集群）</li><li>数据移动减少（无需在YARN和其他系统之间移动数据）</li></ul><p>管理单个群集，还能够减少数据中心空间的使用，从而降低的运营成本，功耗，发热等。</p><h4 id="YARN的其他特征"><a href="#YARN的其他特征" class="headerlink" title="YARN的其他特征"></a>YARN的其他特征</h4><ul><li>如果作业足够小，则可以直接在ApplicationMaster的容器中运行MapReduce作业的所有任务。 这避免了从ResourceManager请求容器并要求NodeManager启动（据说很小）任务的开销。（见上图）</li><li>YARN提供简化的用户日志管理和访问。 与旧的Hadoop 1 MapReduce不同，日志不会保留在单个从节点上，而是移至中央存储（例如HDFS）。 后续可用于调试，性能分析等。</li><li>在重启资源管理器后恢复程序(YARN-128)——使资源管理器可以重建应用程序的状态，并仅重新运行未完成的任务。</li><li>高可用性的资源管理器体系结构（YARN-149）——发送故障后，支持资源管理器从一个实例到另一个实例（可能在另一台计算机上）。 它涉及领导者竞选，权限转移，客户端重定向。</li></ul><h4 id="Hadoop-2总结"><a href="#Hadoop-2总结" class="headerlink" title="Hadoop 2总结"></a>Hadoop 2总结</h4><p>HDFS2——高可用性和用于水平扩展的联合主节点</p><p>YARN——超越了Hadoop 1的批处理，并提高了效率</p><p>工具和程序的完整生态系统</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gd1dm0m0pfj30wy0be0wi.jpg" alt="截屏2020-03-21上午3.13.22"></p><h4 id="Hadoop不平衡集群"><a href="#Hadoop不平衡集群" class="headerlink" title="Hadoop不平衡集群"></a>Hadoop不平衡集群</h4><p>问题：</p><ul><li>将新服务器和机架添加到Hadoop群集可能会导致其变得不平衡。 现有数据保留在原处，新服务器处于空闲状态。</li><li>如果现有节点繁忙，则<u>工作追踪器JobTracker</u>可能不得不将Map任务分配给新服务器。</li><li>如果发生这种情况，新服务器将需要通过网络复制对应的数据块。 这导致更多的网络流量和较慢的作业完成时间。</li></ul><p>解决：为了解决不平衡的情况，Hadoop包含一个称为平衡器的实用程序。</p><ul><li>它检查节点之间的可用空间的差异，并尝试平衡到阈值。</li><li>当检测到具有大量磁盘空间的节点时，数据块将从空间较小的节点复制过去。 </li><li>平衡器是手动运行的，并在管理员关闭其终端时停止。 </li><li>平衡器的默认设置为1MB / s网络流量，可更改。</li></ul><p>理想情况下，平衡器应在所有群集上定期运行以进行良好管理。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hadoop 1 的局限、Hadoop 2：HDFS Federation、YARN&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="https://liaoooyx.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="Hadoop1" scheme="https://liaoooyx.com/tags/Hadoop1/"/>
    
      <category term="Hadoop2" scheme="https://liaoooyx.com/tags/Hadoop2/"/>
    
  </entry>
  
  <entry>
    <title>Bloom filters 布隆过滤器</title>
    <link href="https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/12%20Bloom%20filters%20%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    <id>https://liaoooyx.com/2020/03/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/12%20Bloom%20filters%20%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</id>
    <published>2020-03-02T00:00:00.000Z</published>
    <updated>2020-03-26T03:55:10.383Z</updated>
    
    <content type="html"><![CDATA[<p><strong>布隆过滤器</strong>（英語：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的<a href="https://zh.wikipedia.org/wiki/二进制" target="_blank" rel="noopener">二进制</a>向量和一系列随机<a href="https://zh.wikipedia.org/wiki/映射" target="_blank" rel="noopener">映射函数</a>。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。</p><a id="more"></a><p>will trigger: false positive —- possibly in the set</p><p>will no trigger: false negative —- definitely not in the set</p><h4 id="demo-amp-介绍"><a href="#demo-amp-介绍" class="headerlink" title="demo &amp; 介绍"></a>demo &amp; 介绍</h4><p><a href="https://llimllib.github.io/bloomfilter-tutorial/" target="_blank" rel="noopener">https://llimllib.github.io/bloomfilter-tutorial/</a></p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p><strong>布隆过滤器</strong>（英語：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的<a href="https://zh.wikipedia.org/wiki/二进制" target="_blank" rel="noopener">二进制</a>向量和一系列随机<a href="https://zh.wikipedia.org/wiki/映射" target="_blank" rel="noopener">映射函数</a>。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。</p><p>如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。<a href="https://zh.wikipedia.org/wiki/链表" target="_blank" rel="noopener">链表</a>、<a href="https://zh.wikipedia.org/wiki/树_(数据结构" target="_blank" rel="noopener">树</a>)、<a href="https://zh.wikipedia.org/wiki/散列表" target="_blank" rel="noopener">散列表</a>（又叫哈希表，Hash table）等等数据结构都是这种思路。但是随着集合中元素的增加，我们需要的存储空间越来越大。同时检索速度也越来越慢，上述三种结构的检索时间复杂度分别为<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db50673c67c6e72b7342ca1383def18cdead21b6" alt="{\displaystyle O(https://wikimedia.org/api/rest_v1/media/math/render/svg/db50673c67c6e72b7342ca1383def18cdead21b6),O(\log n),O(1)}">。</p><p>布隆过滤器的原理是，当一个元素被加入集合时，通过K个<a href="https://zh.wikipedia.org/wiki/散列函数" target="_blank" rel="noopener">散列函数</a>将这个元素映射成一个位<a href="https://zh.wikipedia.org/wiki/数组" target="_blank" rel="noopener">数组</a>中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。</p><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5ec39041121b14e8c2b1a986c9b04547b223e3c" alt="O(https://wikimedia.org/api/rest_v1/media/math/render/svg/f5ec39041121b14e8c2b1a986c9b04547b223e3c)">。另外，散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。</p><p>布隆过滤器可以表示全集，其它任何数据结构都不能；</p><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" alt="k">和<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" alt="m">相同，使用同一组散列函数的两个布隆过滤器的交并<a href="https://zh.wikipedia.org/wiki/Wikipedia:列明来源" target="_blank" rel="noopener">[來源請求]</a>运算可以使用位操作进行。</p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>但是布隆过滤器的缺点和优点一样明显。误算率是其中之一。随着存入的元素数量增加，误算率false positive随之增加。但是如果元素数量太少，则使用散列表足矣。</p><p>另外，一般情况下不能从布隆过滤器中删除元素。我们很容易想到把位数组变成整数数组，每插入一个元素相应的计数器加1, 这样删除元素时将计数器减掉就可以了。然而要保证安全地删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面。这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。</p><p>在降低误算率方面，有不少工作，使得出现了很多布隆过滤器的变种。</p><p>optimal number of hash functions $k=\frac{m}{n}ln2,k=-\frac{lnp}{ln2}$</p><p>估计要添加的元素数量</p><p>bollm过滤器的大小</p><p>计算最佳的哈希函数数量</p><p>计算false positive的可能性</p><p>trade-off</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;布隆过滤器&lt;/strong&gt;（英語：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的&lt;a href=&quot;https://zh.wikipedia.org/wiki/二进制&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;二进制&lt;/a&gt;向量和一系列随机&lt;a href=&quot;https://zh.wikipedia.org/wiki/映射&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;映射函数&lt;/a&gt;。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="https://liaoooyx.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="布隆过滤器" scheme="https://liaoooyx.com/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>CNN图像分类</title>
    <link href="https://liaoooyx.com/2020/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/CNN%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    <id>https://liaoooyx.com/2020/03/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/CNN%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</id>
    <published>2020-03-02T00:00:00.000Z</published>
    <updated>2020-04-15T17:31:01.833Z</updated>
    
    <content type="html"><![CDATA[<p>实验步骤和分析</p><a id="more"></a><h3 id="Clarification"><a href="#Clarification" class="headerlink" title="Clarification"></a>Clarification</h3><ul><li><p>This coursework is running and testing on Google Colab. </p></li><li><p>Because the test set is extracted randomly from the dataset, the accuracy on the test set cannot precisely represent the performance of model. But it is still a reasonable approach for evaluating the performance of model.</p></li><li><p>The evaluation on the test set is using the model at final epoch in task 1-3 using the model with lowest loss on validation set in task 4.</p></li></ul><h3 id="Task-1-Experiments"><a href="#Task-1-Experiments" class="headerlink" title="Task 1: Experiments"></a><strong>Task 1: Experiments</strong></h3><h4 id="Subtask-1-1-How-does-the-number-of-layers-affect-the-training-process-and-test-performance-Try-between-2-and-5-layers"><a href="#Subtask-1-1-How-does-the-number-of-layers-affect-the-training-process-and-test-performance-Try-between-2-and-5-layers" class="headerlink" title="Subtask 1-1: How does the number of layers affect the training process and test performance? Try between 2 and 5 layers."></a><strong>Subtask 1-1: How does the number of layers affect the training process and test performance? Try between 2 and 5 layers.</strong></h4><p>Firstly, to clarify the architecture of 4 CNNs for the experiments, I assume the layer 4 and 5 are following the pattern of given layer 1-3 —— the output channels of each layer are added by 8 from its input channels. The parameters of each layer are listed in table 1. Each convolutional layer is followed by the same ReLU, max-pooling and dropout (see table 2). After the last convolutional layer, there are 2 fully connected layers (see table 3). Other relevant parameters are shown in table 4.</p><p>In short, the control variable is only the number of layers and its parameters, everything else, even the increasing pattern of the layer’s parameters, keep the same as possible.</p><p>Table 1: Parameters of each convolutional layer.</p><div class="table-container"><table><thead><tr><th>Layer 1</th><th>Input channels = 3, output channels = 16,  kernel size = 3</th></tr></thead><tbody><tr><td>Layer 2</td><td>Input channels = 16, output channels = 24,  kernel size = 4</td></tr><tr><td>Layer 3</td><td>Input channels = 24, output channels = 32,  kernel size = 4</td></tr><tr><td>Layer 4</td><td>Input channels = 32, output channels = 40,  kernel size = 4</td></tr><tr><td>Layer 5</td><td>Input channels = 40, output channels = 48, kernel  size = 4</td></tr></tbody></table></div><p>Table 2: Functional layers followed by each layer, and relevant parameters.</p><div class="table-container"><table><thead><tr><th>ReLU</th><th></th></tr></thead><tbody><tr><td>Max-pooling</td><td>Kernel size = 2</td></tr><tr><td>Dropout</td><td>Rate = 0.3</td></tr></tbody></table></div><p>Table 3: Fully connected layer, and relevant parameters.</p><div class="table-container"><table><thead><tr><th>Fully connected layer 1</th><th>Input = (flattened output of last  convolutional layer), output = 512</th></tr></thead><tbody><tr><td>Fully connected layer 2</td><td>Input = 512, output = 10</td></tr></tbody></table></div><p>Table 4: Other relevant parameters and methods.</p><div class="table-container"><table><thead><tr><th>Other relevant parameters and methods.</th></tr></thead><tbody><tr><td>Learning  rate = 0.001, Batch size = 16, momentum=0.9  Optimizer = SGD, Loss function = CrossEntropyLoss</td></tr></tbody></table></div><p>In the subtask 1-1, table 5 compares the accuracy of CNNs with a different number of maximal layers, visualizing their confusion matrixes and Loss curves. For each CNNs, the training will stop when the model converges (pre-train the model to find out the most suitable training epochs —— the point when loss curve start increasing, which means overfitting and losing generalization on unseen data). For example, 2-layer CNN will converge at 4th epoch and achieve 49.89% accuracy on the test set, and 5-layer CNN can achieve 63.17% of accuracy on the test set, and this 5-layer CNN will converge at 40th epoch.</p><p>Table 5. Range of accuracy on the test set, after 3 times execution for each architectures (different number of maximal layers).</p><div class="table-container"><table><thead><tr><th>Maximal  layer</th><th>The highest  accuracy (%)</th><th>The lowest  accuracy (%)</th><th>Number of  Epochs when converge</th></tr></thead><tbody><tr><td>Layer 2</td><td>49.89</td><td>45.06</td><td>4</td></tr><tr><td>Layer 3</td><td>53.22</td><td>53.11</td><td>10</td></tr><tr><td>Layer 4</td><td>57.17</td><td>55.94</td><td>15</td></tr><tr><td>Layer 5</td><td>63.17</td><td>59.00</td><td>40</td></tr></tbody></table></div><p>Convolution layer is used to abstract feature and simplify the complexity of the network. A different number of filters and layers can have different performance. The results shown in table 5 indicate that with the increment of layers mentioned above, the accuracy of the model on the test set also increased. It is reasonable in this case because more layer will output more feature map to represent the original image and for classifying</p><p>In figure 1, we can have a clearer understanding of how the models with different layer perform when predicting the class on the test set. On confusion matrix (a) (b) (c) (d), the percentages of a misclassified image are decreasing when the CNN go deeper (seeing the light cells excluding diagonal getting dark from (a) to (b)). The loss curves (e) (f) (g) (h) in which the lines tend to be flat are used to detect converge.</p><p>The best performance is given by 5-layer CNN, achieving 63.17% accuracy on the test set at 40th epochs. The parameters are listed in Table 1-5. This 5-layer CNN will be used in task 2 &amp; 3, called CNN-5L.</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduxi6uxvsj31320ioe5h.jpg" alt="截屏2020-04-15 下午5.43.01"></p><p>Figure 1. Confusion matrix and loss curves of CNNs at 1st execution —— (a) (e) 2-layer, (b) (f) 3-layer, (c) (g) 4-layer, (d) (h) 5-layer</p><h4 id="Subtask-2-Choose-one-more-architectural-element-to-test"><a href="#Subtask-2-Choose-one-more-architectural-element-to-test" class="headerlink" title="Subtask 2: Choose one more architectural element to test"></a><strong>Subtask 2: Choose one more architectural element to test</strong></h4><p>In subtask2, the report will test with 3 different elements. The first experiment is to test the performance of different batch size in 3-layer CNN. The second experiment is to increase the number of fully connected layers in 5-layer CNN. The third experiment is to increase the parameters for each convolutional layer.</p><ol><li><p>The first experiment is based on 3-layer convolutional neural, keeping other parameters same as mentioned above, and train the model with different batch size (see table 6). The model will be pre-trained to find out the number of epoch to converge before the evaluation of accuracy on the test set.</p><p>Intuitively, a larger batch size means the number of iterations required to run an epoch is reduced and therefore speed up the processing. If the batch size is within an ideal range, a larger the batch size will take more points into account, and therefore can make the gradient direction more accurate with less fluctuation. However, based on the result, to achieve similar accuracy, it needs more epochs to run.</p></li></ol><p>Table 6 Comparison of accuracy and converge epochs for different batch size</p><div class="table-container"><table><thead><tr><th>Batch size</th><th>Converge epochs</th><th>Accuracy</th></tr></thead><tbody><tr><td>8</td><td>7</td><td>49.44</td></tr><tr><td>16</td><td>10</td><td>53.22</td></tr><tr><td>32</td><td>13</td><td>51.28</td></tr></tbody></table></div><p>Figure 2: Confusion matrixes of 8 batches CNN (a), 16 batches CNN (b) and 32 batches CNN (c).</p><ol><li>The result of 5-layer architecture seems good. In this experiment, based on the previous 5-layer network, a new CNN with one more fully connected layer with the same 512 input and output channels is tested (see table 7.).  The accuracy of this model on the test set is 59.22% for the first time and 59.59% for the second time. It seems that the performance does not have much difference comparing with CNN-5L (the original 5-layer CNN).</li></ol><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduxixih8lj311m0d6qoo.jpg" alt="截屏2020-04-15 下午5.43.29"></p><p>Table 7. Parameters of 3 fully connected layers</p><div class="table-container"><table><thead><tr><th>Fully connected layer 1</th><th>Input = (flattened output of last  convolutional layer), output = 512</th></tr></thead><tbody><tr><td>Fully connected layer 2</td><td>Input = 512, output = 512</td></tr><tr><td>Fully connected layer 3</td><td>Input = 512, output = 10</td></tr></tbody></table></div><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy0gqk30j30um0ec49z.jpg" alt="截屏2020-04-15 下午6.00.33"></p><p>Figure 3. Confusion matrix (a) and loss curve (b) in experiment 2 (with 59.22% ACC on the test set).</p><ol><li>The third experiment is to increase the parameters for each convolutional layer —— multiply by 4 (see table 8). Larger channels values normally mean that the model can extract more features from an image. After pre-trained the CNN, the loss curve shows the model will converge at around 23rd epoch. Running 23rd epoch again, the model got 61.22% accuracy on the test set. It seems slightly better than the model in experiment 2 but still stays in the potential accuracy range of CNN-5L.</li></ol><p>Table 8. Parameters of each layer in the 5-layer CNN</p><div class="table-container"><table><thead><tr><th>Layer 1</th><th>Input channels = 3, output channels = 64,  kernel size = 3</th></tr></thead><tbody><tr><td>Layer 2</td><td>Input channels = 64, output channels = 96,  kernel size = 4</td></tr><tr><td>Layer 3</td><td>Input channels = 96, output channels = 128,  kernel size = 4</td></tr><tr><td>Layer 4</td><td>Input channels = 128, output channels = 160,  kernel size = 4</td></tr><tr><td>Layer 5</td><td>Input channels = 160, output channels = 196,  kernel size = 4</td></tr></tbody></table></div><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy110xrwj30uw0e0n8i.jpg" alt="截屏2020-04-15 下午6.01.09"></p><p>Figure 4: Confusion matrix (a) and loss curve (b) in experiment 3.</p><h3 id="Task-2-Filter-visualization"><a href="#Task-2-Filter-visualization" class="headerlink" title="Task 2: Filter visualization"></a><strong>Task 2: Filter visualization</strong></h3><p>The filters before training are initialized randomly (see figure 5-a). During the training process, the filters will be updated by gradient descent and backpropagation. In figure 5, there are significant differences between the filters before training (5-a) and halfway training (5-b), which means the model change a lot during the process. However, comparing with the filters in halfway training and after training, there only slight differences, which means that the filters of the first layer of this specific model are close to the optimal values (but possibility local optimum instead of global optimum). This phenomenon can also be observed on loss and accuracy curve (see figure 6). It is clear that the differences between 0 and 20th epochs are significant but much smaller between 20th and 40th epochs (e.g. compare the gaps between 3 lines in figure 6-a).</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy1ia24zj311s0dw7jy.jpg" alt="截屏2020-04-15 下午6.01.39"></p><p>Figure 5: Filters before training (a), halfway training (b) and after training (c), outputting from Conv2d without ReLU.</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy2hyckcj311y0euakn.jpg" alt="截屏2020-04-15 下午6.02.35"></p><p>Figure 6: Loss (a) and accuracy (b) curve in CNN-5L.</p><h3 id="Task-3-Feature-map-visualization"><a href="#Task-3-Feature-map-visualization" class="headerlink" title="Task 3: Feature map visualization"></a><strong>Task 3: Feature map visualization</strong></h3><p>The number of feature maps equals to that of output channels, each filter will extract a type of feature map. With the network goes deeper, feature maps will become smaller and blurrier, but also means being more representative than the previous layer. For example, figure 7 (a) is showing the image of a banana. It is obvious that the feature maps at 6th row are smaller and more abstractive than the 2nd row. Loot at the graffiti on the banana peel in the original image. The information of these graffiti which is unrelated for identifying and classifying is gradually removed from the feature maps as the network goes deeper.</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy3hpsi1j30u00u6b29.jpg" alt="截屏2020-04-15 下午6.03.21"></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy3qjgaoj313e0eejuh.jpg" alt="截屏2020-04-15 下午6.03.40"></p><p>Figure 7: Original and normalized image (1), feature maps after each CONV layer without ReLU (2-6), and feature map before fully connected layer (7), banana (a) and mug (b)</p><h3 id="Task-4-Improving-network-performance"><a href="#Task-4-Improving-network-performance" class="headerlink" title="Task 4: Improving network performance"></a><strong>Task 4: Improving network performance</strong></h3><p>In this task, inspired by AlexNet, this improved model (call CNN-task4) can achieve 69.11% accuracy on the test set. The relevant structure and parameters are listed below (see table 9). Noticed that the accuracy on the test set is evaluated by the model achieving the lowest loss on validation set during training (save the model at that epoch and reload it in evaluation).</p><p>Table 9: Structure and parameters of CNN-task4</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy4h8ikej31240pgaej.jpg" alt="截屏2020-04-15 下午6.04.27"></p><p>One of the adjustments is using another optimizer Adam, which support adaptive learning rate, updating the learning rate during learning. The reason behind is that adaptive learning rate will slow down the stride of gradient descent during the training. Giving a small stride can help reduce the possibility of missing and fluctuating around the (local or global) optimal solution. From figure 8, we can notice that CNN-task4 with 0.0001 initial learning rate can give a better loss curve than the others.</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy4s62maj310c09swh3.jpg" alt="截屏2020-04-15 下午6.04.48"></p><p>Figure 8: Loss curve of original 5-layer CNN with 0.01 LR (a)，CNN-task4 with 0.001 initial LR (b)，CNN-task4 with 0.0001 initial LR (c)</p><p>Another adjustment is to move the dropout layer from convolution layers to fully connected layers. One reason is that the parameters in the convolution layer are quite few but highly relative. The pixels within a certain area of an image in convolutional layers are sharing the same information, which means that the discarded information may still be retained by nearby pixels. Using dropout layer in convolution layer may only help control the noise of the input images but not improving the generalization on unseen data (see figure 9 (d)). On the other hand, if the feature maps between 2 layers are highly abstracted when passing forward such as convolution operation with large kernel size or stride, or max-pooling operation, using dropout will, on the contrary, cause the feature maps to lose important information for classifying. And therefore, the performance of the model will decline, especially causing a significant decrease of accuracy on the test set and fluctuation of loss curve on the validation set (see figure 9 (c)).</p><p>Table 10 is comparing the accuracy on the test set of 4 different dropout layer placing strategies. The 2nd and 4th row are showing that adding dropout after convolution layer 3 &amp; 4, which have small kernel and stride, having similar performance. However, once the dropout layers are placed after max-pooling layer (see 3rd row). The accuracy of the model on the test set will decline from around 65% to 50%.</p><p>Table 10, Position of dropout layer (based on the CNN-task4 in table 9) and the highest accuracy on the test set after 30 epochs training</p><div class="table-container"><table><thead><tr><th>Dropout(0.5)  Before FC1&amp;2</th><th>69.11%</th><th>Figure 9 (a)</th></tr></thead><tbody><tr><td>No dropout</td><td>66.17%</td><td>Figure 9 (b)</td></tr><tr><td>Dropout(0.3)  after max-pooling layer 1&amp;2&amp;3</td><td>50.22%</td><td>Figure 9 (c)</td></tr><tr><td>Dropout(0.3)  after CONV 3&amp;4</td><td>64.94%</td><td>Figure 9 (d)</td></tr></tbody></table></div><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gduy5ahtb9j311608o76i.jpg" alt="截屏2020-04-15 下午6.05.16"></p><p>Figure 9: Loss curve of CNN-task4, with dropout before FC1&amp;2 (original) (a), without dropout (b)，with 0.3 dropout after max-pooling (c)，with 0.3 dropout after CONV 3&amp;4 (d).</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;实验步骤和分析&lt;/p&gt;
    
    </summary>
    
    
      <category term="人工智能" scheme="https://liaoooyx.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="机器学习" scheme="https://liaoooyx.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="图像分类" scheme="https://liaoooyx.com/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
      <category term="CNN" scheme="https://liaoooyx.com/tags/CNN/"/>
    
      <category term="AI" scheme="https://liaoooyx.com/tags/AI/"/>
    
  </entry>
  
</feed>
