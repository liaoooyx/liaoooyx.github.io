<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/03/hello-world/"/>
      <url>/2020/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/03/Big%20Data%20System/16%20APACHE%20SPARK/"/>
      <url>/2020/03/Big%20Data%20System/16%20APACHE%20SPARK/</url>
      
        <content type="html"><![CDATA[<h2 id="16-APACHE-SPARK"><a href="#16-APACHE-SPARK" class="headerlink" title="16 APACHE SPARK"></a>16 APACHE SPARK</h2><h4 id="MapReduce的限制"><a href="#MapReduce的限制" class="headerlink" title="MapReduce的限制"></a>MapReduce的限制</h4><ol><li>MapReduce编程对许多人来说都是有难度的</li><li>性能通常会遇到瓶颈（因为批处理不适合所需的用例）</li></ol><p>这导致MapReduce不适用于大型应用程序。因此出现了多种专业系统的发展。</p><p>因此Spark面世——将所有的专业系统整合到一起</p><h2 id="Apache-Spark"><a href="#Apache-Spark" class="headerlink" title="Apache Spark"></a>Apache Spark</h2><p>是一个通用目的数据处理引擎，为不同的需求设计，</p><ul><li>更快的批处理</li><li>应用需要交互式查询处理</li><li>处理流数据</li><li>系统需要迭代算法</li></ul><p>特征：</p><ul><li>是in-memory的计算引擎（充分利用内存）</li><li>用磁盘时比Hadoop快10倍，用内存时比Hadoop快100倍</li></ul><h4 id="Spark-结构"><a href="#Spark-结构" class="headerlink" title="Spark 结构"></a>Spark 结构</h4><p>Spark不提供任何类似HDFS的存储或者资源管理能力，它是一个以几乎实时的方式，处理大量数据的，统一的框架</p><p>三个主要的分层：</p><ol><li>生态层：基于核心层执行操作的库<ul><li>Spark SQL， Spark Streaming， BlinkDB， Spark ML， GraphX， Tachyon</li></ul></li><li>核心层：框架的通用层，它定义了所有的基础功能，其他功能和扩展都是基于这一层创建的<ul><li>Spark Core，Spark DataFrame API</li></ul></li><li>资源管理层：Spark以独立模式（单节点群集设置）管理自己的资源。 但是对于分布式集群模式，它可以与YARN之类的资源管理模块集成在一起。<ul><li>Standalone，YARN，Mesos</li></ul></li></ol><p>结构：</p><ul><li>Spark应用程序在集群上作为独立的进程集运行，由SparkContext对象（也称为驱动程序）协调。<ul><li>每个应用程序都有其自己的执行程序进程，这些进程在整个应用程序期间保持不变，并在多个线程中运行任务。</li><li>这具有将应用程序彼此<strong>隔离</strong>的好处——每个驱动程序调度自己的任务，并且来自不同应用程序的任务在不同的JVM中运行。</li><li>但是，这也意味着，如果不将数据写入外部存储系统，则无法在不同的Spark应用程序（SparkContext实例）之间共享数据。</li></ul></li><li>SparkContext负责将应用程序代码（JAR或Python文件）和任务发送给执行程序。</li><li>每个驱动程序都有一个Web UI，通常在端口4040上，该Web UI显示有关正在运行的任务，执行程序和存储使用情况的信息。</li></ul><h4 id="语言支持"><a href="#语言支持" class="headerlink" title="语言支持"></a>语言支持</h4><p>提供了Java、Scala、Python的high-level APIs</p><p>提供了优化引擎支持：产生执行图，结构化数据处理的高级工具</p><h3 id="Spark-Core"><a href="#Spark-Core" class="headerlink" title="Spark Core"></a>Spark Core</h3><p>处理：</p><ul><li><p>内存管理和容错</p></li><li><p>对集群上的任务jobs进行调度，分配，监控</p></li><li><p>与存储系统进行交互</p></li></ul><p>它也实现了弹性分布式数据库（RDDs）的关键概念。</p><ul><li>RDD是对象的不可变容错分布式集合，可以并行操作。</li><li>RDD可以包含任何类型的对象，并且可以通过加载外部数据集或从驱动程序分配集合来创建</li><li>RDD是分布在整个集群中的数据集的表示。</li></ul><h4 id="弹性分布式数据库-RESILIENT-DISTRIBUTED-DATABASES（RDDs）"><a href="#弹性分布式数据库-RESILIENT-DISTRIBUTED-DATABASES（RDDs）" class="headerlink" title="弹性分布式数据库 RESILIENT DISTRIBUTED DATABASES（RDDs）"></a>弹性分布式数据库 RESILIENT DISTRIBUTED DATABASES（RDDs）</h4><ul><li>RDDs可以被存储在内存或磁盘中，主要的性能来自于将数据存在内存中<ul><li>诸如MapReduce之类的当前框架提供了许多用于<u>访问集群的计算资源的抽象</u>，但是缺乏<u>利用分布式内存的抽象。</u></li></ul></li><li>Spark的优势：<ul><li>数据重用在许多迭代ML算法中很常见，例如K-means聚类。另一个示例是当用户对同一数据子集运行多个临时查询时。</li></ul></li><li>在Hadoop（和其他框架）中，在不同作业之间<u>重用数据的唯一方法</u>是将其写入外部存储系统（例如HDFS）。使用内存中的RDD，可以更快地处理数据。可以存储在分布式内存中的数据大小仅受群集大小限制。</li></ul><h4 id="RDD操作"><a href="#RDD操作" class="headerlink" title="RDD操作"></a>RDD操作</h4><ul><li>Transformations 转换：在RDD上执行并产生包含结果的新RDD的操作（例如，映射，过滤器，联接，联合等）</li><li>Actions 行动：在RDD上运行计算后返回值的操作（例如reduce，count，first等）。</li></ul><p>Spark上的转换操作是lazy的，并不会立即执行。只有当行动被调用时，转换才会执行。执行的结果将返回给驱动程序。该设计能提高Spark的运行效率</p><h4 id="Lazy-（Transformations）评估"><a href="#Lazy-（Transformations）评估" class="headerlink" title="Lazy （Transformations）评估"></a>Lazy （Transformations）评估</h4><p>转换是对数据的操纵。 它们从一个RDD转换到下一个。</p><p>比如：一个Action查询数据集中有多少数据，Spark在收到查询后，才会进行Transformations，再将结果返回给Action</p><h4 id="RDD用例"><a href="#RDD用例" class="headerlink" title="RDD用例"></a>RDD用例</h4><p>假设我们必须在大量的Web服务器访问日志中查找错误代码。</p><p>我们可以使用MapReduce，Storm或我们喜欢的任何框架来读取文件集，查找特定的错误代码，并将带有该代码的所有行放入存储设备（例如HDFS）</p><p>然后，当我们分析这些结果数据时，我们可能希望将错误与其他用户活动进行交叉引用cross-reference。 这将要求我们再次获取文件，处理并提供结果等。</p><p>对于传统方式需要重复对磁盘进行查询，而RDD是将数据存储在内存中，并提供了重新查询所用子集的功能。 </p><p>内存中数据存储非常适合许多迭代和交互式算法</p><h4 id="RDD容错"><a href="#RDD容错" class="headerlink" title="RDD容错"></a>RDD容错</h4><p>设计RDD的主要挑战是定义一个可提供有效容错能力的编程接口。</p><ul><li>故障是系统中的缺陷defect。</li><li>错误error是系统边界内观察到的行为与系统的指定行为之间的<strong>差异</strong></li><li>故障failure是系统当时<u>显示的行为</u>与<u>规范相反</u>的<strong>实例</strong></li></ul><p>现有解决方案提供基于细粒度更新的容错接口。</p><ul><li><p>使用这样的系统，获得容错的唯一方法，是跨计算机复制数据或跨计算机记录更新。</p></li><li><p>这些方法是数据密集型的——高带宽用于在群集网络上移动数据。</p></li></ul><p>RDD提供了基于粗粒度转换的接口（例如，映射，过滤器，联接）。 这些转换将相同的操作应用于许多数据项。</p><ul><li><p>这允许通过记录用于构建数据库的转换而不是实际数据本身来有效地应用容错。</p></li><li><p>如果RDD的分区丢失，则RDD具有有关如何从其他RDDS派生出来的足够信息，以便仅重新计算该分区。</p></li></ul><h4 id="RDD的限制"><a href="#RDD的限制" class="headerlink" title="RDD的限制"></a>RDD的限制</h4><p>不适合非迭代应用程序，因为Spark的主要性能提升是内存数据的迭代。</p><p>RDD也不太适合对共享状态进行异步细粒度更新的应用程序，例如Web应用程序的存储系统或增量Web爬虫。批量转换对于小的更新是浪费的。</p><h4 id="传统的流处理管道"><a href="#传统的流处理管道" class="headerlink" title="传统的流处理管道"></a>传统的流处理管道</h4><ol><li>从数据源接收流数据</li><li>在集群上并行处理流数据</li><li>将数据输出到下游的系统</li></ol><p>大多数传统的流处理器使用连续操作器（continuous operator）模型进行数据处理</p><ul><li>一组工作节点，每个工作节点运行一个或多个连续操作器</li><li>每个连续的操作器一次处理流数据一个记录，然后将记录转发给管道中的其他操作器。</li><li>有源操作器用于从采集系统接收数据，而下沉操作器则输出到下游系统。</li></ul><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcwbap19kxj30o80e4wii.jpg" alt="截屏2020-03-16下午6.05.24"></p><p>比如Apache Storm；这是一个非常优雅的解决方案，但是随着系统变得越来越大以及大数据分析的复杂性增加，使用此模型面临着越来越多的挑战。</p><h4 id="传统流数据处理系统的问题"><a href="#传统流数据处理系统的问题" class="headerlink" title="传统流数据处理系统的问题"></a>传统流数据处理系统的问题</h4><p><strong>故障和任务被卡主（straggling）：</strong></p><ul><li><p>随着规模扩大，集群节点故障或者无法预测的变慢（比如stragglers，掉队者）的可能性会增加</p></li><li><p>系统需要能自动从故障和卡住的任务（stragglers）中恢复，以实时提供结果</p></li><li><p>将<u>连续操作器</u>静态分配给工作节点，会使传统系统很难从故障和卡住的任务（stragglers）中快速恢复。</p></li></ul><p><strong>负载平衡：</strong></p><ul><li>Workers之间的处理负载分配不均，会导致连续操作器系统出现瓶颈。</li><li>这在大型集群和动态变化的工作负载中更可能发生。</li><li>系统需要能够根据工作负载动态调整资源分配。</li></ul><p><strong>流、批处理、交互式工作负载的统一：</strong></p><ul><li>在许多使用案例中，以交互方式查询流数据或将其与静态数据集（例如，预先计算的模型）结合起来很有吸引力。</li><li>在连续的操作器系统中，这很难做到，因为它们并非旨在动态地为临时查询引入新的运算器</li><li>这需要一个可以结合批处理，流式处理和交互式查询的引擎。</li></ul><p><strong>高级分析：</strong></p><ul><li><p>复杂的工作负载需要连续的学习和更新数据模型，甚至是用sql查询最新的流数据视图</p></li><li><p>使这些分析任务具有通用抽象（API），能让开发人员的工作更加轻松</p></li></ul><h4 id="离散流-Discretized-Streams-——-解决方案"><a href="#离散流-Discretized-Streams-——-解决方案" class="headerlink" title="离散流 Discretized Streams —— 解决方案"></a>离散流 Discretized Streams —— 解决方案</h4><p>为了解决这些问题，Spark Streaming组件使用称为离散化流的新架构，该架构直接利用了Spark引擎的库和容错能力。</p><ul><li>Spark Streaming接收器不会一次读取单个数据记录，而是将数据流离散化为亚秒级的微小批量（RDDs）。（即接收者并行接受数据并将其缓冲在Spark worker节点的内存中）。然后，Spark引擎运行简短的任务（数十毫秒）以处理批处理并将结果输出到其他系统。</li></ul><p>与连续操作器模型不同，Spark任务根据数据的位置和可用资源动态分配给工作人员。这是为了实现更好的负载平衡和更快的故障恢复。</p><ul><li>每个数据的batches都是一个RDD。这允许使用任何Spark代码或库来处理流数据。</li></ul><h4 id="DSP好处：动态负载平衡"><a href="#DSP好处：动态负载平衡" class="headerlink" title="DSP好处：动态负载平衡"></a>DSP好处：动态负载平衡</h4><p>将数据划分为多个微批，可以将计算能力以细粒度的方式分配给资源。</p><p>以字数统计为例：分区不均衡的流会导致某个节点过载，达到瓶颈；而将数据离散Discretized 后，可以根据节点的负载对任务进行分配和调度。</p><h4 id="DSP好处：从故障和卡住的任务中快速恢复"><a href="#DSP好处：从故障和卡住的任务中快速恢复" class="headerlink" title="DSP好处：从故障和卡住的任务中快速恢复"></a>DSP好处：从故障和卡住的任务中快速恢复</h4><p>传统流：</p><ul><li>万一发生节点故障，传统系统必须在另一个节点上重新启动发生故障的连续运算器，并重播数据流的某些部分以重新计算丢失的信息。（请注意，在重播后新节点赶上之前，管道无法继续进行。）</li></ul><p>Spark流（离散流）</p><ul><li><p>可以在集群中的所有其他节点上并行重新启动失败的任务，从而将所有重新计算均匀地分布在多个节点上，从而从故障中恢复。</p><p><u>计算已经离散化为可以在任何地方运行而不会影响正确性的任务。</u></p></li></ul><h4 id="DSP好处：流、批处理、交互的统一"><a href="#DSP好处：流、批处理、交互的统一" class="headerlink" title="DSP好处：流、批处理、交互的统一"></a>DSP好处：流、批处理、交互的统一</h4><p>Spark Streaming中的关键编程接口是DStream或分布式流。 每一批流数据都由RDD表示，因此DStream只是一系列RDD。</p><p>因此，我们可以使用任何Spark函数处理DStream。例如，我们可以将DStream与预先计算的静态数据集（已加载到另一个RDD中）结合在一起</p><p>数据批存储在workers的内存中，因此可以按需交互查询。<br>批处理，流和交互式工作负载的这种统一在Spark中非常简单，但是在没有<u>工作负载的通用接口</u>的系统中很难实现</p><h4 id="DSP好处：高级分析"><a href="#DSP好处：高级分析" class="headerlink" title="DSP好处：高级分析"></a>DSP好处：高级分析</h4><p>DStreams生成的RDD可以转换为DataFrames并使用SQL查询</p><p>例如，使用Spark的JDBC驱动程序，可以公开流的状态，并支持SQL语句进行查询。</p><p>然后，通过JDBC服务器，就能够以交互方式（比如SQL命令、GUI）查询持续更新的表。</p><h4 id="Spark流：性能"><a href="#Spark流：性能" class="headerlink" title="Spark流：性能"></a>Spark流：性能</h4><p>实际上，Spark Streaming具有批处理数据和利用Spark引擎的能力，可以使吞吐量与其他流系统相当或更高。</p><ul><li>Spark Streaming可以实现低至几百毫秒的延迟。</li></ul><p>开发人员有时会问微批处理是否会固有地增加过多的延迟。</p><ul><li>实际上，批处理延迟仅是端到端管道延迟的一小部分。</li></ul><ul><li>例如，许多应用程序在滑动窗口上计算结果，甚至在COS中，该窗口也仅定期更新（例如，每2秒滑动20秒的窗口）。</li></ul><ul><li>许多管道等待很短的时间来处理延迟或乱序的数据。</li></ul><ul><li>最后，任何自动触发算法都倾向于等待一段时间才能触发。</li></ul><p>同样，DStreams带来的吞吐量提高通常意味着您需要更少的计算机来处理相同的工作负载。</p>]]></content>
      
      
      <categories>
          
          <category> 1 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/13_ CAP定理</title>
      <link href="/2020/03/Big%20Data%20System/13_%20CAP%E5%AE%9A%E7%90%86/"/>
      <url>/2020/03/Big%20Data%20System/13_%20CAP%E5%AE%9A%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="CAP定理"><a href="#CAP定理" class="headerlink" title="CAP定理"></a>CAP定理</h2><blockquote><p>在<a href="https://zh.wikipedia.org/wiki/理論計算機科學" target="_blank" rel="noopener">理論計算機科學</a>中，<strong>CAP定理</strong>（CAP theorem），又被稱作<strong>布魯爾定理</strong>（Brewer’s theorem），它指出對於一個<a href="https://zh.wikipedia.org/wiki/分布式计算" target="_blank" rel="noopener">分布式计算系統</a>來說，不可能同時滿足以下三點：<a href="https://zh.wikipedia.org/wiki/CAP定理#cite_note-Lynch-1" target="_blank" rel="noopener">[1]</a><a href="https://zh.wikipedia.org/wiki/CAP定理#cite_note-2" target="_blank" rel="noopener">[2]</a></p><ul><li>一致性（<strong>C</strong>onsistency） （等同于所有节点访问同一份最新的数据副本）</li><li><a href="https://zh.wikipedia.org/wiki/可用性" target="_blank" rel="noopener">可用性</a>（<strong>A</strong>vailability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）</li><li><a href="https://zh.wikipedia.org/w/index.php?title=网络分区&action=edit&redlink=1" target="_blank" rel="noopener">分区容错性</a>（<strong>P</strong>artition tolerance）（以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择<a href="https://zh.wikipedia.org/wiki/CAP定理#cite_note-3" target="_blank" rel="noopener">[3]</a>。）</li></ul><p>根據定理，分佈式系統只能滿足三項中的兩項而不可能滿足全部三項<a href="https://zh.wikipedia.org/wiki/CAP定理#cite_note-4" target="_blank" rel="noopener">[4]</a>。理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。</p></blockquote><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>客户端将值写入任何服务器并获得响应后，它期望从其读取的任何服务器取回该值（或更新鲜的值）</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcv3kjxahwj319q0lygnv.jpg" alt="截屏2020-03-15下午4.52.25"></p><p>为了保证该特性，客户端在向其中一个服务器写入后，该服务器需要与其他服务器同步，在同步完成后，才会通知客户端已成功写入。</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcv3kxx6tij318w0lqwh7.jpg" alt="截屏2020-03-15下午4.52.58"></p><h3 id="可用性"><a href="#可用性" class="headerlink" title="可用性"></a>可用性</h3><blockquote><p>系统中非故障节点收到的每个请求都必须导致响应</p><p>every request received by a non-failing node in the system must result in a response</p></blockquote><p>在可用的系统中，如果我们的客户端向服务器发送请求并且服务器没有崩溃，则服务器最终必须响应客户端。不允许服务器忽略客户端的请求。</p><h3 id="分区容错"><a href="#分区容错" class="headerlink" title="分区容错"></a>分区容错</h3><blockquote><p>网络将被允许任意丢失从一个节点发送到另一节点的许多消息</p><p>the network will be allowed to lose arbitrarily many messages sent from one node to another</p></blockquote><p>即一个节点向另外一个节点发送的消息丢失是可接受的，下图展示当所有消息都丢失的情况：</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcv3sa21zej30yo08k752.jpg" alt="截屏2020-03-15下午4.59.59"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/13 NOSQL数据库_GOOGLE_BIGTABLE_HBAS</title>
      <link href="/2020/03/Big%20Data%20System/13%20NOSQL%E6%95%B0%E6%8D%AE%E5%BA%93_GOOGLE_BIGTABLE_HBAS/"/>
      <url>/2020/03/Big%20Data%20System/13%20NOSQL%E6%95%B0%E6%8D%AE%E5%BA%93_GOOGLE_BIGTABLE_HBAS/</url>
      
        <content type="html"><![CDATA[<h2 id="13-NOSQL-DATABASES-GOOGLE-BIGTABLE-HBAS"><a href="#13-NOSQL-DATABASES-GOOGLE-BIGTABLE-HBAS" class="headerlink" title="13 NOSQL DATABASES: GOOGLE BIGTABLE / HBAS"></a>13 NOSQL DATABASES: GOOGLE BIGTABLE / HBAS</h2><p>大数据系统的规模对数据库空间的要求有很大挑战</p><p>传统的关系数据库管理系统（Relational Database Management System：<em>RDBMS</em>）无法扩展为适应真正的massive级别数据：ACID原则不适合大规模的数据，CAP定理中描述的问题</p><h4 id="CAP定理："><a href="#CAP定理：" class="headerlink" title="CAP定理："></a>CAP定理：</h4><ul><li>一致性：所有客户都能看到最新的数据，不管执行过什么操作（比如更新或删除）</li><li>可用性：即使某些节点发送错误，系统也需要继续客户的操作</li><li>分区容错：即使网络或消息发送错误，系统也需要继续执行可续操作（比如一个节点向另一个节点发送的消息，允许发送错误并被丢弃）</li></ul><h4 id="ACID-和-BASE"><a href="#ACID-和-BASE" class="headerlink" title="ACID 和 BASE"></a>ACID 和 BASE</h4><p>ACID：</p><ul><li>Atomic 原子性：事务的所有操作都成功，不然就回滚</li><li>Consistent 一致性：事务不能使数据库的最终状态出现不一致</li><li>Isolated 隔离性：事务使独立的，不能影响其他事务</li><li>Durable 容忍性：即使服务器重新启动等，已完成的事务也会保留。</li></ul><p>BASE</p><ul><li><strong>B</strong>asic <strong>A</strong>vailability 基础可用性：系统在CAP定理方面，保证系统的可用性</li><li><strong>S</strong>oft-state 软状态：系统的状态会随时间改变，即使没有输入（因为要确保最终一致性）</li><li><strong>E</strong>ventual consistency 最终一致性：只要数据库最终变得一致，在每个事务之后就不需要一致性。</li></ul><h4 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h4><p>可以被分成4类：Key-value stores、Column-oriented databases、Document databases、Graph databases</p><h3 id="GOOGLE-BIGTABLE-HBASE"><a href="#GOOGLE-BIGTABLE-HBASE" class="headerlink" title="GOOGLE BIGTABLE (HBASE)"></a>GOOGLE BIGTABLE (HBASE)</h3><p>BigTable是第一个（也是影响力最大的）面向列的NoSQL数据库之一。于2006年发布。它旨在可靠地扩展到数千台计算机上的PB级数据。</p><p>在60多种Google产品中使用，包括Google Earth，Google Analytics（分析）和Youtube。</p><p>BigTable具有极大的影响力，它催生了一个非常受欢迎的开源克隆：HBase。</p><p>设计为与MapReduce BigTable兼容并互补，可为MapReduce提供基于键的快速查找</p><h4 id="关键特征"><a href="#关键特征" class="headerlink" title="关键特征"></a>关键特征</h4><ul><li>BigTable是一个简单的概念 — 映射两个任意字符串值（行键和列键）以及时间戳，并将其放入关联的任意字节数组中：（行：字符串，列：字符串，时间：int64）-&gt;字符串</li><li>在NoSQL分类中，BigTable是面向列的数据库。<br>它是高度分布式的，没有可用的连接，并且假定“一次写入多次读取”。</li><li>数据模型是“稀疏，分布式，持久的多维排序图”<br>a sparse, distributed, persistent multi-dimensional sorted map”</li><li>实际上，这意味着您可以通过提供行ID，列名和时间戳来访问BigTable中的任何单元（用于版本控制–您保留同一单元的过去版本）。<br>提供这些参数，BigTable会很快将结果返回给您。</li></ul><h4 id="Tablets"><a href="#Tablets" class="headerlink" title="Tablets"></a>Tablets</h4><ul><li>单元的每个新版本都会增加时间戳。 这允许您设置策略，例如“仅保留最新的n个版本”或“仅保留自时间t开始存储的版本”。</li><li>数据按行排序，以行的Key按字典顺序排序，并且表的行范围是动态分区的。 每行范围称为一个Tablets。</li><li>Tablets是分配和负载平衡的单位——如果发生不平衡，则Tablets可以在服务器之间移动。<br>Tablets的大小大约在200MB</li></ul><p>例如 ：如果关键范围是{January，February，March}，并且从March开始有很多数据进入，则它将拆分为多个Tablets，并在服务器之间移动以平衡系统。</p><p>因此，少量row范围的读取是高效的，并且通常仅需要与少量机器通信。</p><h4 id="Tablet-管理"><a href="#Tablet-管理" class="headerlink" title="Tablet 管理"></a>Tablet 管理</h4><p>BigTable使用3层模型对tablet进行管理</p><ol><li>第一层包含存储在Chubby（用于访问控制的分布式锁定服务）中的文件，该文件包含根Tablet的位置。</li><li>根tablet包含系统中所有tablets的位置。 它经过特殊处理，并且与其他tablet不同，它永远不会被分割——确保层次结构永远不会超过3个级别。</li><li>根tablet中的每一行都在内存中使用大约1k的数据。 假设每块tablet有128MB的限制，则3级层次结构可以处理$2^{34}$（〜170亿）个tablets。</li></ol><h4 id="总体结构"><a href="#总体结构" class="headerlink" title="总体结构"></a>总体结构</h4><p>Head node：分配tablets到tablet服务器上</p><p>Tablet server：管理对tablets的读写操作；客户端直接与tablet服务器通信；tablet服务器将太大的tablets拆分</p><p>SSTable：Sorted String Tables 包含真实数据</p><h4 id="读写组织"><a href="#读写组织" class="headerlink" title="读写组织"></a>读写组织</h4><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcvbq1kcy8j30sg0e8dhf.jpg" alt="截屏2020-03-15下午9.34.38"></p><p>内存中有一个表（memTable）用于存储发生的一系列的更新</p><p>一个写操作会将记录添加到memTable中，并且同时会写入日志（为了容错）</p><p>通过读取SSTable文件以及通过动态应用memTable的更新来提供读操作。 换句话说：“这里是价值所在，以及需要应用到该价值以获得真正价值的更新流”</p><h4 id="次要压缩-Minor-Compactions"><a href="#次要压缩-Minor-Compactions" class="headerlink" title="次要压缩 Minor Compactions"></a>次要压缩 Minor Compactions</h4><p>随着写操作执行，memTable的大小也会增大。当memTable的大小达到阈值，该memTable会被冻结，并创建一个新的memTable。被冻结的memTable被转化为SSTable并被写成文件。</p><p> 这部分操作被认为次要压缩，该压缩的两个目标：</p><ol><li>减少tablet服务器的内存使用量</li><li>减少数据恢复时，必须从提交日志中读取的数据量。</li></ol><p>发生压缩时，传入的读/写操作可以继续。</p><h4 id="主要压缩-Major-Compactions"><a href="#主要压缩-Major-Compactions" class="headerlink" title="主要压缩 Major Compactions"></a>主要压缩 Major Compactions</h4><p>每个次要压缩都会产生一个新的SSTable，如果该操作不断进行，读操作需要从大量的SSTables中合并更新。</p><p>为了防止这种情况，我们会在后台定期执行合并压缩。这样的压缩读取了几个SSTables和memTable的内容，并写出了一个新的SSTable。 完成后，可以丢弃之前的SSTables和memTable。</p><p><strong>将所有SSTables重写为一个SSTable的合并压缩称为主要压缩</strong>。 请记住，单个SSTable本身可能会拆分为多个文件。</p><h4 id="关键特征-1"><a href="#关键特征-1" class="headerlink" title="关键特征"></a>关键特征</h4><p>调整压缩格式</p><ul><li><p>客户端可以控制是否压缩地区组的SSTable，以及如果压缩，则使用哪种压缩格式。</p><p>用户指定的压缩格式将应用于每个SSTable块（大小可通过特定于位置组的调整参数来控制）。</p><p>分别压缩每个块时，会损失一些空间，但是我们的好处是，可以读取SSTable的一小部分而无需解压缩整个文件。</p></li></ul><p>布隆过滤器</p><ul><li><p>读取操作必须从组成tablet状态的所有SSTable中读取。 如果这些SSTable不在内存中，我们可能最终会进行许多磁盘访问。</p><p>BigTable可以使用Bloom Filters减少此类访问的次数。 布隆过滤器允许我们询问SSTable是否可能包含指定行/列/对的任何数据。</p><p>对于某些应用程序，将少量tablet服务器内存分配给<u>布隆过滤器</u>，能够大大减少读取操作所需的磁盘搜索次数。</p></li></ul><p>使SSTables不可变</p><ul><li><p>使用BigTable改善性能的另一种方法是使SSTables不可变。</p><p>这意味着SSTables不会直接写入，因为唯一可写入的数据结构是memTable，这使得并发控制相对简单。</p><p>结果，由于具有不可变性，仅在发生重大压缩时才创建SSTables。</p></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/13 复制和仓库</title>
      <link href="/2020/03/Big%20Data%20System/13%20%E5%A4%8D%E5%88%B6%E5%92%8C%E4%BB%93%E5%BA%93/"/>
      <url>/2020/03/Big%20Data%20System/13%20%E5%A4%8D%E5%88%B6%E5%92%8C%E4%BB%93%E5%BA%93/</url>
      
        <content type="html"><![CDATA[<h2 id="13-DEDUPLICATION-AND-WAREHOUSING"><a href="#13-DEDUPLICATION-AND-WAREHOUSING" class="headerlink" title="13: DEDUPLICATION AND WAREHOUSING"></a>13: DEDUPLICATION AND WAREHOUSING</h2><h4 id="数据仓库-data-warehouse"><a href="#数据仓库-data-warehouse" class="headerlink" title="数据仓库 data warehouse"></a>数据仓库 data warehouse</h4><p>有许多数据库database、许多站点sites，和不同的schemas</p><p>•支持决策<br>•在全公司范围内查看高质量信息的集成视图（来自不同的数据库）<br>•分离运营系统和信息系统</p><p>运营系统和信息系统的比较</p><p>数据仓库包括：元数据，原始数据-&gt;轻度总结数据-&gt;高度总结数据，数据库管理系统；其他还有：负载管理、查询管理、数据仓库管理</p><p>数据仓库的使用者：联机分析处理OLIP工具，报告、查询、应用开发、EIS工具，数据挖掘工具，和终端用户end-user访问工具</p><p>数据仓库的来源：<strong>运营数据源Operational data source</strong>，运营数据库Operational data store</p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>“数据仓库是面向主题的，集成的，随时间变化且非易失性的数据收集，以支持管理层的决策过程。”</p><p><strong>Subject-oriented</strong>：</p><ul><li>面向重要的主题，而不是交易transactions：比如销售、市场、金融、分销distribution；</li><li>简洁的视图，仅提供有用的数据以供决策</li></ul><p><strong>Integrated</strong>：</p><ul><li><p>来自于多个数据源的数据遵循一致的命名习惯Consistent naming conventions、格式、编码结构</p></li><li><p>对缺失数据，噪声数据，不一致数据进行清洗cleaning和预处理pre-processing</p></li></ul><p><strong>Time-varinat</strong>：</p><ul><li>只读，周期性刷新</li><li>提供历史historical值和可能的预测projected值</li></ul><p><strong>Non-volatile</strong>：</p><ul><li>在物理上分别存储</li><li>非在线更新</li><li>从不移除数据，因此没有并发问题</li></ul><h4 id="运营数据-Operational-data"><a href="#运营数据-Operational-data" class="headerlink" title="运营数据 Operational data"></a>运营数据 Operational data</h4><ul><li>transient 短暂的（not historical）</li><li>not normalised非标准化的（指的是数据库的范式）（可能为了性能而去规范化）</li><li>约束在一定范围内（非全面的 not comprehensive）</li><li>有时候质量不佳（出现不一致和错误）</li></ul><p><strong>经过提取/转换/加载 E(xtract)T(ransform)L(oad)后：</strong></p><ul><li>详细的Detailed（但还没被总结summarized）</li><li>历史的（周期性的periodic）</li><li>标准化（第三范式3rd  normal form或更高）</li></ul><h4 id="删除重复数据-Data-Deduplication"><a href="#删除重复数据-Data-Deduplication" class="headerlink" title="删除重复数据 Data Deduplication"></a>删除重复数据 Data Deduplication</h4><p>数据复制是一个逐渐流行起来的方法</p><p>重复数据删除有许多用途，但其主要用途是减少系统所需存储空间的潜力。</p><p>去重可以是文件file级别，块block级别，字节byte级别</p><h4 id="文件级别去重"><a href="#文件级别去重" class="headerlink" title="文件级别去重"></a>文件级别去重</h4><p>对单文件去重，常被认为“单实例存储”，它的主要思想就是：不管有多少文件实例被使用，只保留一个文件备份</p><p>该技术被用于Amazon S3，并报告出能够减少存储和带宽的成本为1/10</p><h4 id="块级别去重"><a href="#块级别去重" class="headerlink" title="块级别去重"></a>块级别去重</h4><p>将文件拆分成块blocks（或chunks）：核心思想是，经过两个文件不同，但他们可能包括相同的元素（比如两个不同的ppt可能包含同一张图片）</p><h4 id="字节级别去重"><a href="#字节级别去重" class="headerlink" title="字节级别去重"></a>字节级别去重</h4><p>在许多方面，字节级去重是块级去重的一种特殊情况。它比较数据流中的每个单独字节，而不是块。</p><p>字节级别去重是通常是“内容感知”的——比如，卖方对数据流的组成有一定的了解，因此知道要处理的数据流的特定部分。</p><p>该方法通常是“后处理”的，即先存储所有的流，再进行处理</p><h4 id="去重处理"><a href="#去重处理" class="headerlink" title="去重处理"></a>去重处理</h4><p>我们需要一种方法来检查数据是否已经被存储在我们的系统中：对文件、块、字节进行哈希计算，然后在我们的去重数据库DDB中查询该哈希值。如果该值存在，则该数据存在，如果值不存在，则存储该数据和对应的哈希值。</p><h4 id="Source-based-和-Target-based"><a href="#Source-based-和-Target-based" class="headerlink" title="Source-based 和 Target-based"></a>Source-based 和 Target-based</h4><p><strong>Source-based</strong>：</p><ul><li>之间在文件系统（或靠近数据的地方）中进行去重</li><li>对用户和应用透明</li><li>可以由文件系统本身或主机的操作系统执行</li><li>通常一个文件系统会扫描新文件并和现存的文件比较哈希值</li><li>通常需要中心化的管理</li></ul><p>Target-based</p><ul><li><p>重复数据从创建数据的位置删除</p></li><li><p>通常发生在第二/归档archive数据库</p></li><li><p>不需要减少传输数据到归档地archival store的带宽</p></li><li><p>有可能从源头分担处理要求。</p></li><li><p>不需要中心化的管理</p></li></ul><h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><h4 id="去重的权衡"><a href="#去重的权衡" class="headerlink" title="去重的权衡"></a>去重的权衡</h4><p><strong>Granularity 粒度</strong>：影响存储的效率和性能（存储空间和处理效率的权衡）</p><p>将文件拆分得越小（比如chunck-block-byte），就能找到更多的重复数据，但同样的，去重的处理速度也就越慢</p><p>另一个考虑是是容错：只留一个去重数据的副本copy是否足够</p><p>多个副本的优缺点？容错；数据分散靠近用户的cluster中，有利于提高响应时间；占用存储空间，增加成本</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/12 异构硬件中的大数据处理</title>
      <link href="/2020/03/Big%20Data%20System/12%20%E5%BC%82%E6%9E%84%E7%A1%AC%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
      <url>/2020/03/Big%20Data%20System/12%20%E5%BC%82%E6%9E%84%E7%A1%AC%E4%BB%B6%E4%B8%AD%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h2 id="12-Big-Data-Processing-on-Heterogeneous-Hardware"><a href="#12-Big-Data-Processing-on-Heterogeneous-Hardware" class="headerlink" title="12 Big Data Processing on Heterogeneous Hardware"></a>12 Big Data Processing on Heterogeneous Hardware</h2><h4 id="云计算-大数据"><a href="#云计算-大数据" class="headerlink" title="云计算+大数据"></a>云计算+大数据</h4><p>实时流、实时处理</p><p>数据可视化</p><p>实时结构化数据库、交互式分析、批量处理</p><p>结构化和非结构化数据</p><p>云基础设施</p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p>Cyber-Physical Systems (CPS)，the Internet of Things (IoT)， and the Smart Anything Everywhere Initiative</p><p>从长远来看，随着大规模采用，物联网转型影响预计将显着增加：千万级数量的物品互联，非常大的经济价值</p><p>关键驱动因素：物联网收集的数据，复杂的应用程序开发平台，应用于事物的分析以及<strong>异构硬件体系结构 heterogeneous hardware architectures</strong>，能够促进新业务模型</p><h3 id="异构硬件体系结构-Heterogeneous-hardware-architectures"><a href="#异构硬件体系结构-Heterogeneous-hardware-architectures" class="headerlink" title="异构硬件体系结构 Heterogeneous hardware architectures"></a>异构硬件体系结构 Heterogeneous hardware architectures</h3><p>是运行产品和提供服务的一种高效方法；将不同的处理器类型组合到一个系统中，以此提高绝对性能，最小化能耗和成本。</p><p>引入新的平台：合并多核CPUs，多核GPUs，和许多附加设备作为一个单独解决方案。出现在从超级计算机到个人智能手机的各种环境中.</p><p>因为产品的种类不断增长，因此需要设计<strong>更灵活的软件抽象software abstractions</strong>，以及改进系统结构，以探索异构平台的好处</p><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>数据巨大且复杂，传统处理方法效率不足：</p><ul><li>Too large to fit reasonably in fast RAM 数据太大无法合理的放入fast RAM中</li><li>Random access intensive, making prefetching and caching ineffective 随机访问密集，使预取和缓存无效</li></ul><p>数据经常被存在多机集群中的二号存储节点中</p><ul><li>存储系统和网络性能成为 first-order concerns</li></ul><h4 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h4><p>大数据系统带来新的需求：新的编程模型和工具</p><p>大数据系统需要实现：高性能和高效率</p><h4 id="关于异质性方面"><a href="#关于异质性方面" class="headerlink" title="关于异质性方面"></a>关于异质性方面</h4><p>异质性是并行结构中最深奥和最有挑战的特征</p><p>宏观方面：分布式计算机（云）的网络，由不同的节点结构（单核，多核）组成，通过可能的异质网络进行内部交互；即网络的异质性和，网络上的机器的异质性</p><p>微观方面：深层次的内存结构（main、cache、disk storage、tertiary storage）和不同的accelerator结构（固定的、可编程的，比如GPUs；可配置的：FPGAs）</p><h3 id="电脑结构"><a href="#电脑结构" class="headerlink" title="电脑结构"></a>电脑结构</h3><p>需要进行分类：根据目的进行分类</p><h4 id="通用处理器-General-Purpose-Processors（GPP）"><a href="#通用处理器-General-Purpose-Processors（GPP）" class="headerlink" title="通用处理器 General Purpose Processors（GPP）"></a>通用处理器 <strong>General Purpose Processors</strong>（GPP）</h4><ul><li>通用微处理器（通用电脑）：比如PCs，workstations，Laptops，notepads，用于执行多种应用和任务</li><li>微控制器：嵌入式系统<ul><li>专门为嵌入式系统中指定任务而设计</li><li>有面向控制的外围设备</li><li>具有片上CPU，固定数量的RAM，ROM，I / O端口</li><li>低成本、低能耗、低性能、比微处理器更小</li><li>适合对成本、空间、能耗要求严格的应用</li></ul></li></ul><h4 id="应用专用处理器"><a href="#应用专用处理器" class="headerlink" title="应用专用处理器"></a>应用专用处理器</h4><p>通用处理器对不同的软件都能表现出较好的性能，但专用处理器在特定任务上的表现更好</p><p>应用专用处理器出现的目的：更高的性能，更低的消耗，更低的成本</p><p>比如：TVs、mobile phone（不是智能手机）、GPSs</p><p>被分为：</p><ol><li>Digital Signal Processor (DSPs) 数字信号处理器</li><li>Application Specific Instruction Set Processors (ASIPs) 应用专用命令集处理器</li><li>Application Specific Integrated Circuit (ASICs) 应用专用集成电路<ul><li>指定市场、更少编程、难以构建</li></ul></li></ol><h4 id="Accelerators-Coprocessors-加速器-协处理器"><a href="#Accelerators-Coprocessors-加速器-协处理器" class="headerlink" title="Accelerators - Coprocessors 加速器-协处理器"></a><strong>Accelerators - Coprocessors</strong> 加速器-协处理器</h4><p>加速器-协处理器对某些功能的处理性能比CPU更高效more efficiently ：更快、更低能耗，但更难编程，比如：</p><ol><li>Graphics Processing Unit (GPU)<ul><li>Single Instruction Multiple Thread (SIMT) model 单指令多线程模型 – CUDA code</li><li>高效：数据并行应用；吞吐量密集型应用——算法需要处理大量数据元素</li></ul></li><li>FPGA (Field Programmable Gate Array) 现场可编程门阵列<ul><li>是逻辑门阵列，可以进行硬件编程以完成用户指定的任务</li><li>软件的一部分可以直接由硬件实现</li><li>比软件更有效率，但比ASIC更贵</li></ul></li></ol><h4 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h4><p>Intel CPU -&gt; DSP -&gt; MultiCore -&gt; ManyCore -&gt; GPU -&gt; FPGA -&gt; ASIC</p><p>灵活性、可编程、 —-&gt; 性能、特定领域、能源使用率高 power efficiency</p><h4 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h4><p>Host memory 主存：CPU的内存</p><p>Device memory 显存：GPU的内存</p><p><strong>处理流程：</strong></p><ol><li>从CPU中将输入数据拷贝到GPU中</li><li>加载GPU程序并执行，将数据缓存到芯片chip上提高性能</li><li>将执行结果从GPU内存中拷贝回CPU内存</li></ol><h4 id="GPU——数据处理"><a href="#GPU——数据处理" class="headerlink" title="GPU——数据处理"></a>GPU——数据处理</h4><p>擅长处理并行 data-parallel processing</p><ul><li>在多个数据元素上并行执行相同的计算——低控制流开销和高SP浮点运算强度 high SP floating point arithmetic intensity</li><li>每个内存访问有许多计算</li></ul><p>高浮点运算强度和许多数据元素意味着可以通过计算而不是大数据缓存来隐藏内存访问延迟</p><ul><li>需要避免带宽饱和</li></ul><h4 id="FPGA-现场可编程门阵列"><a href="#FPGA-现场可编程门阵列" class="headerlink" title="FPGA 现场可编程门阵列"></a>FPGA 现场可编程门阵列</h4><p>可配置逻辑块，内部通信网络，I/O信号</p><h4 id="FPGA——数据处理"><a href="#FPGA——数据处理" class="headerlink" title="FPGA——数据处理"></a>FPGA——数据处理</h4><ul><li>用于数据采集和原始数据预处理以进行事件过滤</li><li>需要掌握基于FPGA的硬件描述语言（HDL）的编程模型。<ul><li>– VHDL和Verilog是设计FPGA系统的传统方法</li><li>–描述执行计算的基础设计的基础硬件</li><li>–这与诸如C和C ++的编程语言形成对比，后者描述了在固定不变体系结构上执行的指令</li><li>–这使得FPGA既可以在其上实现的方面极为灵活，又在不充分了解其编程模型的情况下也很难设计。</li></ul></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/Bloom filters 布隆过滤器</title>
      <link href="/2020/03/Big%20Data%20System/Bloom%20filters%20%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"/>
      <url>/2020/03/Big%20Data%20System/Bloom%20filters%20%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>Bloom filters 布隆过滤器</p><p>will trigger: false positive — possibly in the set</p><p>will no trigger: false negative — definitely not in the set</p><h4 id="demo-amp-介绍"><a href="#demo-amp-介绍" class="headerlink" title="demo &amp; 介绍"></a>demo &amp; 介绍</h4><p><a href="https://llimllib.github.io/bloomfilter-tutorial/" target="_blank" rel="noopener">https://llimllib.github.io/bloomfilter-tutorial/</a></p><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h4><p><strong>布隆过滤器</strong>（英語：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的<a href="https://zh.wikipedia.org/wiki/二进制" target="_blank" rel="noopener">二进制</a>向量和一系列随机<a href="https://zh.wikipedia.org/wiki/映射" target="_blank" rel="noopener">映射函数</a>。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。</p><p>如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。<a href="https://zh.wikipedia.org/wiki/链表" target="_blank" rel="noopener">链表</a>、<a href="https://zh.wikipedia.org/wiki/树_(数据结构)" target="_blank" rel="noopener">树</a>、<a href="https://zh.wikipedia.org/wiki/散列表" target="_blank" rel="noopener">散列表</a>（又叫哈希表，Hash table）等等数据结构都是这种思路。但是随着集合中元素的增加，我们需要的存储空间越来越大。同时检索速度也越来越慢，上述三种结构的检索时间复杂度分别为{\displaystyle O(n),O(\log n),O(1)}<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db50673c67c6e72b7342ca1383def18cdead21b6" alt="{\displaystyle O(https://wikimedia.org/api/rest_v1/media/math/render/svg/db50673c67c6e72b7342ca1383def18cdead21b6),O(\log n),O(1)}">。</p><p>布隆过滤器的原理是，当一个元素被加入集合时，通过K个<a href="https://zh.wikipedia.org/wiki/散列函数" target="_blank" rel="noopener">散列函数</a>将这个元素映射成一个位<a href="https://zh.wikipedia.org/wiki/数组" target="_blank" rel="noopener">数组</a>中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。</p><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p>相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数（{\displaystyle O(k)}<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5ec39041121b14e8c2b1a986c9b04547b223e3c" alt="O(https://wikimedia.org/api/rest_v1/media/math/render/svg/f5ec39041121b14e8c2b1a986c9b04547b223e3c)">）。另外，散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。</p><p>布隆过滤器可以表示全集，其它任何数据结构都不能；</p><p>{\displaystyle k}<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" alt="k">和{\displaystyle m}<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" alt="m">)相同，使用同一组散列函数的两个布隆过滤器的交并<a href="https://zh.wikipedia.org/wiki/Wikipedia:列明来源" target="_blank" rel="noopener">[來源請求]</a>运算可以使用位操作进行。</p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>但是布隆过滤器的缺点和优点一样明显。误算率是其中之一。随着存入的元素数量增加，误算率false positive随之增加。但是如果元素数量太少，则使用散列表足矣。</p><p>另外，一般情况下不能从布隆过滤器中删除元素。我们很容易想到把位数组变成整数数组，每插入一个元素相应的计数器加1, 这样删除元素时将计数器减掉就可以了。然而要保证安全地删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面。这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。</p><p>在降低误算率方面，有不少工作，使得出现了很多布隆过滤器的变种。</p><p>optimal number of hash functions $k=\frac{m}{n}ln2,k=-\frac{lnp}{ln2}$</p><p>估计要添加的元素数量</p><p>bollm过滤器的大小</p><p>计算最佳的哈希函数数量</p><p>计算false positive的可能性</p><p>trade-off</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/10 DATABASES AND STORAGE</title>
      <link href="/2020/02/Big%20Data%20System/10%20DATABASES%20AND%20STORAGE/"/>
      <url>/2020/02/Big%20Data%20System/10%20DATABASES%20AND%20STORAGE/</url>
      
        <content type="html"><![CDATA[<h2 id="10-DATABASES-AND-STORAGE"><a href="#10-DATABASES-AND-STORAGE" class="headerlink" title="10: DATABASES AND STORAGE"></a>10: DATABASES AND STORAGE</h2><h4 id="数据库的结构"><a href="#数据库的结构" class="headerlink" title="数据库的结构"></a>数据库的结构</h4><p>关系型数据库，非关系型数据库</p><h4 id="关键特征"><a href="#关键特征" class="headerlink" title="关键特征"></a>关键特征</h4><p>原子的、一致的、隔离的、容错的</p><p>用表对数据结构化，支持ACID事务一致性，使用SQL进行查询，使用SQL和关系进行joins连接，关系由主键和次键管理</p><h4 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h4><p>一致性：</p><p>可用性：</p><p>分区容错性：</p><h4 id="ACID和BASE"><a href="#ACID和BASE" class="headerlink" title="ACID和BASE"></a>ACID和BASE</h4><h4 id="COLUMN-ORIENTED-DATABASES"><a href="#COLUMN-ORIENTED-DATABASES" class="headerlink" title="COLUMN-ORIENTED DATABASES"></a>COLUMN-ORIENTED DATABASES</h4><h4 id="DOCUMENT-ORIENTED-DATABASES"><a href="#DOCUMENT-ORIENTED-DATABASES" class="headerlink" title="DOCUMENT-ORIENTED DATABASES"></a>DOCUMENT-ORIENTED DATABASES</h4><h4 id="GRAPH-TREE-DATABASES"><a href="#GRAPH-TREE-DATABASES" class="headerlink" title="GRAPH/TREE DATABASES"></a>GRAPH/TREE DATABASES</h4>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/09 CLOUD PART 2</title>
      <link href="/2020/02/Big%20Data%20System/09%20CLOUD%20PART%202/"/>
      <url>/2020/02/Big%20Data%20System/09%20CLOUD%20PART%202/</url>
      
        <content type="html"><![CDATA[<h2 id="09-CLOUD-PART-2"><a href="#09-CLOUD-PART-2" class="headerlink" title="09: CLOUD PART 2"></a>09: CLOUD PART 2</h2>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/08 CLOUD – PART 1</title>
      <link href="/2020/02/Big%20Data%20System/08%20CLOUD%20%E2%80%93%20PART%201/"/>
      <url>/2020/02/Big%20Data%20System/08%20CLOUD%20%E2%80%93%20PART%201/</url>
      
        <content type="html"><![CDATA[<h2 id="08-CLOUD-–-PART-1"><a href="#08-CLOUD-–-PART-1" class="headerlink" title="08 CLOUD – PART 1"></a>08 CLOUD – PART 1</h2><h4 id="大数据与云计算的关联"><a href="#大数据与云计算的关联" class="headerlink" title="大数据与云计算的关联"></a>大数据与云计算的关联</h4><ol><li>数据可视化</li><li>实时的结构化数据库、交互式分析、批量处理</li><li>结构化和非结构化数据（HDFS、S3）</li><li>云基础设施</li><li>存储、网络、计算资源</li></ol><h4 id="例子：百事可乐和阿里巴巴"><a href="#例子：百事可乐和阿里巴巴" class="headerlink" title="例子：百事可乐和阿里巴巴"></a>例子：百事可乐和阿里巴巴</h4><h4 id="实用计算-Utility-Computing"><a href="#实用计算-Utility-Computing" class="headerlink" title="实用计算 Utility Computing"></a>实用计算 Utility Computing</h4><h4 id="云计算的定义"><a href="#云计算的定义" class="headerlink" title="云计算的定义"></a>云计算的定义</h4><h4 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h4><ul><li>成本和管理</li><li>减少部署时间</li><li>可扩展性</li><li>可靠性</li><li>可持续性</li></ul><h4 id="虚拟的基础设施"><a href="#虚拟的基础设施" class="headerlink" title="虚拟的基础设施"></a>虚拟的基础设施</h4><p>虚拟的服务平台：整合服务器系统、降低成本、降低复杂性、简化管理、pay-per-usage</p><h4 id="three-“service-models”-software-platform-and-infrastructure"><a href="#three-“service-models”-software-platform-and-infrastructure" class="headerlink" title="three “service models” (software, platform and infrastructure)"></a>three “service models” (software, platform and infrastructure)</h4><h4 id="four-“deployment-models”-private-community-public-and-hybrid-strategies"><a href="#four-“deployment-models”-private-community-public-and-hybrid-strategies" class="headerlink" title="four “deployment models” (private, community, public and hybrid) strategies"></a>four “deployment models” (private, community, public and hybrid) strategies</h4>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/07 Introduction to Mobile Device Virtualization</title>
      <link href="/2020/02/Big%20Data%20System/07%20Introduction%20to%20Mobile%20Device%20Virtualization/"/>
      <url>/2020/02/Big%20Data%20System/07%20Introduction%20to%20Mobile%20Device%20Virtualization/</url>
      
        <content type="html"><![CDATA[<h2 id="07-Introduction-to-Mobile-Device-Virtualization"><a href="#07-Introduction-to-Mobile-Device-Virtualization" class="headerlink" title="07 Introduction to Mobile Device Virtualization"></a>07 <strong>Introduction to Mobile Device Virtualization</strong></h2><h4 id="动机：为什么"><a href="#动机：为什么" class="headerlink" title="动机：为什么"></a>动机：为什么</h4><p>大规模的物联网设备及其数据需要有效利用云资源<br>解决方案：虚拟化<br>但是…隐私问题和性能提升<br>因此：使物联网设备的虚拟化势在必行</p><h4 id="移动设备的虚拟化"><a href="#移动设备的虚拟化" class="headerlink" title="移动设备的虚拟化"></a>移动设备的虚拟化</h4><p>虚拟化：在多个操作系统之间，高效的共享物理资源</p><p>混合关键设置：通用操作系统（实时OS，安全OS，遗留OS）</p><p>减少软件移植费用和硬件成本</p><p>主要的组件：硬件设备、Hypervisor（虚拟机监控程序 VMM）、GuestOS（虚拟机 VM）</p><p>移动设备的高效虚拟化</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/07 Virtualization</title>
      <link href="/2020/02/Big%20Data%20System/07%20Virtualization/"/>
      <url>/2020/02/Big%20Data%20System/07%20Virtualization/</url>
      
        <content type="html"><![CDATA[<h2 id="07-Virtualization"><a href="#07-Virtualization" class="headerlink" title="07 Virtualization"></a>07 Virtualization</h2><p>什么是虚拟化，技术，案例</p><h4 id="什么是虚拟化"><a href="#什么是虚拟化" class="headerlink" title="什么是虚拟化"></a>什么是虚拟化</h4><p>虚拟化可以广义地定义为：概念性资源或服务与提供它的物理方式的（有益）分离</p><p>创建虚拟资源：硬件平台，操作系统，存储设备，计算机网络资源</p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>虚拟机：真实机器的一种表示，使用软件模拟emulate操作环境</p><p>Guest Operating System：运行在虚拟机里的操作系统</p><p>Host OS：运行虚拟机的操作系统</p><p>Hypervisor/VMM 虚拟机监管者：将资源虚拟化的中间件；位于基础资源和虚拟机之间</p><h4 id="虚拟化的好处"><a href="#虚拟化的好处" class="headerlink" title="虚拟化的好处"></a>虚拟化的好处</h4><p>原因：资源利用不足；数据中心空间不足；环保；管理成本上升</p><p>特点：Sharing、Aggregation，Emulation，Isolation</p><p>好处：随意选择操作系统（比如测试环境）；合并服务器和基础设施；节约时间和金钱；简化管理，保护桌面环境：比如将不安全的程序隔离进虚拟机中，可以将虚拟机复制到其他机器中，相同的操作系统/软件可以快速安装。</p><p>缺点：Guest OS对硬件要求更高；需要学习如何使用；不够精确；硬件问题：比如Intel IA-32</p><h4 id="虚拟机监管者-Virtual-Machine-Monitor"><a href="#虚拟机监管者-Virtual-Machine-Monitor" class="headerlink" title="虚拟机监管者 Virtual Machine Monitor"></a>虚拟机监管者 Virtual Machine Monitor</h4><p>Qemu, VMware Player, Microsoft Virtual PC etc，Sometimes called Emulation, e.g. x86 Emulation</p><h4 id="Hypervisor的分类"><a href="#Hypervisor的分类" class="headerlink" title="Hypervisor的分类"></a>Hypervisor的分类</h4><p><strong>裸机模式 Bare Metal: Type 1 hypervisor</strong></p><p>位于裸机计算机硬件上，例如CPU，内存等；所有来宾操作系统都在Hypervisor之上；Hypervisor是硬件之上的第一层。如：Microsoft Hyper-V</p><p><strong>托管模式 Hosted Approach：Type 2 Hypervisor</strong></p><p>在主操作系统上运行；Hypervisor是硬件之上的第二层；Guest OS在hypervisor上的一层运行</p><p>比如：VMWare Workstations、Microsoft Virtual PC、FreeBSD</p><h4 id="Hypervisor的主要属性"><a href="#Hypervisor的主要属性" class="headerlink" title="Hypervisor的主要属性"></a>Hypervisor的主要属性</h4><p><strong>Equivalence</strong>：程序应该表现的像是直接在同样的硬件上执行</p><p><strong>Resource control 资源控制</strong> ：Hypervisor对虚拟资源有完整的控制</p><p><strong>Efficiency 效率</strong>：必须在无Hypervisor的干预下执行绝大部分机器指令machine instruction</p><h4 id="虚拟技术"><a href="#虚拟技术" class="headerlink" title="虚拟技术"></a>虚拟技术</h4><p>全虚拟化，硬件辅助虚拟化，部分虚拟化：半虚拟化、混合、OS Level</p><h4 id="全虚拟化"><a href="#全虚拟化" class="headerlink" title="全虚拟化"></a>全虚拟化</h4><p>在全虚拟化技术中，Guest OS并不知道自己处于虚拟的环境，以Guest OS的角度，它直接与硬件进行通信（实际上是虚拟的硬件）</p><ul><li>主机系统模拟硬件，使Guest OS无需任何修改即可运行</li><li>不同的架构可以独立运行</li><li>因为GuestOS与仿真硬件通信（due to the overhead associated with emulating hardware at the transistor level），导致相当大的性能损失</li></ul><h4 id="硬件辅助虚拟化"><a href="#硬件辅助虚拟化" class="headerlink" title="硬件辅助虚拟化"></a>硬件辅助虚拟化</h4><p>是全虚拟化的一种，其中的微处理器架构有特殊的指令，可以协助硬件的虚拟化（而不是完全靠主机操作系统模拟硬件）。这种方式以“Virtual Machine Extensions”的形式，充分利用了硬件的能力，如Intel VT和AMD V</p><p><strong>促进虚拟机的性能</strong>：可以直接与主机的处理器通信，而不需要由Hypervisor进行翻译和隔离；限制GuestOS与主机使用一样的命令集</p><p><strong>完整的硬件协助虚拟化</strong>（如I/O和内存管理），还没有在任何VMM中实现</p><h4 id="部分虚拟化"><a href="#部分虚拟化" class="headerlink" title="部分虚拟化"></a>部分虚拟化</h4><p>只模拟主机的大部分硬件，而非全部；支持资源共享，但不保证GuestOS实例被隔离</p><p>比如：半虚拟化 Para-Virtualization、混合虚拟化 Hybrid Virtualization、操作系统级别虚拟化 Operating System-Level Virtualization</p><h4 id="半虚拟化"><a href="#半虚拟化" class="headerlink" title="半虚拟化"></a>半虚拟化</h4>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/06 MESSAGING AND STORAGE LAYER</title>
      <link href="/2020/02/Big%20Data%20System/06%20MESSAGING%20AND%20STORAGE%20LAYER/"/>
      <url>/2020/02/Big%20Data%20System/06%20MESSAGING%20AND%20STORAGE%20LAYER/</url>
      
        <content type="html"><![CDATA[<h2 id="06-MESSAGING-AND-STORAGE-LAYER"><a href="#06-MESSAGING-AND-STORAGE-LAYER" class="headerlink" title="06 MESSAGING AND STORAGE LAYER"></a>06 MESSAGING AND STORAGE LAYER</h2><p>大数据分层结构：负责采集数据、Hadoop、Hadoop分布式文件系统：数据是如何在file system中分布的</p><h4 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h4><p>Hadoop是包括多个不同产品的完整生态系统，由Apache软件基金会负责</p><p>是开源框架，实现MapReduce，用于处理、存储和分析数据</p><p>最初用于10亿级的网页搜索引擎</p><p>基本原则是将一个大块的数据拆分成多个小块，然后把多个小块分散存储</p><h4 id="Hadoop的基本结构"><a href="#Hadoop的基本结构" class="headerlink" title="Hadoop的基本结构"></a>Hadoop的基本结构</h4><p>Hadoop包括两个方面：</p><ul><li><p>HDFS：Hadoop分布式文件系统</p></li><li><p>MapReduce：集群资源管理和批数据处理</p></li></ul><h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><blockquote><p>HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群是由一个NameNode和若干个DataNode组成的。其中NameNode作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；集群中的DataNode管理存储的数据。</p></blockquote><p>HDFS公开文件系统的命名空间，并允许用户数据储存在文件中。HDFS由Java编写，因此只要能运行Java的机器，就能成为NameNode或DataNode</p><p>在内部，一个文件被拆分成1个或多个块blocks，并且这些块被存储在一系列的DataNodes中</p><p>HDFS包括一个NameNode和多个DataNodes：</p><ul><li><p>NameNode：作为主服务器，管理文件系统的命名空间和客户端对文件的访问操作；</p><p>执行文件系统操作，例如打开，关闭和重命名文件/目录。 它确定Block到DataNode的映射（找到所需的Block在哪些DataNodes中）。</p></li><li><p>DataNodes：通常，集群中的每个节点都有一个DataNode，DataNode运行在该节点之上，并管理该节点的存储</p><p>DataNode处理来自文件系统客户端的读写请求。 它们根据NameNode的指令执行块创建，删除和复制。</p></li></ul><p>根据系统偏好设置，DataNode中的块将跨多个节点复制，因此，如果一个DataNode发生故障，则包含所需数据的另一个DataNode会自动联机。</p><h4 id="HDFS-File-Writes"><a href="#HDFS-File-Writes" class="headerlink" title="HDFS File Writes"></a>HDFS File Writes</h4><ol><li>HDFS客户端把一个文件File.txt分成了多个块BlockA B C，</li><li>HDFS客户端发送写文件请求给NameNode，NameNode分配DataNodes，并返回DataNodes的地址</li><li>HDFS客户端直接将文件块写入被分配好的DataNodes</li><li>DataNode会复制数据块到其他DataNode中</li><li>下一个DataNode重复该复制操作</li></ol><p>一个文件被拆分的块blocks越多，那么在并行处理数据时，就有越多的机器可以参与进来</p><p>对于容错，每个块将在被写入时复制。Hadoop的标准是在一个集群中，每个block至少有3个copies（可配置）</p><h4 id="Hadoop-Rack-Awareness-机架感知"><a href="#Hadoop-Rack-Awareness-机架感知" class="headerlink" title="Hadoop Rack Awareness 机架感知"></a>Hadoop Rack Awareness 机架感知</h4><p>机架感知确保每个块Block至少被储存在2个以上的机架Rack中（至少有一个block的备份在不同的机架中）。通过机架感知，我们可以确保数据不会因为整个机架崩溃failure而丢失</p><p>机架感知还可以尽可能让大数据在机架中流动（flows in-rack）：我们认为机架内in-rack有更高的带宽和更低的延迟</p><p>每个从属数据节点DataNode的机架号需要手动定义</p><h4 id="HDFS-Pipeline-Write-管道写"><a href="#HDFS-Pipeline-Write-管道写" class="headerlink" title="HDFS Pipeline Write 管道写"></a>HDFS Pipeline Write 管道写</h4><ol><li>在HDFS将一个块block写入集群cluster之前，它会确认是否所有需要保存块备份的DataNode都准备好了</li><li>客户端首先连接DataNode1，DN1会询问DN2，DN2会询问DN3（至少有一个DataNode在另一个机架中，不同机架的DataNode需要通过交换机Switch进行连接，同一个机架上的DataNode则通过架顶交换机TOR Switch进行连接）</li><li>如果所有DataNode都准备好了，那么DataNode1会通知客户端</li><li>每个块被写入集群后，都会创建一个复制管道replication pipeline。<ul><li>意思是，当一个DataNode接受到了block数据，它会同时将block的备份推送到管道的下一个节点中</li><li><strong>机架感知</strong>会在这部分有所体现（机架内intra-rack通信速度更快）</li></ul></li><li>各个管道的初始节点都是不一样的（即两个管道的初始节点不会是同一个）</li><li>Hadoop根据配置的复制因素，使用大量的带宽和存储</li></ol><h4 id="File-Spread-文件传播"><a href="#File-Spread-文件传播" class="headerlink" title="File Spread 文件传播"></a>File Spread 文件传播</h4><ul><li>理想情况下，文件最终应散布在整个机器集群中</li><li>组成文件的块blocks越多，数据可传播到的机器越多，并行处理能力越强，结果越快。</li><li>当群集扩展时，我们的网络需要适当地扩展。 </li><li>提高性能的另一种方法：pre-process some data in the edge</li></ul><h4 id="NameNode的细节"><a href="#NameNode的细节" class="headerlink" title="NameNode的细节"></a>NameNode的细节</h4><ul><li>除了持有文件系统的所有元数据，NameNode还监控DataNodes的运行状况，并协调数据访问</li><li>每3秒，通过TCP，DataNodes发送“心跳heartbeat”消息给NameNode；<ul><li>第10次心跳的消息是block report。这允许NameNode构建其元数据，并确保Block的备份数量是足够的</li></ul></li><li>如果NameNode没有收到DataNode的心跳消息，那么就会假设DataNode出故障了。</li><li>基于NameNode之前收到的block report，它知道故障的数据节点持有哪个block，因此可以重新备份将该block到其他DataNode中<ul><li>这里再次涉及到<strong>机架感知</strong>（备份在不同的机架上）</li></ul></li></ul><h4 id="Secondary-NameNode-辅助节点"><a href="#Secondary-NameNode-辅助节点" class="headerlink" title="Secondary NameNode 辅助节点"></a>Secondary NameNode 辅助节点</h4><p>该辅助NameNode定时与主NameNode进行连接（默认是1小时），辅助主节点的元数据（基于内存和基于文件）</p><p>辅助NameNode合并（检查点）上述信息，并将其传递回NameNode，同时为其自身维护副本。</p><p>如果NameNode死亡，则可以使用Secondary NameNode恢复。</p><p>在繁忙的群集中，管理员可以将整理工作设置得更加频繁。</p><h4 id="HDFS客户端读文件"><a href="#HDFS客户端读文件" class="headerlink" title="HDFS客户端读文件"></a>HDFS客户端读文件</h4><p>要读取文件，客户端会查询NameNode并询问文件的块位置。</p><p>对于每个块，NameNode会返回包含该块的DataNode的列表。</p><p>客户端从每个block列表中选择一个DataNode，并使用TCP一次读取一个块。 </p><p>在前一个块完成之前，它不会进行到下一个块。</p><h4 id="DataNode读文件"><a href="#DataNode读文件" class="headerlink" title="DataNode读文件"></a>DataNode读文件</h4><p>有时，DataNode自身可能需要从HDFS中读取一个数据块：比如该节点被要求处理非本地数据。</p><p>该节点的机架感知Rack Awareness 可以提供最优的网络方案（比如优先选择同一机架内节点的block）</p><h4 id="HDFS的特点"><a href="#HDFS的特点" class="headerlink" title="HDFS的特点"></a>HDFS的特点</h4><p><strong>硬件故障 Hardware Failure</strong>：故障检测和快速自动恢复是HDFS的核心架构目标。</p><p><strong>可移植性 Portability</strong>：HDFS被设计为可从一个平台轻松移植到另一个平台。</p><p><strong>大数据集 Large Data Sets</strong>：典型文件的大小应为GB，TB或PB，因此HDFS已调整为支持大文件。 它可以在单个实例中支持数千万个文件。</p><p><strong>流数据访问 Streaming Data Access</strong>：HDFS设计用于批处理，而不是用户交互使用。 重点在于数据的高吞吐量而不是数据访问的低延迟。</p><p><strong>简单一致性模型 Simple Coherency Model</strong>：文件通常只创建和写入一次，不需要更改。 该假设简化了数据一致性问题。 有计划在将来支持对文件的追加写入。</p><p><strong>计算应移至数据 Move Computing To Data</strong>：如果在要处理的数据附近执行计算，效率会大大提高，尤其是在数据量很大时。 HDFS为应用程序提供了使自己更接近数据的接口。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/05 MapReduce</title>
      <link href="/2020/02/Big%20Data%20System/05%20MapReduce/"/>
      <url>/2020/02/Big%20Data%20System/05%20MapReduce/</url>
      
        <content type="html"><![CDATA[<h2 id="05-MapReduce"><a href="#05-MapReduce" class="headerlink" title="05 MapReduce"></a>05 MapReduce</h2><p>大数据的挑战、MapReduce、Hadoop、例子</p><h4 id="大数据的挑战"><a href="#大数据的挑战" class="headerlink" title="大数据的挑战"></a>大数据的挑战</h4><ul><li>大量的数据：数据产生的速度和数据的种类在快速的增长</li><li>数据描述：用于描述内容的媒体数据和语义</li><li>搜索：语义嵌入的搜索引擎</li><li>存储：重建比存储更容易；有用数据和噪音的比例；公司会存储所有类型的数据</li><li>数据采集：信息和知识；质量控制</li></ul><h4 id="解决方案：并行化"><a href="#解决方案：并行化" class="headerlink" title="解决方案：并行化"></a>解决方案：并行化</h4><p>将工作分割处理Partition，然后合并Combine</p><h4 id="并行化的挑战-1"><a href="#并行化的挑战-1" class="headerlink" title="并行化的挑战 1"></a>并行化的挑战 1</h4><ul><li>Scheduling 调度：如何分配任务给不同的worker</li><li>可用性：如果工作单元work units比worker更多该怎么做</li><li>依赖 Dependencies：process 不要相互依赖（并行化的关键）；workers如何共享资源；如何确定所有works的任务都完成了</li><li>容错：如果worker在执行中出错怎么办</li><li>通信和同步：workers之间交换状态state和访问共享资源（如数据）</li></ul><h4 id="当前的工具"><a href="#当前的工具" class="headerlink" title="当前的工具"></a>当前的工具</h4><p>编程模型：共享内存、消息传递</p><p>设计模式：主从（Master-slaves）模式、生产者消费者流模式（Producer-consumer flows）：1.循环；2.工作队列</p><h4 id="并行化的挑战-2"><a href="#并行化的挑战-2" class="headerlink" title="并行化的挑战 2"></a>并行化的挑战 2</h4><p>并发 <strong>Concurrency</strong>：当考虑数据中心的规模，错误，多个服务之间的交互</p><p>负载平衡 <strong>Shifting the burden</strong>：开发人员制定需要执行的计算；处理实际执行任务的执行框架（在运行时）。</p><h4 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h4><p>是一个编程模型，用于在大规模系统中表达分布式计算；是一个用于zu</p><p>怎么把计算任务拆分，分配到不同的处理器中</p><p>Hadoop是MapReduce的开源实现之一</p><h4 id="MapReduce的步骤"><a href="#MapReduce的步骤" class="headerlink" title="MapReduce的步骤"></a>MapReduce的步骤</h4><ol><li>对大量的记录进行迭代</li><li>对每个记录提取感兴趣的信息——Map</li><li>对中间结果进行shuffle和sort</li><li>把中间结果合并为可用的格式，并产生结果——Reduce</li></ol><h4 id="MapReduce模型"><a href="#MapReduce模型" class="headerlink" title="MapReduce模型"></a>MapReduce模型</h4><p><strong>map(k,v)：</strong>Map 把原始数据转化为键值对 &lt;key,val&gt;</p><p><strong>reduce(k*,v*)：</strong>Reduce 对键值对组&lt;key,[val, val, …]&gt;进行处理</p><ul><li>All values with the same key are sent to the same Reducer.把相同Key的值封装在一起</li></ul><p>Shuffle and Sort 把按照键值排序和合并&lt;key,[val, val, …]&gt;，把相同Key的键值对发送给同一个Reduce进程</p><p>执行框架Execution framework处理其他所有的工作</p><p>其他可编程的部分还有</p><p><strong>partition(k’, number of partition)</strong>：按key将任务拆分，并行处理reduce操作，相同的Key交给相同的Reducer</p><p><strong>combine(k’, v’)</strong>：迷你Reducer，在内存中运行，在map阶段后运行；用于优化，减少网络负载network traffic（减少需要传递的数据）</p><h4 id="运行时-Runtime"><a href="#运行时-Runtime" class="headerlink" title="运行时 Runtime"></a>运行时 Runtime</h4><p>处理调度：将workers分配到Map和Reduce任务中</p><p>处理“数据分布”：将processes移动到data上</p><p>处理同步：采集、排序、重组中间（过渡）数据</p><p>处理错误：检测workers的错误，并重新开始</p><h4 id="分布式文件系统-DFS"><a href="#分布式文件系统-DFS" class="headerlink" title="分布式文件系统 DFS"></a>分布式文件系统 DFS</h4><p>不要移动数据，而是移动workers：将数据存储在集群节点的本地磁盘中，启动该节点中的workers。例子：</p><ul><li><strong>Job Tracker</strong> 查看 <strong>NameNode</strong> 以了解哪些 <strong>DataNode</strong> 具有 file blocks文件块。然后，<strong>Job Tracker</strong> 为”具有文件块的节点“上的 <strong>Task Tracker</strong> 提供执行Map计算所需的Java代码，让代码在节点本地计算。Job Tracker将始终尝试为Map任务选择具有本地数据的节点。</li></ul><p>原因：memory中的RAM不足以存放所有的数据；磁盘访问很慢，但磁盘的吞吐量是合理的</p><p>解决方案：分布式文件系统：GFS、HDFS</p><h4 id="MapReduce的特征"><a href="#MapReduce的特征" class="headerlink" title="MapReduce的特征"></a>MapReduce的特征</h4><p>Map的输出和Reduce的输入和输出都是<strong>键值对</strong></p><p>任务相互独立：比如不同Map的输出不会相互依赖</p><p>Reduce阶段必须等到Map完成后才会开始</p><p>MapReduce关注调度任务scheduling tasks，对他们进行监控以及对错误的任务重新执行</p><p>数据在MapReduce中是不可改变的，也就是说无法更新</p><h4 id="Hadoop例子"><a href="#Hadoop例子" class="headerlink" title="Hadoop例子"></a>Hadoop例子</h4><ol><li>客户端将MapReduce任务提交给 <strong>Job Tracker</strong></li><li><strong>Job Tracker</strong> 查看 <strong>NameNode</strong> 以了解哪些 <strong>DataNode</strong> 具有 file blocks文件块。</li><li>然后，<strong>Job Tracker</strong> 为”具有文件块的节点“上的 <strong>Task Tracker</strong> 提供执行Map计算所需的Java代码，让代码在节点本地计算</li><li><strong>Task Tracker</strong>启动Map任务并监视其进度。 它将心跳和任务状态返回给<strong>Job Tracker</strong>。</li><li>每个Map任务完成时，其节点将结果存储在临时存储区中（中间数据 <strong>intermediate data</strong>）。</li><li>当所有Map都完成后，它将通过网络发送到运行reduce任务的节点</li></ol><ul><li>Job Tracker将始终尝试为Map任务选择具有本地数据的节点。这可能做不到（例如，具有本地数据的节点可能已经在运行许多其他任务）</li><li>在这种情况下，Job Tracker将尝试尽可能将任务分配给与数据位于同一机架中的节（使用机架感知 Rack Awareness）。</li><li>NameNode将指示节点从相关DataNode复制数据。</li></ul><ol><li>Job Tracker在集群中的任何节点上启动Reduce任务</li><li>它引导Reduce任务从“所需的每个已完成的Map任务”复制中间数据<strong>intermediate data</strong>。</li><li>如果Map任务几乎立即响应，那么网络会过载。</li><li>为了解决这个问题，群集网络很重要：交换机具有良好的内部流量管理功能和缓冲区（ <strong>good internal traffic management capabilities and buffers</strong>）</li><li>Reducer任务的输出将写入HDFS（拆分为块，管道复制等）</li><li>Hadoop支持：“在需要时合并多个Reduce Task jobs”的方法</li></ol><h4 id="Facebook例子——共同好友"><a href="#Facebook例子——共同好友" class="headerlink" title="Facebook例子——共同好友"></a>Facebook例子——共同好友</h4><p>共同好友列表的数据改变频率不高，所以我们可以用MapReduce来计算所有人的共同好友并储存结果，每天一次</p><p>当有人访问时，就可以展示结果</p><ol><li>Map：对于一个人A的好友列表，可以通过Map转换为，A与列表中每个好友分别组成键，其好友为值</li><li>排序和重组</li><li>Reduce：相同键所包含的列表中，如果值有相同，那么说明相同的值就是他们的共同好友</li><li>最后将结果输出到HDFS（Hadoop分布式文件系统）中</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/04 Data Sources</title>
      <link href="/2020/02/Big%20Data%20System/04%20Data%20Sources/"/>
      <url>/2020/02/Big%20Data%20System/04%20Data%20Sources/</url>
      
        <content type="html"><![CDATA[<h2 id="04-Data-Sources"><a href="#04-Data-Sources" class="headerlink" title="04 Data Sources"></a>04 Data Sources</h2><h4 id="来源层-Sources-layer"><a href="#来源层-Sources-layer" class="headerlink" title="来源层 Sources layer"></a>来源层 Sources layer</h4><p>指的是“来自于所有渠道的，可用于分析的，所有数据”。分析的类型和来源密切相关</p><p>格式：结构化的、半结构化的、非结构化的</p><p>Velocity和Volume：数据传入(arrives)的速度，以及数据传递速率(rate)根据数据源而不同</p><p>采集点：实时或分批采集数据的来源（直接采集或者源自数据提供者）。数据可以来自主要或次要来源。</p><p>数据源的地点：数据源可以在企业内部或外部。 <u>需要标识限制访问的数据，因为对数据的访问会影响可用于分析的数据范围</u></p><h4 id="第四次工业革命"><a href="#第四次工业革命" class="headerlink" title="第四次工业革命"></a>第四次工业革命</h4><p>2000年开始：IoT，数字整合，大数据，AI等</p><h4 id="IoT和IIoT"><a href="#IoT和IIoT" class="headerlink" title="IoT和IIoT"></a>IoT和IIoT</h4><p>IoT：基于消费者；低成本端点设备</p><p>Industrial IoT：以企业为重点；高成本工业资产</p><h4 id="从Cloud到Edge"><a href="#从Cloud到Edge" class="headerlink" title="从Cloud到Edge"></a>从Cloud到Edge</h4><p>Cloud 云计算：基于数据中心，TCP/IP访问，使用虚拟化基础架构可大规模扩展</p><p>Edge 边缘计算：地理位置本地化的服务器，将计算向终端设备靠近</p><p>Fog 雾计算：联合Cloud和Edge，在Could和Edge之间的去中心化计算</p><h4 id="云计算、边缘计算、雾计算"><a href="#云计算、边缘计算、雾计算" class="headerlink" title="云计算、边缘计算、雾计算"></a>云计算、边缘计算、雾计算</h4><p><strong>云计算</strong>是把大量数据放到“云”里去计算或存储，解决诸如电脑或手机存储量不够，或者是运算速度不够快的问题</p><p><strong>雾计算</strong>是定义边缘计算应如何工作的标准，它促进了终端设备与云计算数据中心之间的计算，存储和网络服务的运行。此外，许多人将雾作为边缘计算的起点。</p><p><strong>边缘计算</strong>使处理靠近数据源，不需要将其发送到远程云或其他集中式系统进行处理。通过消除将数据发送到集中式源所需的距离和时间，我们可以提高数据传输以及边缘设备和应用程序的速度和性能。</p><p>优点：以减少“云”的压力，提高了效率，也提升了传输速率，减低了时延</p><p>缺点：如果终端设备end devices（如传感器）太多，那么边缘处理器和存储平台可能不堪重负overloaded；安全性问题，分布的边缘节点edge node意味着更高的安全风险higher risk of security，比如飞机引擎被黑Imagine if a jet engine could be hacked in flight.</p><p>对于时间敏感、计算量小的任务，如紧急情况的监控和警告，应该由边缘计算负责，比如飞机引擎是否过热（such as in-flight analysis about if the engine is overheating）</p><p>对于需要计算大量数据的任务，如进行预测分析、深度数据分析或机器学习，则应该由云计算负责，比如根据过去几个月的数据预测未来的天气、找出飞机引擎过热的原因</p><h4 id="例子：无人驾驶汽车"><a href="#例子：无人驾驶汽车" class="headerlink" title="例子：无人驾驶汽车"></a>例子：无人驾驶汽车</h4><p>大量的传感器数据，要求本地数据处理能力；需要连接云端的高级数据分析工具；全新的分布式计算结构的出现，拆分不同元素间的大量工作负载（大数据分析、实时应用）；边缘计算</p><h4 id="例子：航空"><a href="#例子：航空" class="headerlink" title="例子：航空"></a>例子：航空</h4><p>对于时间敏感、计算量小的任务，如紧急情况的监控和警告，应该由边缘计算负责，比如飞机引擎是否过热（such as in-flight analysis about if the engine is overheating）</p><p>对于需要计算大量数据的任务，如进行预测分析、深度数据分析或机器学习，则应该由云计算负责，比如根据过去几个月的数据预测未来的天气、找出飞机引擎过热的原因</p><h4 id="例子：自动测试"><a href="#例子：自动测试" class="headerlink" title="例子：自动测试"></a>例子：自动测试</h4><h4 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h4><p>无线连接：NFC/RFID、Bluetooth/ZigBee、WiFi、Radio、LTE、IEEE 802</p><p>通信协议：TCP/IP、HTTP/HTTPS/WebSocket、REST、SOAP、WS-*、WCF、AMQP</p><p>专用RTI：DDS、HLA(IEEE 1516.2010)</p><p>非同步消息队列：RabbitMQ、Apache kafka、ActiveMQ</p><p>特定的应用API</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Big Data System/03 HIGH LEVEL ARCHITECTURE</title>
      <link href="/2020/01/Big%20Data%20System/03%20HIGH%20LEVEL%20ARCHITECTURE/"/>
      <url>/2020/01/Big%20Data%20System/03%20HIGH%20LEVEL%20ARCHITECTURE/</url>
      
        <content type="html"><![CDATA[<h2 id="03-HIGH-LEVEL-ARCHITECTURE"><a href="#03-HIGH-LEVEL-ARCHITECTURE" class="headerlink" title="03 HIGH LEVEL ARCHITECTURE"></a>03 HIGH LEVEL ARCHITECTURE</h2><p>大数据技术；层结构：来源、数据通信、分析、使用；信息整合；数据统治；系统管理；例子</p><h4 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h4><p>存储、检索、合并、分析 ——解决方案——&gt; 使用分布式资源</p><h4 id="从原始数据到最终执行"><a href="#从原始数据到最终执行" class="headerlink" title="从原始数据到最终执行"></a>从原始数据到最终执行</h4><p>流程：1.数据获取 -&gt; 3.Infrastructure -&gt; 5.数据管理 -&gt; 7.分析和自动化 -&gt; 9.可视化 -&gt; 11.最终执行 (&lt;1%)</p><p>数据丢失点：0.不可获取 -&gt; 2.不可流化或存储 -&gt; 4.不可访问 -&gt; 6.不可分析 -&gt; 8.不可通信 -&gt; 10.不可用于决策</p><h4 id="Infrastructure"><a href="#Infrastructure" class="headerlink" title="Infrastructure"></a>Infrastructure</h4><p>Infrastructure包括：Multiple nodes、CPU或GPUs、FPGAs、ASICs、Memory、Storage、Network</p><p>方法：并行化任务、并行化数据（分布数据）</p><p>应用：大规模并行 (Massive parallelism)、庞大的数据量存储、分布式数据、高速网络、高性能计算、任务和线程管理、数据挖掘和分析、数据检索、机器学习、数据可视化</p><h4 id="分层结构-Layered-architecture"><a href="#分层结构-Layered-architecture" class="headerlink" title="分层结构 Layered architecture"></a>分层结构 Layered architecture</h4><p>Layered approach最适合组织大数据系统的结构</p><p>是逻辑上的分层，而不一定要在把不同的层功能分别放在不同的机器上</p><p>按商业分层：大数据资源、数据传输和存储层、分析层、消费Consumption层</p><p>按技术分层：信息整合、大数据统治、系统管理、服务质量</p><h4 id="来源层-Sources-layer"><a href="#来源层-Sources-layer" class="headerlink" title="来源层 Sources layer"></a>来源层 Sources layer</h4><p>指的是“来自于所有渠道的，可用于分析的，所有数据”。分析的类型和来源密切相关</p><p>格式：结构化的、半结构化的、非结构化的</p><p>Velocity和Volume：数据传入(arrives)的速度，以及数据传递速率(rate)根据数据源而不同</p><p>采集点：实时或分批采集数据的来源（直接采集或者源自数据提供者）。数据可以来自主要或次要来源。</p><p>数据源的地点：数据源可以在企业内部或外部。 <u>需要标识限制访问的数据，因为对数据的访问会影响可用于分析的数据范围</u></p><h4 id="数据通信和存储层-Data-Messaging-and-Store-Layer"><a href="#数据通信和存储层-Data-Messaging-and-Store-Layer" class="headerlink" title="数据通信和存储层 Data Messaging and Store Layer"></a>数据通信和存储层 Data Messaging and Store Layer</h4><p>Storage manager管理多个数据节点（将存储拆分）</p><p>负责从数据源获取数据——<strong>数据获取Acquisition</strong>：从数据源采集数据，然后对数据进行格式化或存储。</p><p>如果有必要，该层还能负责对数据进行格式化用于分析——<strong>数据消化Digest</strong>：简单的转化逻辑或复杂的统计算法对数据进行格式化，最大的挑战是对<strong>非结构化</strong>数据的格式化。</p><p>服从规定regulations和统治政策governance policies，为不同类型的数据提供适当的存储——<strong>分布式存储Distributed storage</strong>：负责存储数据，通常提供多种数据存储方式，比如分布式文件存储DFS、cloud、结构化数据源、NoSQL等</p><h4 id="分析层-Analysis-Layer"><a href="#分析层-Analysis-Layer" class="headerlink" title="分析层 Analysis Layer"></a>分析层 Analysis Layer</h4><p>Job manager管理多个处理节点（将分析任务拆分）</p><p>分析层的职责（如何设计分析层）：产生所需的分析；从数据中推断出观点insight；找到所需的实体；定位可以为实体提供数据的数据源；了解所需的算法和工具</p><p>辨别实体 Entity：负责表示和填充上下文的实体；需要高效的高性能处理；定义了数据的格式；提供给分析引擎</p><p>分析引擎：使用其他组件进行分析和处理数据</p><p>模型管理：负责维护不同的统计模块，并通过不断训练确保这些模块的精确性</p><h4 id="消费层Consumption-Layer"><a href="#消费层Consumption-Layer" class="headerlink" title="消费层Consumption Layer"></a>消费层Consumption Layer</h4><p>使用分析层的数据；消费者是以可视化软件、人、商业过程、服务；</p><p>难点在于可视化数据（可以向竞争者学习 look at what competitors in similar markets are doing）</p><p>组件：</p><ul><li>事务拦截：实时拦大量额事务，并将之转化为合适的格式给实时分析；使用不同的适配器和接口，对不同来源的数据进行整合和处理</li><li>商业过程管理进程：API，BPEL和其他流程可以使用来自分析层的Insight，从而通过自动化上下游应用程序，人员和流程的功能来推动价值。</li><li>实时监测：使用分析层的输出可以生成警告Alerts，并发送给设备或用户；实时数据可以以仪表板的形式提供。</li><li>报告引擎：生成类似于传统商业智能报告的报告至关重要。 用户可以基于来自分析层的洞察力Insight来创建临时报告，计划的报告或自我查询和分析。</li><li>推荐引擎：根据分析结果，向用户提供个性化的实时相关建议。引擎会实时处理可用信息，并根据用户的实时活动动态响应每个用户。</li><li>可视化和发现：可以在企业内部和外部的各种联合数据源之间导航数据。 数据的内容和格式可以不同，可以合并以进行可视化。</li></ul><h4 id="信息整合层-Information-Integration-Layer"><a href="#信息整合层-Information-Integration-Layer" class="headerlink" title="信息整合层 Information Integration Layer"></a>信息整合层 Information Integration Layer</h4><p>负责连接不同的数据源；需要优质的连接器和适配器（比如通信协议、API、网络服务），工业4.0平台的作用就是简化这部分</p><h4 id="数据统治层-Data-Governance-Layer"><a href="#数据统治层-Data-Governance-Layer" class="headerlink" title="数据统治层 Data Governance Layer"></a>数据统治层 Data Governance Layer</h4><p>核心原则：合法、公正、透明；目的限制、数据最小化、准确性、存储限制、诚信和保密、问责制Accountability</p><p>至少需要考虑：数据发现、保障措施、同意管理、数据最小化、使用情况监控、违规Breach通知</p><p>通用数据保护规则：数据控制器、数据处理器</p><h4 id="数据管理层-System-Management-Layer"><a href="#数据管理层-System-Management-Layer" class="headerlink" title="数据管理层 System Management Layer"></a>数据管理层 System Management Layer</h4><p>监视和管理整个大数据生态系统的健康状况。</p><p>包括：云消费者、云审计者 Auditor、云提供者、云中介者 Broker、云运输者 Carrier</p><h4 id="服务质量层-QoS-Quality-of-Service-Layer"><a href="#服务质量层-QoS-Quality-of-Service-Layer" class="headerlink" title="服务质量层 (QoS) Quality of Service Layer"></a>服务质量层 (QoS) Quality of Service Layer</h4><p>定义数据质量，有关隐私和安全性的政策，数据的频率等</p><h4 id="大数据层结构总览"><a href="#大数据层结构总览" class="headerlink" title="大数据层结构总览"></a>大数据层结构总览</h4><h4 id="传统系统-VS-大数据系统"><a href="#传统系统-VS-大数据系统" class="headerlink" title="传统系统 VS 大数据系统"></a>传统系统 VS 大数据系统</h4><p>应用开发：传统系统利用高级HPC专家开发的并行性进行优化和调整的应用程序；大数据系统简化的应用程序执行模型（分布式文件系统，编程模型，分布式数据库和调度程序）。</p><p>平台：传统系统使用高成本的大规模并行处理（MPP）计算机，利用高带宽网络和大规模I / O设备；大数据系统创建可扩展但具有弹性的虚拟化平台的创新方法。</p><p>数据管理：传统系统限于使用标准的面向行的数据布局的基于文件或RDBMS；大数据系统使用数据管理的可替换模型（通常为NoSQL），具有根据需要管理信息的多种方法。</p><p>资源：传统系统需要大量资本投资来购买要在内部安装和管理的高端硬件。大数据系统能够在虚拟平台（尤其是云）上部署系统，从而降低了进入门槛。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>INTRODUCTION, HISTORY, AND DEFINITIONS</title>
      <link href="/2013/07/Big%20Data%20System/01%20INTRODUCTION,%20HISTORY,%20AND%20DEFINITIONS/"/>
      <url>/2013/07/Big%20Data%20System/01%20INTRODUCTION,%20HISTORY,%20AND%20DEFINITIONS/</url>
      
        <content type="html"><![CDATA[<h2 id="L1-INTRODUCTION-HISTORY-AND-DEFINITIONS"><a href="#L1-INTRODUCTION-HISTORY-AND-DEFINITIONS" class="headerlink" title="L1 INTRODUCTION, HISTORY, AND DEFINITIONS"></a>L1 INTRODUCTION, HISTORY, AND DEFINITIONS</h2><h4 id="IoT"><a href="#IoT" class="headerlink" title="IoT"></a>IoT</h4><p>指环境中的人、动物、或物体具有唯一标识符，能够通过网络传输数据，而不需要人与人或人与电脑的交互</p><h4 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h4><p>复杂和巨大的数据集，使得传统的数据库软件工具无法获取、储存、管理和分析</p><h4 id="大数据的3个特征-——-Volume-Velocity-Variety"><a href="#大数据的3个特征-——-Volume-Velocity-Variety" class="headerlink" title="大数据的3个特征 —— Volume Velocity Variety"></a>大数据的3个特征 —— Volume Velocity Variety</h4><p>Volume：就存储和访问而言，数据的尺寸觉得庞大</p><p>Velocity：数据传入的速度以及处理时间</p><p>Variety：文件的种类，数据的格式和来源</p><h4 id="Volume增长的因素"><a href="#Volume增长的因素" class="headerlink" title="Volume增长的因素"></a>Volume增长的因素</h4><p>基于交易的数据的不断积累</p><p>来自社交媒体的 Unstructured data streaming 非结构化数据流，结合关系数据（评论、讨论、支持投票等）</p><p>其他例子：</p><p>Facebook and Youtube have billions of users, Twitter and Instagram have hundreds of millions users. Every day, these users contribute to billions of images, posts, videos, tweets etc.</p><p>Most of the companies in the US have at least 100 Terabytes of data stored.</p><p>It’s estimated that 2.5 quintillion bytes of data are created each day.</p><h4 id="Velocity"><a href="#Velocity" class="headerlink" title="Velocity"></a>Velocity</h4><p>数据速度，既是数据流入(stream in)的速度，也是处理数据的速度以保证数据的时效性(timeliness)</p><p>比如：</p><p>实时处理和储存国家天气信息、即时响应高频率的股票交易和快速分析、</p><p>Tmall’s total turnover exceeded 10 billion CNY in the first 96 seconds at 11/11 last year</p><p>Modern cars have close to 100 sensors that monitor items such as fuel level and tire pressure</p><h4 id="Variety"><a href="#Variety" class="headerlink" title="Variety"></a>Variety</h4><p>Variety is all about the ability to classify the incoming data into various categories.多样性是指将传入数据分类为各种类别的能力。</p><p>数据有各种各样的格式，但可以被分为2种：<strong>structured 结构化</strong> 和 <strong>unstructured 非结构化</strong></p><p><strong>结构化数据</strong>：是传统数据库中的数字数据，从业务线(line-of-business)和预格式化(pre-formatted)数据中创建，随时间推移收集</p><p><strong>非结构化数据</strong>：是相关的或看似无关的数据，来自非结构化来源（社交媒体，文本文档，电子邮件，视频，音频等）</p><p>比如：</p><p>data in healthcare、data from wearable, wireless health monitors、pieces of content from Facebook and Twitter</p><h4 id="Veracity-和-Value-——-用于描述大数据的特征，而不是定义特征"><a href="#Veracity-和-Value-——-用于描述大数据的特征，而不是定义特征" class="headerlink" title="Veracity 和 Value —— 用于描述大数据的特征，而不是定义特征"></a>Veracity 和 Value —— 用于描述大数据的特征，而不是定义特征</h4><p>Veracity：数据的准确性和意义的多少</p><p>Value：从数据中可获得的价值的多少</p>]]></content>
      
      
      <categories>
          
          <category> Diary </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PS3 </tag>
            
            <tag> Games </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>EXAMPLES AND TECHNOLOGY LANDSCAPE</title>
      <link href="/2013/07/Big%20Data%20System/02%20EXAMPLES%20AND%20TECHNOLOGY%20LANDSCAPE/"/>
      <url>/2013/07/Big%20Data%20System/02%20EXAMPLES%20AND%20TECHNOLOGY%20LANDSCAPE/</url>
      
        <content type="html"><![CDATA[<h2 id="02-EXAMPLES-AND-TECHNOLOGY-LANDSCAPE"><a href="#02-EXAMPLES-AND-TECHNOLOGY-LANDSCAPE" class="headerlink" title="02 EXAMPLES AND TECHNOLOGY LANDSCAPE"></a>02 EXAMPLES AND TECHNOLOGY LANDSCAPE</h2><p>大数据的分类、场景、大数据公司</p><h4 id="什么是大数据"><a href="#什么是大数据" class="headerlink" title="什么是大数据"></a>什么是大数据</h4><ol><li>大量数据的收集</li><li>从中获得收益</li></ol><p>大数据不是一个单独的科技、技术、或创新，而是一个可表征的趋势</p><h4 id="大数据工具和技术"><a href="#大数据工具和技术" class="headerlink" title="大数据工具和技术"></a>大数据工具和技术</h4><ul><li>数据操控和分析：用于计算和回答明确的问题</li><li>数据挖掘：发现数据的模式(patterns)</li><li>机器学习：对缺失或未来的数据，进行预测或推断</li><li>数据可视化：把数据绘制成图像、Tableau</li><li>数据采集和准备：填充缺失数值、移除可疑的数据、格式化</li></ul><h4 id="如何表达大数据——Causation-因果关系-amp-Correlation-相关性"><a href="#如何表达大数据——Causation-因果关系-amp-Correlation-相关性" class="headerlink" title="如何表达大数据——Causation 因果关系 &amp; Correlation 相关性"></a>如何表达大数据——Causation 因果关系 &amp; Correlation 相关性</h4><p>Correlation Does Not Imply Causation 相关性并不意味着因果关系</p><p>错误的把相关性当做是因果关系会导致经济损失等各种严重的后果</p><p>比如通过大数据发现：books in the home correlated to higher test scores，这几乎导致State of Illinois向州里的孩子们送书。但后来的研究发现：homes where parents buy books have an environment where learning is encouraged and rewarded。</p><p>These are correlation versus causation in plain view. 在普通的视野里，这些是Correlation而不是Causation</p><p>Illinois didn’t have money to waste going in the wrong direction and neither does today’s enterprise. </p><h4 id="大数据的分类"><a href="#大数据的分类" class="headerlink" title="大数据的分类"></a>大数据的分类</h4><ul><li>分析类型：实时，分批</li><li>处理方法：预测分析，分析：社交网络分析、基于位置的分析、特征识别、文本分析、统计算法、转录(transcription)、语音分析，查询和报告，杂项(miscellaneous)：3D重建、翻译</li><li>数据频率：按需的、连续的、实时的、时间系列的；（the feeds可以是每月周日时分秒）</li><li>数据类型：媒体(Meta)数据，基准(Master)数据，历史数据、交易数据</li><li>内容格式：结构化的、非结构化的、半结构化的 —— 图像、文本、视频、文档、音频</li><li>数据来源：网页和社交媒体、机器、人类、网络数据源、交易数据、生物数据、通过数据供应商(Provider)、通过数据产生者(Originator)</li><li>数据的消费者：人、商业进程、其他企业应用、其他数据仓库</li><li>硬件：日常硬件、最新硬件</li></ul><h4 id="场景例子"><a href="#场景例子" class="headerlink" title="场景例子"></a>场景例子</h4><p>人体佩戴设备：</p><ul><li>Volume：每个人每时每刻都会产生数据，如果所有人都佩戴，那么数据会不断积累；</li><li>Velocity：有些传感器需要实时更新数据到监控设备中，监控设备还需要即刻处理数据并反馈结果给用户；</li><li>Variety：各种各样的数据，比如Scanadu Scout测体温、心率、血压，EPOC - Emotiv 探测用户情绪，Rapid Rehab System测用户的走路模式；</li><li>Veracity：比如Asthmapolis需要精确的测量剂量dosage</li><li>Value：比如Hydration Sensor测量并分析用户的hydration level，可以提醒用户什么时候喝水，该喝多少水</li></ul><p>其他场景：智能商场，设备状况监控，汽车联网和自动驾驶，智能运输 Intelligent Transport，智能网格 Smart Grid，推荐系统，金融</p>]]></content>
      
      
      <categories>
          
          <category> BDS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> a </tag>
            
            <tag> b </tag>
            
            <tag> c </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
