<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>图像分割 Image segmentation</title>
      <link href="/2020/03/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%20Image%20segmentation/"/>
      <url>/2020/03/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%20Image%20segmentation/</url>
      
        <content type="html"><![CDATA[<p>颜色colour分割、行动motion分割、语义semantic分割</p><a id="more"></a><h3 id="颜色分割"><a href="#颜色分割" class="headerlink" title="颜色分割"></a>颜色分割</h3><p>将像素的颜色从0-255映射到0-1，然后打印在3D散点图上</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcyciroftqj30z60hyanc.jpg" alt="截屏2020-03-18下午12.18.52"></p><p>对像素点进行聚类（比如k-means），每个聚类用聚类中心的颜色表示</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcycqvympuj310w0iawq0.jpg" alt="截屏2020-03-18下午12.26.45"></p><h3 id="行动分割"><a href="#行动分割" class="headerlink" title="行动分割"></a>行动分割</h3><p>固定镜头，检测移动物体的像素</p><p>原理：对于某个固定的像素点，当移动物体经过该点时，该点的像素值会剧烈变化</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcycyn0svqj30oe09waau.jpg" alt="截屏2020-03-18下午12.34.13"></p><p>具体：</p><ol><li>对背景建模：选择视频中出现的空场景的时候，计算对每个像素计算RGB均值（<script type="math/tex">l=\frac{r+b+g}3</script>）和标准差（<script type="math/tex">\sigma=\frac1T\sum_{t=1}^T(l_t-\mu)^2,\mu=\frac1T\sum^T_{t=1}l_t</script>）</li><li><script type="math/tex">\mu\pm\lambda\sigma</script>作为像素值的可接受波动范围</li><li>计算每帧画面的异常点：<script type="math/tex">|l-\mu|>\lambda\sigma</script></li></ol><h4 id="Blob-finding-Algorithm-光团检测算法"><a href="#Blob-finding-Algorithm-光团检测算法" class="headerlink" title="Blob finding Algorithm 光团检测算法"></a>Blob finding Algorithm 光团检测算法</h4><p>原理：</p><ul><li>使用两个2*2的卷积核，对背景画面（前部）和当前画面（后部）进行扫描，计算灰度值总和，并相减。如果当前画面没有<u>前景</u>存在，这个前部与后部灰度值总和差应该是趋近0的。</li><li>如果矩阵扫描到了一块前景的边缘，这时矩阵前部与后部灰度值总和差突变了，灰度值不再接近，则是到了一个Blob。当算法扫描完整的时候，系统就记录了全部发生这种突变情况的点的坐标。之后再对这些边缘点进行一系列的分析，便可以得到这个Blob的大小、形状及面积等信息。</li></ul><blockquote><p>Blob是指图像中的一块连通区域</p><p>Blob分析就是对前景/背景分离后的<strong>二值图像</strong>，进行连通域提取和标记。标记完成的每一个Blob都代表一个前景目标，然后就可以计算Blob的一些相关特征，如：面积、质心、外接矩形等几何特征，还可以计算Blob的颜色、纹理特征，这些特征都可以作为跟踪的依据。</p><p>其优点在于通过Blob提取，可以获得相关区域的信息，但是速度较慢，分析难度大。</p></blockquote><p>找出光团Blob：当图像分割为背景像素和目标像素后，需要进行连通性分析，以便将目标图像聚合为目标像素或斑点的聚合体</p><ol><li>查找连通区域（4向8向邻接）</li><li>忽略只有几个像素的区域</li><li>用最小的矩形表示剩余的内容</li></ol><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcyf02692pj30yi0duwfy.jpg" alt="截屏2020-03-18下午1.44.46"></p><p><strong>目前的Blob算法有几个缺点：</strong></p><p>1、速度过慢，要整个区域作逐点扫描。</p><p>2、Blob分析难度大。这是一纯几何学上的问题，一个不规则的形状，如何计算它的面积、大小没有简单易行的算法，太过复杂，运算时间就长，速度就更慢了。另外，实际应用中，没有单纯的表面检测，在一个场景中通常要检测几个区域块，<a href="https://baike.baidu.com/item/表面检测/7051254" target="_blank" rel="noopener">表面检测</a>只是其中一项。这就使Blob分析算法的局限性更为明显。比如，我们做一个印刷品的检测：一是检测印刷品上印上去的字是否清楚；二是检测印刷品表面有没有划痕。于是，Blob算法就要能区别出哪个是文字，哪个是划痕。</p><p>3、实际应用。Blob算法在实际应用中，非常依赖光源。几乎可以说，Blob算法如果离开了一个可靠的光源设计，则完全不起作用。场景中有各种不同的颜色，这些颜色上的差异，在黑白相机下来看，就是灰度值的变化，因为颜色的表现跟光源有很大的关系，所以一个稳定的光源是必须的。</p><p><strong>Blob在目标跟踪的优势有：</strong></p><p>（1）通过Blob提取，可以获得相关区域的信息，这些信息可以作为边缘监测器或者角点检测器的补充信息。在目标识别中，Blob可以提供局部的统计信息和外貌信息，这些信息能够为目标识别和跟踪提供依据；</p><p>（2）可以利用Blob对直方图进行峰值检测；</p><p>（3）Blob还可以作为纹理Texture分析和纹理识别的基元；</p><p>（4）通过Blob分析，可以得到目标的个数及其所在区域，在进行目标匹配时，不需要对全局图像进行搜索。</p><h4 id="更新背景"><a href="#更新背景" class="headerlink" title="更新背景"></a>更新背景</h4><p>以下原因导致背景需要更新：</p><ol><li>场景中的物体被移动了</li><li>亮度变化（比如因为云）</li><li>相机自动光圈变化</li><li>相机的移动</li></ol><h4 id="更新算法"><a href="#更新算法" class="headerlink" title="更新算法"></a>更新算法</h4><script type="math/tex; mode=display">\mu_t=(1-\rho)\mu_{t-1}+\rho l_t</script><script type="math/tex; mode=display">\sigma^2=(1-\rho)\sigma^2_{t-1}+\rho(l_t-\mu_t)^2</script><p>该算法的问题是：移动的物体也开始融合到背景中</p><h4 id="使用中位数median"><a href="#使用中位数median" class="headerlink" title="使用中位数median"></a>使用中位数median</h4><p>我们需要一个“稳健robust”的估算器，通过忽略由移动物体引起的瞬态“离群值”来为我们<strong>提供所需的背景值</strong>。中位数提供了典型分布平均值的近似值</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcyjx11imej30y80g0wmq.jpg" alt="截屏2020-03-18下午4.34.51"></p><h3 id="语义分割"><a href="#语义分割" class="headerlink" title="语义分割"></a><a href="https://blog.csdn.net/say_hi_andhelloworld/article/details/94839562" target="_blank" rel="noopener">语义分割</a></h3><h4 id="Pixel-wise-逐像素"><a href="#Pixel-wise-逐像素" class="headerlink" title="Pixel-wise 逐像素"></a>Pixel-wise 逐像素</h4><p>语义分割是指<strong>在认知图像时具体到像素级别，就是给图像中的每一个像素分配一个类别</strong>。如下图所示，左图为原图，而右图为语义分割结果。在右图中，分别用红色与绿色将摩托车与人分割出来。</p><blockquote><p>在实际场景的图片中，一些物体的结构比较复杂,内部差异性较大，仅利用像素点的颜色、亮度、纹理等较低层次的内容信息不足以生成好的分割效果，容易产生错误的分割。因此需要更多地结合图像提供的中高层内容信息辅助图像分割，称为图像语义分割。</p><p>深度学习对高级语义信息的model能力很大程度上解决了传统图像分割方法中语义信息缺失的问题。</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcykdlk3zwj30ne0iutk3.jpg" alt="截屏2020-03-18下午4.50.46" style="zoom:50%;" /></p><h4 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h4><p>交集除以并集</p><p>$AO(B_{gt},B_p)=\frac{|B_{gt}\cap B_p|}{|B_{gt}\cup B_p|}$</p><p> <img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcykeelaz9j30dk0dgq37.jpg" alt="截屏2020-03-18下午4.51.35" style="zoom: 50%;" /></p><h4 id="逐块-Patch-wise"><a href="#逐块-Patch-wise" class="headerlink" title="逐块 Patch-wise"></a>逐块 Patch-wise</h4><p>以某个分类的像素为中心进行多尺度采样，将多尺度的局部图像patch送到CNN分类器中逐一进行分类，最终得到每个像素所属的语义类别。</p><p>卷积网络结构：</p><p>从300x300灰度图像中提取40x40大小的色块（步幅= 4），无填充卷积</p><p>50个训练图像，提供190,440个40x40的块patch，每个块中心带有像素标签</p><p>均方误差损失函数：使用独热编码表示分类后，可以用MSE loss代替cross-entroyp loss</p><blockquote><p>MSE：预测值与真实值相减的平方，求和，再除总数。反映在矩阵上，就是每个样本的输出矩阵与标签矩阵中，每个元素相减的平方，求和，再除以元素总数。（在这里，卷积输出的格式为one-hot矩阵）。对于整个批次来说，同理</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcylabsussj30dg0l8ta9.jpg" alt="截屏2020-03-18下午5.22.15" style="zoom: 50%;" /></p><h4 id="使用编码-解码结构"><a href="#使用编码-解码结构" class="headerlink" title="使用编码-解码结构"></a>使用编码-解码结构</h4><p>从word2vec skip-gram中得到启发</p><p><strong>autoencoder</strong>：</p><p>输入和输出相同。 因此，autoencoder学习了压缩的编码（代码，嵌入，表示）。 注意，这是非监督的（不需要输入/输出对）。</p><p>为了简化起见，编码器-解码器通常表示为：<img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcypiduyzoj30jy082weu.jpg" alt="截屏2020-03-18下午7.48.22" style="zoom: 33%;" /></p><p>例如，自动编码器可以从图像数据集中学习图像特征。 在这种情况下，编码器和解码器通常是CNN。结果类似于CNN分类器的特征层，不过是非监督的。</p><h4 id="在语义分割中使用encoder-decoder结构："><a href="#在语义分割中使用encoder-decoder结构：" class="headerlink" title="在语义分割中使用encoder-decoder结构："></a>在语义分割中使用encoder-decoder结构：</h4><p>使用maxpooling缩小尺寸，使用“up-convolution”扩展尺寸。</p><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcypksl6u0j30vg08ead2.jpg" alt="截屏2020-03-18下午7.50.40"></p><h4 id="U-net"><a href="#U-net" class="headerlink" title="U-net"></a>U-net</h4><blockquote><p>5个pooling layer实现了网络对图像特征的多尺度特征识别。</p><p>上采样部分会融合特征提取部分的输出，这样做实际上是将多尺度特征融合在了一起，以最后一个上采样为例，它的特征既来自第一个卷积block的输出(同尺度特征)，也来自上采样的输出(大尺度特征)，这样的连接是贯穿整个网络的，你可以看到上图的网络中有四次融合过程</p></blockquote><p><img src="https://tva1.sinaimg.cn/large/00831rSTgy1gcypo9d7vpj31260m8do5.jpg" alt="截屏2020-03-18下午7.54.01"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/03/hello-world/"/>
      <url>/2020/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p><div class="pdfobject-container" data-target="https://curve.carleton.ca/system/files/etd/8156865c-4c77-4dbb-9a45-c3ccc42af3c1/etd_pdf/21bf1800ee5857b9170ae6d843e35c03/afriyie-anempiricalstudyinvestigatingthepredictors.pdf" data-height="500px"></div>]]></content>
      
      
      <categories>
          
          <category> 技术 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>08 Information Extraction</title>
      <link href="/2020/02/08%20Information%20Extraction/"/>
      <url>/2020/02/08%20Information%20Extraction/</url>
      
        <content type="html"><![CDATA[<h2 id="08-Information-Extraction"><a href="#08-Information-Extraction" class="headerlink" title="08 Information Extraction"></a>08 Information Extraction</h2><p><strong>Information Retrieval</strong>，从大的本文集中（通常是网站），根据关键字或查询，获取文档documents。用于分析文档。（如搜索引擎）</p><ul><li>返回的文档可能包含需求相关的信息（不一定）</li></ul><p><strong>Information Extraction</strong>，从大的文本集的内容中，获取事实facts，和结构化的信息。用于分析事实</p><ul><li><p>IE返回结构化的信息</p></li><li><p>比IR返回的knowledge更加深入</p></li><li><p>通过IE构建数据库，并与文档关联，可以形成另一种形式的搜索工具。</p><ul><li>即使结果不够精确，人们也可以从关联的原始文档中查找。（相当于另一种形式的IR）</li></ul></li><li><p>使用场景：</p><ul><li>新闻：分辨主要的关系 major relations，和事件种类 event types；</li><li>科学报告：分辨关系relations和涉及的科学领域subfield</li></ul></li></ul><h4 id="例子：HASIE、KIM、Threat-tracker"><a href="#例子：HASIE、KIM、Threat-tracker" class="headerlink" title="例子：HASIE、KIM、Threat tracker"></a>例子：HASIE、KIM、Threat tracker</h4><p><strong>HaSIE</strong>，IE系统，自动找出公司对健康和安全问题的报告，自动识别文档的每个部分，从中提取出关于健康和安全问题的句子，并存入数据库。</p><p><strong>KIM</strong>，简化的数据库查询页面</p><p><strong>Threat tracker</strong>：识别文章中出现的实体（名词）</p><h4 id="如何识别命名实体-Named-Entity-NE-Recognition"><a href="#如何识别命名实体-Named-Entity-NE-Recognition" class="headerlink" title="如何识别命名实体 Named Entity (NE) Recognition"></a>如何识别命名实体 Named Entity (NE) Recognition</h4><p>识别文字中的命名实体，并将他们分类到提前定义好的类别中</p><p>命名实体包括：人、组织、地点、日期、其他</p><p>是构建复杂IE系统的基础</p><p>命名实体之间的关系可以用于追踪tracking、信息本体论ontological information、情景构建scenario building</p><blockquote><p>本体就是一种特殊类型的<a href="https://zh.wikipedia.org/wiki/术语集" target="_blank" rel="noopener">术语集</a>，具有结构化的特点，且更加适合于在<a href="https://zh.wikipedia.org/wiki/信息系统" target="_blank" rel="noopener">计算机系统</a>之中使用；或者说，本体实际上就是「对特定<a href="https://zh.wikipedia.org/wiki/论域" target="_blank" rel="noopener">领域</a>之中某套<a href="https://zh.wikipedia.org/wiki/概念" target="_blank" rel="noopener">概念</a>及其相互之间<a href="https://zh.wikipedia.org/wiki/关系_(数学" target="_blank" rel="noopener">关系</a>)的形式化表达（formal representation）」</p></blockquote><h4 id="两种途径"><a href="#两种途径" class="headerlink" title="两种途径"></a>两种途径</h4><p><strong>知识工程Knowledge Engineering</strong>：基于规则、由有经验的语言学工程师开发、采用人类的直觉、开发周期长、有些变化很难适应</p><p><strong>学习系统Learning System</strong>：采用统计学或机器学习、开发者不需要语言学专业技能、需要大量的带注解的训练数据annotated training data、有些更改可能需要重新标注整个训练语料库</p><h4 id="NE命名实体中的问题"><a href="#NE命名实体中的问题" class="headerlink" title="NE命名实体中的问题"></a>NE命名实体中的问题</h4><p>实体的多样性：John Smith / Mr Smith, John</p><p>实体种类的不确定性：John Smith 人或公司</p><p>常用词的一词多义：may</p><h4 id="MUSE-–-MUlti-Source-Entity-Recognition"><a href="#MUSE-–-MUlti-Source-Entity-Recognition" class="headerlink" title="MUSE – MUlti-Source Entity Recognition"></a>MUSE – MUlti-Source Entity Recognition</h4>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>07 Unsupervised ML Association Rules, Clustering</title>
      <link href="/2020/02/07%20Unsupervised%20ML%20Association%20Rules,%20Clustering/"/>
      <url>/2020/02/07%20Unsupervised%20ML%20Association%20Rules,%20Clustering/</url>
      
        <content type="html"><![CDATA[<h2 id="07-Unsupervised-ML-Association-Rules-Clustering"><a href="#07-Unsupervised-ML-Association-Rules-Clustering" class="headerlink" title="07 Unsupervised ML: Association Rules, Clustering"></a>07 Unsupervised ML: Association Rules, Clustering</h2><h4 id="关联规则-Assoication-Rules"><a href="#关联规则-Assoication-Rules" class="headerlink" title="关联规则 Assoication Rules"></a>关联规则 Assoication Rules</h4><p>基本算法：</p><ul><li>生成覆盖范围大于某些指定的最小覆盖范围的所有规则；</li><li>仅从这些规则中选择精度高于某些指定的最低精度（例如100％！）的规则。</li></ul><p><strong>$n$-item sets</strong> (with minimum coverage = $m$)：任意n个属性，且满足attr-val对的实例数量超过m个</p><p>Minimun coverage = $m$</p><p>Rules from : attr1=val1, attr2=val2, … </p><p>If …[Case]… then …</p><p><strong>Coverage</strong>：满足“attr=val”的所有实例</p><p><strong>Accuracy</strong> = Coverage / Cases</p><h4 id="聚类算法：K-means"><a href="#聚类算法：K-means" class="headerlink" title="聚类算法：K-means"></a>聚类算法：K-means</h4><p>计算欧几里得距离</p><p>将属性从nominal转化为numerical：可以是一维向量，或者N维数组</p><h4 id="聚类算法：增量聚类-Incremental-Clustering"><a href="#聚类算法：增量聚类-Incremental-Clustering" class="headerlink" title="聚类算法：增量聚类 Incremental Clustering"></a>聚类算法：增量聚类 Incremental Clustering</h4><p>算法：根据category utility，把每一个实例添加到当前的树中最合适的位置。</p><ul><li>一次添加一个实例，建立树状图</li><li>通过<strong>category utility</strong>，对与每一个新的实例，决定该实例应该划分到哪个簇cluster，或划分为一个新的簇</li><li><strong>category utility</strong>是一个测量方法，用于判断一个簇的好坏，它不需要属性值为数字</li></ul><h4 id="比较Kmeans和增量聚类"><a href="#比较Kmeans和增量聚类" class="headerlink" title="比较Kmeans和增量聚类"></a>比较Kmeans和增量聚类</h4><p>两者都无法保证全局最优</p><p>Kmeans的效果取决于聚类的数量和聚类中心的初始位置</p><p>增量聚类生成可以检查和推理的层次结构</p><p>增量聚类的效果取决于实例被添加的顺序</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>06 Supervised ML to learn Classifiers Decision Trees and Classification Rules</title>
      <link href="/2020/02/06%20Supervised%20ML%20to%20learn%20Classifiers%20Decision%20Trees%20and%20Classification%20Rules/"/>
      <url>/2020/02/06%20Supervised%20ML%20to%20learn%20Classifiers%20Decision%20Trees%20and%20Classification%20Rules/</url>
      
        <content type="html"><![CDATA[<h2 id="06-Supervised-ML-to-learn-Classifiers-Decision-Trees-and-Classification-Rules"><a href="#06-Supervised-ML-to-learn-Classifiers-Decision-Trees-and-Classification-Rules" class="headerlink" title="06 Supervised ML to learn Classifiers: Decision Trees and Classification Rules"></a>06 Supervised ML to learn Classifiers: Decision Trees and Classification Rules</h2><h4 id="数据挖掘的目标"><a href="#数据挖掘的目标" class="headerlink" title="数据挖掘的目标"></a>数据挖掘的目标</h4><p>发现数据中有用的模式，因此我们需要数据挖掘技术、算法、工具（如Weka），和用于采集数据，应用算法的方法学框架（CRISP-DM）</p><p>机器学习中的监督学习：训练集已经被分类</p><h4 id="概念-Concept"><a href="#概念-Concept" class="headerlink" title="概念 Concept"></a>概念 Concept</h4><p>Concept 的定义：</p><ul><li>数据集间的关键区别：比如某区域不同年份的销售额sales的区别</li><li>簇clusters 或自然分隔partitions：根据用户的购物习惯对用户进行分类</li><li><p>分类的规则：Adj+X+Verb =&gt; X=Noun</p></li><li><p>通用的关联：高频词一般是语法性的，而不是有含义的</p></li><li>数字的预测：找到预测数值的规则，比如根据成绩预测毕业生的工资</li></ul><h4 id="决策树的构建方法"><a href="#决策树的构建方法" class="headerlink" title="决策树的构建方法"></a>决策树的构建方法</h4><p>建立决策树</p><p>决定用哪个属性划分节点：基于entropy熵</p><p>避免过度拟合：决策树太复杂，能够精确的描述训练集，但不适合用于预测</p><p>异常点</p><h4 id="建立决策树"><a href="#建立决策树" class="headerlink" title="建立决策树"></a>建立决策树</h4><p>算法是递归的</p><p>节点表示在该属性值上进行分类（测试），分支表示分类（测试）的输出</p><p>决策树算法会选择information gain最高的属性进行划分</p><p>目标：更小更紧凑的树（节点数量少），和更低的错误率（错误划分）；如果精确度相同，那么优先选择更小的树</p><h4 id="Entropy-熵"><a href="#Entropy-熵" class="headerlink" title="Entropy 熵"></a>Entropy 熵</h4><p>$H=E(I)=\sum_i(-p_ilog_2p_i)$</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Information_Gain &#x3D; Entropy_before - Entropy_after</span><br></pre></td></tr></table></figure><p>ID3会选择information gain最高的属性进行划分</p><p>划分后的熵越低，最后得到的Information gain越高</p><p>该属性中，如果多个分类的数量都一样，那么熵最高；如果只有一个分类，那么熵最低</p><p>所以，如果对一个属性划分后，只有一个种类，那么决策树就会选择该属性进行划分</p><h4 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h4><p>混淆矩阵</p><p>如果决策树算法已“过度拟合”数据，则基于训练集的错误率将远小于基于测试集的错误率。</p><p>10-fold cross-validation：将数据集随机分成10组（subsets），9组用于训练，1组用于测试，然后循环10次。</p><h4 id="决策树-gt-规则-Rules"><a href="#决策树-gt-规则-Rules" class="headerlink" title="决策树 =&gt; 规则 Rules"></a>决策树 =&gt; 规则 Rules</h4><p>决策树可能不容易解释</p><ul><li>与较低节点相关的测试（属性），不得不在树的更远端中读取</li><li>有时可能会将“子概念”分解并分发到树的不同部分</li><li>计算机科学家可能更喜欢“If…then…”规则！</li></ul><h4 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h4><ul><li>决策树可用于预测或解释。<ul><li>预测：将未分类的实例与树进行比较，并预测其属于哪个类（带有错误估计）</li><li>解释：检查树并尝试了解实例为何最终归入它们所在的类。</li></ul></li><li>规则集通常更易于解释</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>04 Data Mining and Knowledge Management</title>
      <link href="/2020/02/04%20Data%20Mining%20and%20Knowledge%20Management/"/>
      <url>/2020/02/04%20Data%20Mining%20and%20Knowledge%20Management/</url>
      
        <content type="html"><![CDATA[<h2 id="04-Data-Mining-and-Knowledge-Management"><a href="#04-Data-Mining-and-Knowledge-Management" class="headerlink" title="04 Data Mining and Knowledge Management"></a>04 Data Mining and Knowledge Management</h2><p>数据挖掘利用机器学习从数据中提取/发现知识，用于知识管理。</p><p>什么是知识？管理/发现知识是什么意思？信息技术有什么用？</p><h4 id="柯林斯英语词典中的定义"><a href="#柯林斯英语词典中的定义" class="headerlink" title="柯林斯英语词典中的定义"></a>柯林斯英语词典中的定义</h4><p>一个人或一群人知道的事实、感觉、经验；知道的状态；通过经验或学习所获得的感知、意识、熟悉感；博学或知情的学习；关于某主题的特定信息</p><h4 id="朗文当代英语词典中的定义"><a href="#朗文当代英语词典中的定义" class="headerlink" title="朗文当代英语词典中的定义"></a>朗文当代英语词典中的定义</h4><p>一个人或一群人知道的事实、感觉、经验；知道某事发生过或者是真的；你所知道的关于特定的情况、事件的信息；</p><h4 id="“知识管理”中的知识"><a href="#“知识管理”中的知识" class="headerlink" title="“知识管理”中的知识"></a>“知识管理”中的知识</h4><p>三种含义：</p><ul><li>知道或熟悉或熟悉的状态（知道是什么）</li><li>行动能力（知道怎么做）</li><li>整理，记录，积累事实，方法，原理，技术</li></ul><h4 id="“知识库”中的的知识"><a href="#“知识库”中的的知识" class="headerlink" title="“知识库”中的的知识"></a>“知识库”中的的知识</h4><p>除了示例，没有对“知识库”的定义。<br>Knowledge based：推论新事实的事实和逻辑规则，例如：如果（sun = yes）和（湿度= low）然后play = yes …而且还有信息检索，语言/语音/图像</p><h4 id="Explicit-Knowledge-显性知识"><a href="#Explicit-Knowledge-显性知识" class="headerlink" title="Explicit Knowledge 显性知识"></a>Explicit Knowledge 显性知识</h4><p><strong>以文本形式记录下be articulated（清晰表达）的知识</strong>：产品规格、科学公式、电脑程序、专利、记录的最佳实践、手册。</p><p>可以储存于可以存储在知识库中（如果我们可以解决数据捕获/转换的问题，…）</p><h4 id="Tacit-Knowledge-隐性知识"><a href="#Tacit-Knowledge-隐性知识" class="headerlink" title="Tacit Knowledge 隐性知识"></a>Tacit Knowledge 隐性知识</h4><p><strong>无法以文本形式记录下来（无法清晰表达）的知识</strong>：如何骑单车、如何识别脸、如何理解句子、如何创造艺术</p><p>AI试图将隐性知识改写为显性知识，例如处理英语句子的规则</p><h4 id="Implicit-Knowledge-内含知识"><a href="#Implicit-Knowledge-内含知识" class="headerlink" title="Implicit Knowledge 内含知识"></a>Implicit Knowledge 内含知识</h4><p><strong>可以表达但尚未表达的知识</strong>：培训知识工程师和系统分析员，以识别隐性知识并帮助专家表达其知识。</p><p>可以储存于可以存储在知识库中（如果我们可以解决数据捕获/转换的问题，…）</p><h4 id="Cultural-Knowledge-文化知识"><a href="#Cultural-Knowledge-文化知识" class="headerlink" title="Cultural Knowledge 文化知识"></a>Cultural Knowledge 文化知识</h4><p><strong>（文化或环境带来的知识）</strong></p><p>一个组织对自身及其环境的了解（“元知识”？）：共同的信念，规范和价值观；组织成员在其中构筑现实的框架；需要了解和使用事实，规则和试探法；需要以与其他人相同的方式进行归纳，以便采取一致行动</p><h4 id="Terminology术语-and-Ontology本体"><a href="#Terminology术语-and-Ontology本体" class="headerlink" title="Terminology术语 and Ontology本体"></a>Terminology术语 and Ontology本体</h4><ul><li>本体Ontology：学科中的“概念”，和这些概念之间的意义关系<ul><li>“概念”大致等同于术语Terminology：学科中的专业单词和短语</li></ul></li><li>术语Terminology和本体论对学科中的知识进行编码</li></ul><h4 id="从数据到知识"><a href="#从数据到知识" class="headerlink" title="从数据到知识"></a>从数据到知识</h4><p>信号 Signals =1.=&gt; 数据 Data =2.=&gt; 信息 Information =3.=&gt; 知识 Knowledge</p><ol><li>物理 Physical 构造：感知、选择</li><li>认知 Cognitive 构造：意义、重要性</li><li>信念 Belief 构造：信念、证明</li></ol><h4 id="数据的不同角度（术语解释）"><a href="#数据的不同角度（术语解释）" class="headerlink" title="数据的不同角度（术语解释）"></a>数据的不同角度（术语解释）</h4><p>数据挖掘：发现数据中的模式（知识）</p><p>机器学习：算法，用于发现数据中的知识</p><p>知识发现：发现（数据中的）知识</p><p>数据库：存储知识</p><p>信息管理：使用数据</p><p>知识管理：发现并使用数据中的模式，“驯服数据”</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>数据挖掘不只是关于数据库技术</p><p>数据挖掘包括：获取数据、清洗数据、从数据中提取有用的结构或知识</p><p>数据不仅仅在数据库中</p><p>网络中大多数的数据或信息，是非结构化的文本（HTML/XML标记多少有点帮助）</p><p>所以我们需要提取、清洗、格式化数据，从“网络”的格式转化为“类似于数据库”的格式，用于数据挖掘</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>03 What “knowledge” can Data Mining learn</title>
      <link href="/2020/02/03%20What%20%E2%80%9Cknowledge%E2%80%9D%20can%20Data%20Mining%20learn/"/>
      <url>/2020/02/03%20What%20%E2%80%9Cknowledge%E2%80%9D%20can%20Data%20Mining%20learn/</url>
      
        <content type="html"><![CDATA[<h2 id="03-Data-Mining-outputs-What-“knowledge”-can-Data-Mining-learn"><a href="#03-Data-Mining-outputs-What-“knowledge”-can-Data-Mining-learn" class="headerlink" title="03 Data Mining outputs: What “knowledge” can Data Mining learn?"></a>03 Data Mining outputs: What “knowledge” can Data Mining learn?</h2><h4 id="数据挖掘、知识发现、文本挖掘"><a href="#数据挖掘、知识发现、文本挖掘" class="headerlink" title="数据挖掘、知识发现、文本挖掘"></a>数据挖掘、知识发现、文本挖掘</h4><p>数据挖掘是关于如何发现“知识”：大数据集中的模式、关系、预测规则</p><p>因此需要数据挖掘技术、算法、工具，如Weka、MatLab、R；和指导我们采集数据和发现模型的方法学框架（指导方针）：CRISP-DM</p><p>数据挖掘最初是关于从数据库中学习模式，以及将数据结构化为记录，字段</p><p>越来越多的非结构化数据（如文本），因此文本挖掘是新的数据挖掘的子领域，专注于从非结构化的文本数据中发现知识</p><h4 id="实例-Instance"><a href="#实例-Instance" class="headerlink" title="实例 Instance"></a>实例 Instance</h4><p>每个实例是被学习或描述的概念的一个例子；实例由它自身属性的值进行描述</p><p>Instance的定义取决于分类的目标：如果分类单词，那么单词是实例，如果分类句子，那么句子是实例。</p><p>数据挖掘算法的输入就是一系列实例的集合</p><p>实例表示为一系列的特征feature或属性attribute：通常来说，在文件中，一个实例instance就是文件中的一条记录record，一个属性attribute就是记录的一个字段field（attribute-instance，record-field）</p><p>从一系列实例instances中发现模式patterns，从而形成概念concepts</p><h4 id="概念-Concept"><a href="#概念-Concept" class="headerlink" title="概念 Concept"></a>概念 Concept</h4><p>Concept 的定义：</p><ul><li>数据集间的关键区别：比如某区域不同年份的销售额sales的区别</li><li>簇clusters 或自然分隔partitions：根据用户的购物习惯对用户进行分类</li><li><p>分类的规则：Adj+X+Verb =&gt; X=Noun</p></li><li><p>通用的关联：高频词一般是语法性的，而不是有含义的</p></li><li>数字的预测：找到预测数值的规则，比如根据成绩预测毕业生的工资</li></ul><h4 id="Kmeans"><a href="#Kmeans" class="headerlink" title="Kmeans"></a>Kmeans</h4><p>cluster centroids 聚类中心</p><h4 id="聚类的例子"><a href="#聚类的例子" class="headerlink" title="聚类的例子"></a>聚类的例子</h4><p>销售数据点包含买方和购物篮的信息；我们希望对不同的用户推送不同的广告；聚类分析把用户分成不同的类别的组，每个类别有不同的特征；聚类的特征与广告的种类相关联（每个簇的用户都有不同的购买偏好）；最后对用户分类</p><h4 id="输出：聚类"><a href="#输出：聚类" class="headerlink" title="输出：聚类"></a>输出：聚类</h4><p>如果不知道有多少聚类，可以先做出树状图Dendrogram</p><ul><li>根据聚类的数量/名字，对每个实例进行分类</li><li>聚类中心点</li><li>用树状图Dendrogram对结果进行展示，可以根据需求对树状图进行切割，得到不同数量的簇</li></ul><h4 id="使用案例：比较数据集"><a href="#使用案例：比较数据集" class="headerlink" title="使用案例：比较数据集"></a>使用案例：比较数据集</h4><p>寻找US vs UK专门的术语；比较这个月和上个月的数据；和几个月前的数据比较；注意新的销售增长区域；趋势：上升、下降、循环；关键的区别可能表示聚类的簇；不同的规模；</p><h4 id="输出：数据集间的不同"><a href="#输出：数据集间的不同" class="headerlink" title="输出：数据集间的不同"></a>输出：数据集间的不同</h4><p>最明显不同的关键实例/属性；关键术语的划分：names；不同数据集的趋势；整体的差别度量</p><h4 id="分类器的使用例子"><a href="#分类器的使用例子" class="headerlink" title="分类器的使用例子"></a>分类器的使用例子</h4><p>医疗记录中的大量症状和诊断数据集是可用的；找到规则来通过病人的症状预测疾病；</p><h4 id="关于决策树"><a href="#关于决策树" class="headerlink" title="关于决策树"></a>关于决策树</h4><p>无叶子节点表示特定属性的测试；边表示测试的结果；数字属性的测试通常有二元输出；普通属性的测试，通常在领域中的每个元素都有一个结果；叶子节点表示一个分类；每条路径都表示一个“实例关联到分类”的预测</p><h4 id="关于分类规则-Classification-Rules"><a href="#关于分类规则-Classification-Rules" class="headerlink" title="关于分类规则 Classification Rules"></a>关于分类规则 Classification Rules</h4><p>是决策树的替换形式：If &lt;前因antecedent&gt; then &lt;后果consequent&gt;；结果表示一个类；通常前因是条件的结合，表现在属性值上；通常我们将规则集解释为单个规则的分离</p><p>评估，规则的准确性Accuracy：它正确预测的实例数的比例，和匹配该前因的实例总数之比。</p><p>规则的优点：比树更容易理解；更紧凑；每个规则都表示一部分知识和对应得准确性</p><h4 id="例外规则"><a href="#例外规则" class="headerlink" title="例外规则"></a>例外规则</h4><p>If A then B except if C then D；比普通规则更紧凑；心理学认为这更接近人类组织知识的方式；当新实例引入时更好扩展；</p><p>对于编程的角度来说，程序会先处理异常（例外）情况，最后处理通用规则</p><h4 id="输出：其他分类器"><a href="#输出：其他分类器" class="headerlink" title="输出：其他分类器"></a>输出：其他分类器</h4><p>ZeroR、JRIP、NaiveBayes、VotedPerceptron、IB1、Bagging；输出分类器可能难以可视化、一个可以分类新实例的黑盒</p><h4 id="输出：关联规则"><a href="#输出：关联规则" class="headerlink" title="输出：关联规则"></a>输出：关联规则</h4><p>找出销售数据点之间的依赖关系可以帮助我们发现购物行为；学习规则的过程可能并不有趣</p><h4 id="关于关联规则-Assoication-Rules"><a href="#关于关联规则-Assoication-Rules" class="headerlink" title="关于关联规则 Assoication Rules"></a>关于关联规则 Assoication Rules</h4><p>类似于分类规则，但不仅可以预测分类，还能<strong>预测属性</strong></p><p>评估，规则的覆盖面Coverage：正确预测的实例的数量</p><p>评估，规则的准确性Accuracy：它正确预测的实例数的比例，和匹配该前因的实例总数之比。</p><h4 id="输出：数字预测"><a href="#输出：数字预测" class="headerlink" title="输出：数字预测"></a>输出：数字预测</h4><p>最适合使用公式；广泛应用于数学maths和统计学statistics</p><p>例子：给出关于物理环境和作物田的数字化信息，找出帮助我们在某些新条件下预测作物田的规则</p><h4 id="重点"><a href="#重点" class="headerlink" title="重点"></a>重点</h4><p>数据挖掘工具能够半自动化的发现数据的规则</p><p>不同工具用于发现不同的概念（差异，聚类，决策树，规则，数值预测）和提供不同的输出（提供聚类中心或者树状图的聚类算法）</p><p>根据业务目标选择合适的工具以用于工作：发现知识的用途是什么</p><h4 id="自测"><a href="#自测" class="headerlink" title="自测"></a>自测</h4><p>我们应该：</p><ul><li>确定哪些属性与给定的数据挖掘任务相关</li><li>确定根据业务目标定义的给定问题的适当数据挖掘技术。</li><li>确定最合适的输出形式。</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>02 Based on Intro to Data Mining CRISP-DM</title>
      <link href="/2020/02/02%20Based%20on%20Intro%20to%20Data%20Mining%20CRISP-DM/"/>
      <url>/2020/02/02%20Based%20on%20Intro%20to%20Data%20Mining%20CRISP-DM/</url>
      
        <content type="html"><![CDATA[<h2 id="02-Based-on-Intro-to-Data-Mining-CRISP-DM"><a href="#02-Based-on-Intro-to-Data-Mining-CRISP-DM" class="headerlink" title="02 Based on Intro to Data Mining: CRISP-DM"></a>02 Based on Intro to Data Mining: CRISP-DM</h2><p><strong>Cross-industry standard process for data mining</strong>, known as CRISP-DM, is an open standard process model that describes common approaches used by data mining experts. It is the most widely-used analytics model.</p><p>是一种用于数据分析的方法，而不是一种工具或者技术</p><h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><p>通过定义子任务，在整个数据挖掘过程中使用可交互工具；使任何人都能进行数据挖掘工作，而不需要特别的专业技能</p><h4 id="为什么需要标准化流程"><a href="#为什么需要标准化流程" class="headerlink" title="为什么需要标准化流程"></a>为什么需要标准化流程</h4><ul><li><strong>数据挖掘工作 Data mining process</strong>，必须要可靠reliable 并且可被缺少数据挖掘背景的人重复repeatable</li><li>需要有框架记录经历experience，使项目是可复制的</li><li>协助项目的规划planning和管理</li><li>使新采纳者“感到舒适”的因素：展示数据挖掘的成熟性；减少对“明星”的依赖</li></ul><h4 id="CRISP-DM的特点"><a href="#CRISP-DM的特点" class="headerlink" title="CRISP-DM的特点"></a>CRISP-DM的特点</h4><ul><li>非专利的 Non-proprietary</li><li>行业中立的 Application/Industry neutral</li><li>中性的工具 Tool neutral</li><li>专注于商业问题和实践问题，以及技术分析</li><li>用于指导的框架</li><li>基于经验的：用于引导和分析的例子和案例学习</li></ul><h4 id="CRISP-DM的6个阶段"><a href="#CRISP-DM的6个阶段" class="headerlink" title="CRISP-DM的6个阶段"></a>CRISP-DM的6个阶段</h4><ul><li>商业理解<ul><li>理解用户（项目）的目标和需求</li><li>定义数据挖掘问题</li></ul></li><li>数据理解<ul><li>熟悉和采集原始数据</li><li>辨别数据质量问题</li><li>初始的、明显的结果</li></ul></li><li>数据准备<ul><li>记录record，和选择属性attribute</li><li>清洗数据</li></ul></li><li>建模<ul><li>运行数据分析和数据挖掘软件</li></ul></li><li>评估<ul><li>评估结果是否符合商业目标</li><li>辨别应该提前解决的商业问题</li></ul></li><li>部署<ul><li>将建立的模型应用到实践中</li><li>为数据重复采集和连续采集做好部署</li></ul></li></ul><h4 id="6个阶段的任务细节"><a href="#6个阶段的任务细节" class="headerlink" title="6个阶段的任务细节"></a>6个阶段的任务细节</h4><p><img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gbij8b0fpbj31mx0u049s.jpg" alt="截屏2020-02-02下午4.41.12"></p><h4 id="1-商业理解"><a href="#1-商业理解" class="headerlink" title="1-商业理解"></a>1-商业理解</h4><p>关于商业目标、数据挖掘目标、和成功标准Success Criteria的陈述Statement</p><h4 id="2-数据理解"><a href="#2-数据理解" class="headerlink" title="2-数据理解"></a>2-数据理解</h4><p>采集数据、描述数据、探索数据、证实（确保）数据质量（特征和值有关联并且有意义）、辨别异常数据</p><p>Explore/verify that the features and values “<strong>seem relevant and sensible</strong>” – if not, how to transform?</p><h4 id="3-数据准备"><a href="#3-数据准备" class="headerlink" title="3-数据准备"></a>3-数据准备</h4><p>可能会占90%的时间（避免此情况）。</p><p><strong>合并Consolidation和清洗Cleaning数据</strong>：数值缺失、移除“noisy”数据（比如重复数据）、移除异常点（看情况）</p><p><strong>特征选取</strong>：选择特征、使用可视化工具</p><p><strong>转化Transformation</strong>：创建新变量、改变格式（比如拆分出训练集合测试集）</p><h4 id="4-建模"><a href="#4-建模" class="headerlink" title="4-建模"></a>4-建模</h4><p>建模方法的选择取决于数据挖掘的目标</p><p>建模可以是迭代过程</p><p>模型可能用于描述或预测（或both）</p><h4 id="5-模型评估"><a href="#5-模型评估" class="headerlink" title="5-模型评估"></a>5-模型评估</h4><p>评估模型的性能和对商业需求的达成度(how well it met)：比如是否找到并量化关键特征</p><p>方法methods和标准criteria取决于模型的种类：比如混淆矩阵用于分类模型，也满足“理解数据”的需求</p><p>说明模型Interpretation：重要性和难易程度取决于算法；不仅要展示结果，还要解释产生的可能原因</p><h4 id="6-部署"><a href="#6-部署" class="headerlink" title="6-部署"></a>6-部署</h4><p>确定结果应该如何被应用utilized，谁需要使用这些结果、以及使用的频率</p><p>如何部署数据挖掘的结果：生成报告给用户，其中包含（对商业的）改进建议；直接将结果应用在商业中</p><h4 id="为什么使用CRISP-DM"><a href="#为什么使用CRISP-DM" class="headerlink" title="为什么使用CRISP-DM"></a>为什么使用CRISP-DM</h4><p>对于指导方针guidelines和经验文件experience documentation，提供了独一无二的框架</p><p>可以灵活的考虑不同的商业/代理问题和不同的数据</p><h4 id="概念描述，Descriptive-VS-Predictive-data-mining"><a href="#概念描述，Descriptive-VS-Predictive-data-mining" class="headerlink" title="概念描述，Descriptive VS. Predictive data mining"></a>概念描述，Descriptive VS. Predictive data mining</h4><p><strong>描述性的Descriptive</strong> vs <strong>预测性的Predictive</strong>数据挖掘：</p><ul><li>描述性的数据挖掘：以简明扼要的形式描述概念或与任务相关的数据集：决策树，决策规则</li><li><p>预测性的数据挖掘：根据数据和分析，从数据集构建模型，并预测未知数据的趋势和属性：“模型”无需可视化，例如神经网络，集成</p><p><strong>概念描述 Concept description</strong>：</p></li><li><p>表征 Characterization：对给定的数据集合进行简洁明了的总结</p></li></ul><h4 id="数据挖掘-vs-可视化"><a href="#数据挖掘-vs-可视化" class="headerlink" title="数据挖掘 vs 可视化"></a>数据挖掘 vs 可视化</h4><p><strong>数据挖掘</strong>：可以处理复杂数据类型（有许多属性/特征/维度的数据）；更加自动化的过程</p><p><strong>可视化 —— OLAP Online Analytic Processing (Visualization)</strong>：限于少数尺寸和特征类型（例如，不适合文本）；由用户控制的过程</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
